{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5edba719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\generative-health-models\\src\n"
     ]
    }
   ],
   "source": [
    "# 1) Put your repo's src on sys.path\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "\n",
    "SRC = Path(r\"C:\\Users\\Joseph\\generative-health-models\\src\")\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "print(SRC)\n",
    "\n",
    "# 2) (Optional) reload the module if you just edited tc_multigan.py\n",
    "import importlib\n",
    "import models.tc_multigan as tcm\n",
    "importlib.reload(tcm)\n",
    "\n",
    "# 3) Import the parts you need\n",
    "from models.tc_multigan import Embedder, Supervisor\n",
    "from datasets.wesad import make_loader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f39a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using stats: C:\\Users\\Joseph\\generative-health-models\\data\\processed\\tc_multigan_fold_s10\\norm_low.npz C:\\Users\\Joseph\\generative-health-models\\data\\processed\\tc_multigan_fold_s10\\norm_ecg.npz\n"
     ]
    }
   ],
   "source": [
    "# --- Config: mirror AE pretrain ---\n",
    "cfg = SimpleNamespace(\n",
    "    # data\n",
    "    data_root        = r\"C:\\Users\\Joseph\\generative-health-models\\data\\processed\",\n",
    "    fold             = \"tc_multigan_fold_s10\",\n",
    "    train_split      = \"train\",\n",
    "    val_split        = \"test\",          # adjust to your dataset's naming if needed (e.g., \"valid\" or \"dev\")\n",
    "    seq_length_low   = 120,\n",
    "    condition_dim    = 4,\n",
    "\n",
    "    # loader\n",
    "    batch_size       = 32,\n",
    "    num_workers      = 0,\n",
    "    weighted_sampling= False,\n",
    "\n",
    "    # model-ish\n",
    "    hidden_dim       = 256,\n",
    "\n",
    "    # device\n",
    "    device           = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "fold_dir = Path(cfg.data_root) / cfg.fold\n",
    "stats_low_path = fold_dir / \"norm_low.npz\"\n",
    "stats_ecg_path = fold_dir / \"norm_ecg.npz\"\n",
    "\n",
    "print(\"Using stats:\", stats_low_path, stats_ecg_path)\n",
    "assert stats_low_path.exists() and stats_ecg_path.exists(), \\\n",
    "    \"Normalization stats not found. Make sure they were saved during AE pretrain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf7af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loader(split: str, shuffle: bool):\n",
    "    return make_loader(\n",
    "        root_dir          = Path(cfg.data_root),\n",
    "        fold              = cfg.fold,\n",
    "        split             = split,\n",
    "        window_size_low   = cfg.seq_length_low,\n",
    "        batch_size        = cfg.batch_size,\n",
    "        shuffle           = shuffle,\n",
    "        num_workers       = cfg.num_workers,\n",
    "        weighted_sampling = cfg.weighted_sampling,\n",
    "        condition_dim     = cfg.condition_dim,\n",
    "        normalize         = True,\n",
    "        normalize_ecg     = True,\n",
    "        force_use_stats   = True,\n",
    "        stats_low_path    = str(stats_low_path),\n",
    "        stats_ecg_path    = str(stats_ecg_path),\n",
    "        augment           = False,      # keep off for S pretrain\n",
    "        # If your loader supports it, you can force ECG length explicitly:\n",
    "        # window_size_ecg = cfg.seq_length_low * 44,  # e.g., 5280 for integer ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a2890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_low: (32, 120, 2) | x_ecg: (32, 5250, 1) | cond: (32, 120, 4)\n",
      "ECG:low ratio = 5250 / 120 = 43.7500\n",
      "⚠️  Non-integer ratio detected. For best stability, consider re-windowing to an integer multiple, e.g., 120→5280 (×44) or 120→5400 (×45).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dl = build_loader(cfg.train_split, shuffle=True)\n",
    "# If your dataset doesn’t have a \"val\" split, either use \"valid\"/\"dev\" or make a small held-out sampler.\n",
    "try:\n",
    "    val_dl = build_loader(cfg.val_split, shuffle=False)\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't build val loader with split='{cfg.val_split}': {e}\\n\"\n",
    "          \"Falling back to train split without shuffling for quick checks.\")\n",
    "    val_dl = build_loader(cfg.train_split, shuffle=False)\n",
    "\n",
    "# --- One-batch shape & ratio sanity check (important) ---\n",
    "batch = next(iter(train_dl))\n",
    "x_low  = batch[\"signal_low\"]        # (B, T_low,  C=2)\n",
    "x_ecg  = batch[\"signal_ecg\"]        # (B, T_ecg, C=1)\n",
    "cond   = batch[\"condition\"]         # (B, T_low, K=condition_dim)\n",
    "\n",
    "print(\"x_low:\", tuple(x_low.shape), \"| x_ecg:\", tuple(x_ecg.shape), \"| cond:\", tuple(cond.shape))\n",
    "\n",
    "T_low = x_low.shape[1]\n",
    "T_ecg = x_ecg.shape[1]\n",
    "ratio = T_ecg / T_low\n",
    "print(f\"ECG:low ratio = {T_ecg} / {T_low} = {ratio:.4f}\")\n",
    "if abs(ratio - round(ratio)) > 1e-6:\n",
    "    print(\"⚠️  Non-integer ratio detected. For best stability, consider re-windowing to an integer multiple, \"\n",
    "          \"e.g., 120→5280 (×44) or 120→5400 (×45).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cec8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Infer lengths from your loader (keeps dims identical to AE pretrain)\n",
    "_batch = next(iter(train_dl))\n",
    "T_low = _batch[\"signal_low\"].shape[1]       # 120\n",
    "T_ecg = _batch[\"signal_ecg\"].shape[1]       # 5250 (current dataset)\n",
    "H      = cfg.hidden_dim                     # 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0f971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
