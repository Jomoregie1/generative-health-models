{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8ea191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: C:\\Users\\Joseph\\generative-health-models\n",
      "sys.path[0]: C:\\Users\\Joseph\\generative-health-models\\src\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Users\\Joseph\\generative-health-models\")\n",
    "SRC = PROJECT_ROOT / \"src\"\n",
    "\n",
    "# Ensure our local 'src' comes before site-packages (avoid clash with HF 'datasets')\n",
    "os.chdir(PROJECT_ROOT)\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets.wesad import make_loader\n",
    "import models.tc_multigan as tcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a976c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: namespace(data_root='C:\\\\Users\\\\Joseph\\\\generative-health-models\\\\data\\\\processed', fold='tc_multigan_fold_s10', train_split='train', seq_length_low=120, condition_dim=4, batch_size=32, num_workers=0, weighted_sampling=False, hidden_dim=256, lr_g=0.001, epochs_ae=25, device='cuda')\n"
     ]
    }
   ],
   "source": [
    "# ---------------- config & seed ----------------\n",
    "def set_seed(seed=42):\n",
    "    import random, numpy as np\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "cfg = SimpleNamespace(\n",
    "    # data\n",
    "    data_root        = r\"C:\\Users\\Joseph\\generative-health-models\\data\\processed\",\n",
    "    fold             = \"tc_multigan_fold_s10\",\n",
    "    train_split      = \"train\",\n",
    "    seq_length_low   = 120,\n",
    "    condition_dim    = 4,\n",
    "\n",
    "    # loader\n",
    "    batch_size       = 32,\n",
    "    num_workers      = 0,\n",
    "    weighted_sampling= False,\n",
    "\n",
    "    # model / opt\n",
    "    hidden_dim       = 256,\n",
    "    lr_g             = 1e-3,\n",
    "    epochs_ae        = 25,\n",
    "\n",
    "    # device\n",
    "    device           = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "print(\"Config:\", cfg)\n",
    "\n",
    "root = Path(cfg.data_root)\n",
    "fold_dir = root / cfg.fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f8f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- loaders (Option A: no dataset normalization) ----------------\n",
    "train_dl = make_loader(\n",
    "    root_dir=root, fold=cfg.fold, split=\"train\",\n",
    "    window_size_low=cfg.seq_length_low,\n",
    "    batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers,\n",
    "    condition_dim=cfg.condition_dim,\n",
    "    augment=True,\n",
    "    normalize=False, normalize_ecg=False,     # <-- Option A\n",
    "    force_use_stats=False,\n",
    "    use_split_stats_if_needed=False,\n",
    "    stats_low_path=None, stats_ecg_path=None,\n",
    "    debug_print=False,                        # set True if you want one-time prints\n",
    ")\n",
    "\n",
    "val_dl = make_loader(\n",
    "    root_dir=root, fold=cfg.fold, split=\"test\",\n",
    "    window_size_low=cfg.seq_length_low,\n",
    "    batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers,\n",
    "    condition_dim=cfg.condition_dim,\n",
    "    augment=False,\n",
    "    normalize=False, normalize_ecg=False,     # <-- Option A\n",
    "    force_use_stats=False,\n",
    "    use_split_stats_if_needed=False,          # we’ll standardize val on-the-fly below\n",
    "    stats_low_path=None, stats_ecg_path=None,\n",
    "    debug_print=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88e1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN  std low: [0.7463854551315308, 1.0361276865005493] ecg: [0.9888325929641724]\n",
      "VAL    std low: [0.22556525468826294, 0.7407307624816895] ecg: [0.5809653401374817]\n"
     ]
    }
   ],
   "source": [
    "b_tr = next(iter(train_dl)); b_va = next(iter(val_dl))\n",
    "xL_tr, xE_tr = b_tr[\"signal_low\"].float(), b_tr[\"signal_ecg\"].float()\n",
    "xL_va, xE_va = b_va[\"signal_low\"].float(), b_va[\"signal_ecg\"].float()\n",
    "print(\"TRAIN  std low:\", xL_tr.std(dim=(0,1)).tolist(), \"ecg:\", xE_tr.std(dim=(0,1)).tolist())\n",
    "print(\"VAL    std low:\", xL_va.std(dim=(0,1)).tolist(), \"ecg:\", xE_va.std(dim=(0,1)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e5b0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_stats_from_loader(dl):\n",
    "    \"\"\"Mean/std over the whole loader per channel, stable & memory-safe.\"\"\"\n",
    "    sumL = torch.zeros(2, dtype=torch.float64)\n",
    "    sumsqL = torch.zeros(2, dtype=torch.float64)\n",
    "    nL = 0\n",
    "    sumE = torch.zeros(1, dtype=torch.float64)\n",
    "    sumsqE = torch.zeros(1, dtype=torch.float64)\n",
    "    nE = 0\n",
    "\n",
    "    for b in dl:\n",
    "        xL = b[\"signal_low\"].to(dtype=torch.float32)   # (B,T_low,2)\n",
    "        xE = b[\"signal_ecg\"].to(dtype=torch.float32)   # (B,T_ecg,1)\n",
    "        sumL   += xL.sum(dim=(0,1)).double()\n",
    "        sumsqL += (xL**2).sum(dim=(0,1)).double()\n",
    "        nL     += xL.shape[0] * xL.shape[1]\n",
    "        sumE   += xE.sum(dim=(0,1)).view(-1).double()\n",
    "        sumsqE += (xE**2).sum(dim=(0,1)).view(-1).double()\n",
    "        nE     += xE.shape[0] * xE.shape[1]\n",
    "\n",
    "    meanL = (sumL / nL).to(torch.float32).numpy()\n",
    "    varL  = (sumsqL / nL - (sumL / nL)**2).clamp_min(1e-12).to(torch.float32).numpy()\n",
    "    stdL  = np.sqrt(varL)\n",
    "\n",
    "    meanE = (sumE / nE).to(torch.float32).numpy()\n",
    "    varE  = (sumsqE / nE - (sumE / nE)**2).clamp_min(1e-12).to(torch.float32).numpy()\n",
    "    stdE  = np.sqrt(varE)\n",
    "    return meanL, stdL, meanE, stdE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b53b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_muL, val_stdL, val_muE, val_stdE = compute_stats_from_loader(val_dl)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "_EPS = 1e-8\n",
    "\n",
    "# Make them tensors with shape (1, 1, C) for broadcasting over (B, T, C)\n",
    "low_mu  = torch.from_numpy(val_muL).to(device).view(1, 1, 2)\n",
    "low_std = torch.from_numpy(val_stdL).to(device).view(1, 1, 2)\n",
    "ecg_mu  = torch.from_numpy(val_muE).to(device).view(1, 1, 1)\n",
    "ecg_std = torch.from_numpy(val_stdE).to(device).view(1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57b84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_stream_losses(dl, model, device, low_mu, low_std, ecg_mu, ecg_std, eps=1e-8):\n",
    "    \"\"\"Evaluate on val/test with inputs standardized by val/test’s own stats.\"\"\"\n",
    "    model.eval()\n",
    "    totL = totE = n = 0\n",
    "    for batch in dl:\n",
    "        xL = batch[\"signal_low\"].to(device)   # (B, T_low, 2)\n",
    "        xE = batch[\"signal_ecg\"].to(device)   # (B, T_ecg, 1)\n",
    "\n",
    "        xLz = (xL - low_mu) / (low_std + eps)\n",
    "        xEz = (xE - ecg_mu) / (ecg_std + eps)\n",
    "\n",
    "        yL, yE = model(xLz, xEz)\n",
    "\n",
    "        totL += F.mse_loss(yL, xLz).item() * xL.size(0)\n",
    "        totE += F.mse_loss(yE, xEz).item() * xE.size(0)\n",
    "        n += xL.size(0)\n",
    "    return totL / max(1, n), totE / max(1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e9a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "_probe = next(iter(train_dl))\n",
    "T_low = _probe[\"signal_low\"].shape[1]\n",
    "T_ecg = _probe[\"signal_ecg\"].shape[1]\n",
    "\n",
    "ae = tcm.AutoencoderER(\n",
    "    hidden_dim=cfg.hidden_dim,\n",
    "    seq_length_low=T_low,\n",
    "    seq_length_ecg=T_ecg,\n",
    "    latent_downsample=4,\n",
    "    use_ecg=True,\n",
    ").to(device)\n",
    "\n",
    "optim = torch.optim.Adam(ae.parameters(), lr=cfg.lr_g, betas=(0.9, 0.99))\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b6ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xEz mean/std: -0.00010215160000370815 1.0806077718734741\n",
      "yE  mean/std: -0.0012157309101894498 0.004450276959687471\n"
     ]
    }
   ],
   "source": [
    "# === QUICK ECG sanity check (run once, right before the training loop) ===\n",
    "with torch.no_grad():\n",
    "    ae.eval()\n",
    "    b = next(iter(val_dl))\n",
    "    xL = b[\"signal_low\"].to(device)\n",
    "    xE = b[\"signal_ecg\"].to(device)\n",
    "\n",
    "    # Standardize val inputs exactly like in eval_stream_losses\n",
    "    xLz = (xL - low_mu) / (low_std + _EPS)      # (B, T_low, 2)\n",
    "    xEz = (xE - ecg_mu) / (ecg_std + _EPS)      # (B, T_ecg, 1)\n",
    "\n",
    "    yL, yE = ae(xLz, xEz)\n",
    "\n",
    "    print(\"xEz mean/std:\", xEz.mean().item(), xEz.std().item())\n",
    "    print(\"yE  mean/std:\", yE.mean().item(),  yE.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d911b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 020 ECG loss: 1.0550\n",
      "step 040 ECG loss: 1.0499\n",
      "step 060 ECG loss: 1.0444\n",
      "step 080 ECG loss: 1.0383\n",
      "step 100 ECG loss: 1.0354\n",
      "step 120 ECG loss: 1.0425\n",
      "step 140 ECG loss: 1.0281\n",
      "step 160 ECG loss: 1.0333\n",
      "step 180 ECG loss: 1.0197\n",
      "step 200 ECG loss: 1.0193\n"
     ]
    }
   ],
   "source": [
    "ae.train()\n",
    "b = next(iter(train_dl))\n",
    "xL, xE = b[\"signal_low\"].to(cfg.device), b[\"signal_ecg\"].to(cfg.device)\n",
    "\n",
    "opt = torch.optim.Adam(ae.parameters(), lr=1e-3)\n",
    "for t in range(200):\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    yL, yE = ae(xL, xE)\n",
    "    lossE = F.mse_loss(yE, xE)  # focus on ECG only\n",
    "    lossE.backward()\n",
    "    opt.step()\n",
    "    if (t+1) % 20 == 0:\n",
    "        print(f\"step {t+1:03d} ECG loss: {lossE.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef472edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path.cwd() / \"results\" / \"logs\" / \"ae\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    ae.train() if train else ae.eval()\n",
    "    total, n = 0.0, 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for batch in dl:\n",
    "            x_low = batch[\"signal_low\"].to(device)\n",
    "            x_ecg = batch[\"signal_ecg\"].to(device)\n",
    "\n",
    "            low_hat, ecg_hat = ae(x_low, x_ecg)\n",
    "            loss_low = mse(low_hat, x_low)\n",
    "            loss_ecg = mse(ecg_hat, x_ecg)\n",
    "            loss = 0.5 * loss_low + 0.5 * loss_ecg\n",
    "\n",
    "            if train:\n",
    "                optim.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "            bs = x_low.size(0)\n",
    "            total += loss.item() * bs\n",
    "            n += bs\n",
    "    return total / max(1, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3275fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/25] train=0.730792 | val=0.588896 (low=0.177710, ecg=1.000082) | 2.0s\n",
      "  ↳ saved ae_best.pth\n",
      "[002/25] train=0.552198 | val=0.547312 (low=0.094618, ecg=1.000007) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[003/25] train=0.546111 | val=0.535876 (low=0.071755, ecg=0.999998) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[004/25] train=0.524946 | val=0.522702 (low=0.045403, ecg=1.000000) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[005/25] train=0.519193 | val=0.516938 (low=0.033881, ecg=0.999995) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[006/25] train=0.518167 | val=0.514371 (low=0.028746, ecg=0.999996) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[007/25] train=0.524018 | val=0.531066 (low=0.062135, ecg=0.999996) | 1.7s\n",
      "[008/25] train=0.560235 | val=0.540460 (low=0.080914, ecg=1.000006) | 1.8s\n",
      "[009/25] train=0.566189 | val=0.614011 (low=0.228021, ecg=1.000002) | 1.7s\n",
      "[010/25] train=0.575208 | val=0.541975 (low=0.083958, ecg=0.999992) | 1.7s\n",
      "[011/25] train=0.534368 | val=0.513979 (low=0.027961, ecg=0.999998) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[012/25] train=0.574202 | val=0.513306 (low=0.026621, ecg=0.999992) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[013/25] train=0.526765 | val=0.519707 (low=0.039414, ecg=1.000000) | 1.7s\n",
      "[014/25] train=0.514057 | val=0.511128 (low=0.022257, ecg=1.000000) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "[015/25] train=0.511552 | val=0.509168 (low=0.018342, ecg=0.999995) | 1.8s\n",
      "  ↳ saved ae_best.pth\n",
      "[016/25] train=0.512192 | val=0.528628 (low=0.057275, ecg=0.999980) | 1.7s\n",
      "[017/25] train=0.556515 | val=0.521894 (low=0.043780, ecg=1.000008) | 1.7s\n",
      "[018/25] train=0.527368 | val=0.513372 (low=0.026742, ecg=1.000003) | 1.6s\n",
      "[019/25] train=0.510291 | val=0.522187 (low=0.044383, ecg=0.999990) | 1.6s\n",
      "[020/25] train=0.550163 | val=0.516299 (low=0.032591, ecg=1.000006) | 1.7s\n",
      "[021/25] train=0.539780 | val=0.519508 (low=0.039015, ecg=1.000000) | 1.6s\n",
      "[022/25] train=0.530981 | val=0.530462 (low=0.060933, ecg=0.999991) | 1.6s\n",
      "[023/25] train=0.525617 | val=0.525948 (low=0.051901, ecg=0.999996) | 1.6s\n",
      "[024/25] train=0.514636 | val=0.528521 (low=0.057009, ecg=1.000033) | 1.6s\n",
      "[025/25] train=0.515104 | val=0.508219 (low=0.016415, ecg=1.000022) | 1.7s\n",
      "  ↳ saved ae_best.pth\n",
      "Done. Best val recon: 0.5082188700565818 \n",
      "Saved to: C:\\Users\\Joseph\\generative-health-models\\results\\logs\\ae\n"
     ]
    }
   ],
   "source": [
    "# ---------------- training loop ----------------\n",
    "for epoch in range(1, cfg.epochs_ae + 1):\n",
    "    t0 = time.time()\n",
    "    train_loss = run_epoch(train_dl, train=True)\n",
    "\n",
    "    # Validation on standardized inputs (consistent metric)\n",
    "    val_low_mse, val_ecg_mse = eval_stream_losses(\n",
    "        val_dl, ae, device, low_mu, low_std, ecg_mu, ecg_std, eps=_EPS\n",
    "    )\n",
    "    val_loss = 0.5 * val_low_mse + 0.5 * val_ecg_mse\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"[{epoch:03}/{cfg.epochs_ae}] train={train_loss:.6f} | \"\n",
    "          f\"val={val_loss:.6f} (low={val_low_mse:.6f}, ecg={val_ecg_mse:.6f}) | {dt:.1f}s\")\n",
    "\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"state_dict\": ae.state_dict(),\n",
    "        \"optim\": optim.state_dict(),\n",
    "        \"val_loss\": val_loss,\n",
    "        \"meta\": {\n",
    "            \"hidden_dim\": cfg.hidden_dim,\n",
    "            \"T_low\": T_low, \"T_ecg\": T_ecg, \"latent_downsample\": 4,\n",
    "            \"note\": \"Option A: train pre-standardized on disk; val standardized on-the-fly.\",\n",
    "        },\n",
    "    }\n",
    "    torch.save(ckpt, out_dir / \"ae_last.pth\")\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(ckpt, out_dir / \"ae_best.pth\")\n",
    "        print(\"  ↳ saved ae_best.pth\")\n",
    "\n",
    "print(\"Done. Best val recon:\", best_loss, \"\\nSaved to:\", out_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12fd022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE keys top-level prefixes: ['E', 'R']\n",
      "torch.Size([32, 120, 2]) torch.Size([32, 5250, 1])\n"
     ]
    }
   ],
   "source": [
    "sd = torch.load(out_dir / \"ae_best.pth\", map_location=\"cpu\")[\"state_dict\"]\n",
    "top_prefixes = sorted({k.split('.', 1)[0] for k in sd})\n",
    "print(\"AE keys top-level prefixes:\", top_prefixes)  # expect {'E','R'}\n",
    "\n",
    "ae.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(val_dl))\n",
    "    low_hat, ecg_hat = ae(batch[\"signal_low\"].to(device), batch[\"signal_ecg\"].to(device))\n",
    "print(low_hat.shape, ecg_hat.shape)  # expect (B, 120, 2), (B, 5250, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
