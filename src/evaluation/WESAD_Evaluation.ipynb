{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03814c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joseph\\generative-health-models\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Find repo root (directory that contains src/)\n",
    "from pathlib import Path\n",
    "import sys, contextlib, io, json\n",
    "import numpy as np,  pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from shutil import copy2\n",
    "\n",
    "# Resolve REPO root and make src importable\n",
    "here = Path.cwd()\n",
    "REPO = next((p for p in (here, *here.parents) if (p / \"src\").exists()), None)\n",
    "assert REPO is not None, \"Couldn't find repo root (folder with src/)\"\n",
    "sys.path.insert(0, str(REPO / \"src\"))\n",
    "\n",
    "# Core imports from the repo\n",
    "from generate.core import WESADGenerator, _denorm, _interp_to_len, sha256_file\n",
    "from evaluation.wesad_real import RealWESADPreparer\n",
    "from evaluation.wesad_eval import WESADEvaluator, EvalConfig\n",
    "from evaluation.calibration import WESADCalibrator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b2006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080\n",
      "Sample tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    x = torch.randn(1, device=\"cuda\")\n",
    "    print(\"Sample tensor device:\", x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14af833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: c:\\Users\\Joseph\\generative-health-models\n",
      "Milestones: c:\\Users\\Joseph\\generative-health-models\\results\\checkpoints\\diffusion\\milestones\n",
      "Ckpt: c:\\Users\\Joseph\\generative-health-models\\results\\checkpoints\\diffusion\\ckpt_epoch_130_WEIGHTS.pt\n",
      "Fold: c:\\Users\\Joseph\\generative-health-models\\data\\processed\\two_stream\\fold_S10\n",
      "Out: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\eval_ckpt130\n",
      "Real split dir: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\n",
      "Synth dir: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\n"
     ]
    }
   ],
   "source": [
    "# === Paths you’ll most often tweak ===\n",
    "MILESTONES   = REPO / \"results/checkpoints/diffusion/milestones\"\n",
    "CKPT         = REPO / \"results/checkpoints/diffusion/ckpt_epoch_130_WEIGHTS.pt\"  # swap to _041.pt if needed\n",
    "FOLD_DIR     = REPO / \"data/processed/two_stream/fold_S10\"                      # pick the fold you want\n",
    "OUT_DIR      = REPO / \"results/evaluation/eval_ckpt130\"                          # outputs go here\n",
    "CALIB_JSON   = OUT_DIR / \"calibration_targets.json\"\n",
    "NORM_LOW_PATH = FOLD_DIR / \"norm_low.npz\"\n",
    "NORM_ECG_PATH = FOLD_DIR / \"norm_ecg.npz\"\n",
    "\n",
    "# Where the per-class real/synth npz live\n",
    "REAL_SPLIT_DIR = REPO / \"results/evaluation/real_3class_split\"\n",
    "SYN_DIR        = REPO / \"data/generated/3class_calibrated\"\n",
    "\n",
    "# (Legacy scratch eval dir; we’ll create run-tagged dirs later)\n",
    "EVAL_DIR = REPO / \"results\" / \"evaluation\" / \"ckpt130_cls_run_3class\"\n",
    "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "maybe_real_base   = FOLD_DIR / \"test_baseline.npz\"\n",
    "maybe_real_stress = FOLD_DIR / \"test_stress.npz\"\n",
    "maybe_real_amuse  = FOLD_DIR / \"test_amusement.npz\"\n",
    "\n",
    "# ---------- Generation knobs ----------\n",
    "CONDITION          = \"baseline\"   # or \"stress\", \"amusement\" ... (must be supported by your model)\n",
    "BASE_SEED          = 42\n",
    "OVERRIDE_STEPS     = 150          # e.g., 100 to override manifest sampling_steps\n",
    "OVERRIDE_GUIDANCE  = 0.5          # e.g., 0.5 to override manifest cfg_scale\n",
    "FORCE_REBUILD_CAL  = True\n",
    "FORCE_REBUILD_CA   = False\n",
    "\n",
    "# ---- centralized sampling knobs & norm paths ----\n",
    "STEPS_ECG = 150     # or 100 if you prefer\n",
    "STEPS_LOW = 150\n",
    "GUID_ECG  = 0.5\n",
    "GUID_LOW  = 0.1\n",
    "STORE_ECG_QMAP = True     # set True to enable ECG histogram matching\n",
    "RESP_Q_N = 4001           # finer resolution\n",
    "\n",
    "# ---------- Mapping (raw test_cond IDs → 3-class labels) ----------\n",
    "# IMPORTANT for this fold: ID_MAP = {3:0, 2:1, 1:2}\n",
    "BASELINE_ID  = 3\n",
    "STRESS_ID    = 2\n",
    "AMUSEMENT_ID = 1\n",
    "USE_IDS  = [BASELINE_ID, STRESS_ID, AMUSEMENT_ID]\n",
    "REMAPPED = {BASELINE_ID: 0, STRESS_ID: 1, AMUSEMENT_ID: 2}\n",
    "ORDER    = [\"baseline\", \"stress\", \"amusement\"]\n",
    "\n",
    "# ---------- Sampling rates (used by evaluator for PSD/ACF) ----------\n",
    "FS_ECG = 175.0\n",
    "FS_LOW = 4.0\n",
    "\n",
    "# A run tag we’ll reuse for output folders\n",
    "RUN_TAG = f\"3class_run_{CKPT.stem}_seed{BASE_SEED}_stE{STEPS_ECG}_stL{STEPS_LOW}_gE{GUID_ECG}_gL{GUID_LOW}_cal\"\n",
    "BEST_TAG = \"stE200_stL100_gE040_gL010_a80\"  # from your sweep summary\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REAL_SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SYN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Repo:\", REPO)\n",
    "print(\"Milestones:\", MILESTONES)\n",
    "print(\"Ckpt:\", CKPT)\n",
    "print(\"Fold:\", FOLD_DIR)\n",
    "print(\"Out:\", OUT_DIR)\n",
    "print(\"Real split dir:\", REAL_SPLIT_DIR)\n",
    "print(\"Synth dir:\", SYN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b30ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL: (194, 5250, 3) float32 labels: (194,)\n",
      "Saved real set -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\eval_ckpt130\\real_test_ecgT.npz\n"
     ]
    }
   ],
   "source": [
    "# Build the real set in the standard shape (N, T, 3) with channels [ECG, Resp, EDA]\n",
    "prep = RealWESADPreparer(FOLD_DIR)\n",
    "X_real, y_real = prep.prepare(target=\"ecg\")   # T=5250\n",
    "print(\"REAL:\", X_real.shape, X_real.dtype, \"labels:\", None if y_real is None else y_real.shape)\n",
    "\n",
    "assert y_real is not None, \"test_cond.npy missing → labels unavailable.\"\n",
    "assert len(X_real) == len(y_real), \"Label count doesn’t match X count.\"\n",
    "assert X_real.shape[2] == 3 and X_real.shape[1] == 5250, f\"Expected (N,5250,3), got {X_real.shape}\"\n",
    "\n",
    "# Save the full real set once (handy for other tools)\n",
    "real_npz = OUT_DIR / \"real_test_ecgT.npz\"\n",
    "np.savez_compressed(\n",
    "    real_npz,\n",
    "    signals=X_real.astype(np.float32, copy=False),\n",
    "    channels=np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object),\n",
    "    labels=y_real.astype(np.int32, copy=False),\n",
    ")\n",
    "print(\"Saved real set ->\", real_npz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8902ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline   -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_baseline.npz (N=23)\n",
      "stress     -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_stress.npz (N=46)\n",
      "amusement  -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_amusement.npz (N=77)\n",
      "[check] baseline: signals=(23, 5250, 3), labels unique=[0] (expected [0])\n",
      "[check] stress: signals=(46, 5250, 3), labels unique=[1] (expected [1])\n",
      "[check] amusement: signals=(77, 5250, 3), labels unique=[2] (expected [2])\n"
     ]
    }
   ],
   "source": [
    "# ---- Build/refresh the 3-class real split (exclude other IDs, remap with REMAPPED) ----\n",
    "keep = np.isin(y_real, USE_IDS)\n",
    "X3 = X_real[keep]\n",
    "y3_raw = y_real[keep]\n",
    "y3 = np.vectorize(REMAPPED.get)(y3_raw).astype(np.int32)  # {3:0, 2:1, 1:2} -> {0,1,2}\n",
    "\n",
    "def _save_one(label_id: int, name: str) -> Path:\n",
    "    m = (y3 == label_id)\n",
    "    p = REAL_SPLIT_DIR / f\"real_{name}.npz\"\n",
    "    np.savez_compressed(\n",
    "        p,\n",
    "        signals=X3[m].astype(np.float32, copy=False),\n",
    "        channels=np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object),\n",
    "        labels=np.full(int(m.sum()), label_id, dtype=np.int32),\n",
    "    )\n",
    "    print(f\"{name:<10} -> {p} (N={int(m.sum())})\")\n",
    "    return p\n",
    "\n",
    "p_baseline = _save_one(0, \"baseline\")\n",
    "p_stress   = _save_one(1, \"stress\")\n",
    "p_amuse    = _save_one(2, \"amusement\")\n",
    "\n",
    "# Quick sanity: label purity & shapes\n",
    "for name, expected in zip(ORDER, [0,1,2]):\n",
    "    d = np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=True)\n",
    "    uu = np.unique(d[\"labels\"])\n",
    "    print(f\"[check] {name}: signals={d['signals'].shape}, labels unique={uu} (expected [{expected}])\")\n",
    "\n",
    "# Keep for later cells\n",
    "T_target = X_real.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec55fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved calibration targets -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\eval_ckpt130\\calibration_targets.json\n",
      "[cal] ecg_qmap=True  resp_q_n=4001\n"
     ]
    }
   ],
   "source": [
    "CALIB_JSON.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _build_cal_targets():\n",
    "    cal_ = WESADCalibrator.from_real(\n",
    "        X_real,\n",
    "        store_ecg_qmap=STORE_ECG_QMAP,\n",
    "        resp_q_n=int(RESP_Q_N),\n",
    "        # ecg_q_n uses library default unless you want to override\n",
    "    )\n",
    "    cal_.save(CALIB_JSON)\n",
    "    print(\"Saved calibration targets ->\", CALIB_JSON)\n",
    "    return cal_\n",
    "\n",
    "if FORCE_REBUILD_CAL or not CALIB_JSON.exists():\n",
    "    cal = _build_cal_targets()\n",
    "else:\n",
    "    cal = WESADCalibrator.load(CALIB_JSON)\n",
    "    need_rebuild = False\n",
    "    try:\n",
    "        # Rebuild if ECG q-map on/off differs from current knob\n",
    "        if bool(STORE_ECG_QMAP) != bool(cal.has_ecg_qmap()):\n",
    "            need_rebuild = True\n",
    "        # Rebuild if resp quantile resolution changed\n",
    "        rq = getattr(cal.targets, \"resp_qs\", None)\n",
    "        if rq is None or len(rq) != int(RESP_Q_N):\n",
    "            need_rebuild = True\n",
    "    except Exception:\n",
    "        need_rebuild = True\n",
    "\n",
    "    if need_rebuild:\n",
    "        cal = _build_cal_targets()\n",
    "    else:\n",
    "        print(\"Loaded calibration targets:\", CALIB_JSON)\n",
    "\n",
    "# Quick summary\n",
    "try:\n",
    "    rqn = len(getattr(cal.targets, \"resp_qs\", []))\n",
    "except Exception:\n",
    "    rqn = None\n",
    "print(f\"[cal] ecg_qmap={cal.has_ecg_qmap()}  resp_q_n={rqn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fce36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_real_full: (194, 5250, 3) float32\n",
      "y_real_full: (194,) int32\n"
     ]
    }
   ],
   "source": [
    "# 1) Load real windows — reuse the already prepared arrays from RealWESADPreparer\n",
    "X_real_full = X_real.astype(np.float32, copy=False)         # (N, 5250, 3)\n",
    "y_real_full = y_real.astype(np.int32,  copy=False)          # (N,)\n",
    "\n",
    "print(\"X_real_full:\", X_real_full.shape, X_real_full.dtype)\n",
    "print(\"y_real_full:\", y_real_full.shape, y_real_full.dtype)\n",
    "\n",
    "# Sanity checks\n",
    "assert X_real_full.ndim == 3 and X_real_full.shape[2] == 3 and X_real_full.shape[1] == 5250, \\\n",
    "    f\"Expected (N,5250,3), got {X_real_full.shape}\"\n",
    "assert y_real_full is not None and len(X_real_full) == len(y_real_full), \\\n",
    "    \"Label count doesn’t match X count (check you’re using the same fold).\"\n",
    "\n",
    "# Keep target length handy for synth generation\n",
    "T_target = X_real_full.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e5f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline   -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_baseline.npz (N=23)\n",
      "stress     -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_stress.npz (N=46)\n",
      "amusement  -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_amusement.npz (N=77)\n",
      "[check] real_baseline.npz: labels unique=[0] (expected [0])\n",
      "[check] real_stress.npz: labels unique=[1] (expected [1])\n",
      "[check] real_amusement.npz: labels unique=[2] (expected [2])\n"
     ]
    }
   ],
   "source": [
    "# Keep only the chosen three classes, and remap raw IDs -> {0,1,2}\n",
    "keep = np.isin(y_real_full, USE_IDS)\n",
    "\n",
    "remap = np.full_like(y_real_full, fill_value=-1)\n",
    "for raw, mapped in REMAPPED.items():\n",
    "    remap[y_real_full == raw] = mapped\n",
    "\n",
    "X3 = X_real_full[keep]\n",
    "y3 = remap[keep].astype(np.int32)\n",
    "\n",
    "assert X3.shape[1:] == (5250, 3), f\"Expected (N,5250,3), got {X3.shape}\"\n",
    "assert set(np.unique(y3).tolist()).issubset({0,1,2}), f\"Bad remap: {np.unique(y3)}\"\n",
    "\n",
    "# Save class-specific real sets for the evaluator / classifier\n",
    "REAL_SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "channels = np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object)\n",
    "\n",
    "def _save_one(label_id: int, name: str) -> Path:\n",
    "    m = (y3 == label_id)\n",
    "    p = REAL_SPLIT_DIR / f\"real_{name}.npz\"\n",
    "    np.savez_compressed(\n",
    "        p,\n",
    "        signals=X3[m].astype(np.float32, copy=False),\n",
    "        channels=channels,\n",
    "        labels=np.full(int(m.sum()), label_id, dtype=np.int32),\n",
    "    )\n",
    "    print(f\"{name:<10} -> {p} (N={int(m.sum())})\")\n",
    "    return p\n",
    "\n",
    "p_baseline = _save_one(0, \"baseline\")\n",
    "p_stress   = _save_one(1, \"stress\")\n",
    "p_amuse    = _save_one(2, \"amusement\")\n",
    "\n",
    "# Quick sanity: label purity\n",
    "for (p, exp) in [(p_baseline,0),(p_stress,1),(p_amuse,2)]:\n",
    "    d = np.load(p, allow_pickle=True)\n",
    "    u = np.unique(d[\"labels\"])\n",
    "    print(f\"[check] {p.name}: labels unique={u} (expected [{exp}])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dc77153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_match_real_fast(\n",
    "    gen,\n",
    "    condition,\n",
    "    T,\n",
    "    N,\n",
    "    base_seed,\n",
    "    *,\n",
    "    # shared defaults (fallback to manifest)\n",
    "    steps=None,\n",
    "    guidance=None,\n",
    "    batch_size=16,\n",
    "    show_pbar=True,\n",
    "    suppress_model_logs=True,\n",
    "    # which normalization stats to use\n",
    "    norm_source=\"milestone\",\n",
    "    norm_low_path=None,\n",
    "    norm_ecg_path=None,\n",
    "    # NEW: per-head overrides\n",
    "    steps_ecg=None,\n",
    "    steps_low=None,\n",
    "    guidance_ecg=None,\n",
    "    guidance_low=None,\n",
    "):\n",
    "    import io, contextlib\n",
    "    from tqdm.auto import tqdm\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    # --- labels/condition dim ---\n",
    "    label_idx = {'baseline':0, 'stress':1, 'amusement':2}[condition]\n",
    "    K = getattr(gen, \"condition_dim\", None) or int(gen.bundle.manifest.get(\"condition_dim\", 3))\n",
    "    device   = gen.device\n",
    "    manifest = gen.bundle.manifest\n",
    "    method   = str(manifest.get(\"sampling_method\", \"ddim\")).lower()\n",
    "\n",
    "    # --- resolve steps & guidance safely ---\n",
    "    raw_steps = steps if steps is not None else manifest.get(\"sampling_steps\", 50)\n",
    "    try:\n",
    "        base_steps = int(raw_steps)\n",
    "    except Exception:\n",
    "        base_steps = 50\n",
    "    if base_steps < 1:\n",
    "        base_steps = 50  # avoid DDIM division-by-zero\n",
    "\n",
    "    se = int(steps_ecg) if steps_ecg is not None else base_steps\n",
    "    sl = int(steps_low) if steps_low is not None else base_steps\n",
    "    if se < 1: se = base_steps\n",
    "    if sl < 1: sl = base_steps\n",
    "\n",
    "    default_guidance = float(guidance) if guidance is not None else float(manifest.get(\"cfg_scale\", 0.0))\n",
    "    ge = float(guidance_ecg) if guidance_ecg is not None else default_guidance\n",
    "    gl = float(guidance_low) if guidance_low is not None else default_guidance\n",
    "\n",
    "    print(f\"Sampling: method={method}  steps(ecg/low)={se}/{sl}  guidance(ecg/low)={ge}/{gl}\")\n",
    "\n",
    "    # --- seeding ---\n",
    "    torch.manual_seed(int(base_seed))\n",
    "    np.random.seed(int(base_seed))\n",
    "\n",
    "    # --- choose norms ---\n",
    "    if norm_source == \"milestone\":\n",
    "        nl_path = gen.bundle.norm_low\n",
    "        ne_path = gen.bundle.norm_ecg\n",
    "    elif norm_source == \"paths\":\n",
    "        if norm_low_path is None or norm_ecg_path is None:\n",
    "            raise ValueError(\"Provide norm_low_path and norm_ecg_path when norm_source='paths'.\")\n",
    "        nl_path = norm_low_path\n",
    "        ne_path = norm_ecg_path\n",
    "    else:\n",
    "        raise ValueError(\"norm_source must be 'milestone' or 'paths'.\")\n",
    "\n",
    "    nl = np.load(nl_path, allow_pickle=False)\n",
    "    ne = np.load(ne_path, allow_pickle=False)\n",
    "    print(\"Using norm_low from:\", nl_path)\n",
    "    print(\"Using norm_ecg from:\", ne_path)\n",
    "    print(\"low mean/std:\", nl[\"mean\"], nl[\"std\"])\n",
    "    print(\"ecg mean/std:\", ne[\"mean\"], ne[\"std\"])\n",
    "\n",
    "    out = np.empty((N, T, 3), dtype=np.float32)\n",
    "    pbar = tqdm(total=N, desc=\"Synth\", unit=\"win\", leave=True) if show_pbar else None\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        b = min(batch_size, N - i)\n",
    "        cond = torch.zeros(b, K, device=device, dtype=torch.float32)\n",
    "        cond[:, label_idx] = 1.0\n",
    "\n",
    "        def _sample():\n",
    "            with torch.no_grad():\n",
    "                # per-head steps/guidance\n",
    "                x_low = gen.low.sample(cond, num_steps=sl, method=method, cfg_scale=gl)\n",
    "                x_ecg = gen.ecg.sample(cond, num_steps=se, method=method, cfg_scale=ge)\n",
    "            return x_low, x_ecg\n",
    "\n",
    "        if suppress_model_logs:\n",
    "            with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
    "                x_low, x_ecg = _sample()\n",
    "        else:\n",
    "            x_low, x_ecg = _sample()\n",
    "\n",
    "        # de-normalize using the chosen stats\n",
    "        x_low = _denorm(x_low.cpu().numpy(), nl)\n",
    "        x_ecg = _denorm(x_ecg.cpu().numpy(), ne)\n",
    "\n",
    "        # map low-stream channels to [Resp, EDA]\n",
    "        mapped = False\n",
    "        if \"channels\" in nl.files:\n",
    "            try:\n",
    "                chs = [str(c).lower() for c in nl[\"channels\"].tolist()]\n",
    "                resp_idx = chs.index(\"resp\") if \"resp\" in chs else chs.index(\"respiration\")\n",
    "                eda_idx  = chs.index(\"eda\")  if \"eda\"  in chs else chs.index(\"electrodermal activity\")\n",
    "                x_low = x_low[..., [resp_idx, eda_idx]]\n",
    "                mapped = True\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not mapped:\n",
    "            # heuristic: smaller std ~ Resp, larger ~ EDA\n",
    "            stds = x_low.std(axis=(0, 1))\n",
    "            idx_small = int(np.argmin(stds))  # Resp\n",
    "            idx_large = 1 - idx_small         # EDA\n",
    "            x_low = x_low[..., [idx_small, idx_large]]\n",
    "\n",
    "        # EDA non-negative\n",
    "        x_low[..., 1] = np.clip(x_low[..., 1], 0.0, None)\n",
    "\n",
    "        # fuse to requested length T\n",
    "        if T == gen.ecg_len:\n",
    "            fused = np.concatenate([x_ecg.astype(np.float32), _interp_to_len(x_low, gen.ecg_len)], axis=-1)\n",
    "        elif T == gen.low_len:\n",
    "            fused = np.concatenate([_interp_to_len(x_ecg, gen.low_len), x_low.astype(np.float32)], axis=-1)\n",
    "        else:\n",
    "            raise ValueError(f\"T={T} must equal {gen.ecg_len} (ECG) or {gen.low_len} (LOW).\")\n",
    "\n",
    "        out[i:i+b] = fused\n",
    "        if pbar: pbar.update(b)\n",
    "\n",
    "    if pbar: pbar.close()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1127c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using norm_low path: c:\\Users\\Joseph\\generative-health-models\\data\\processed\\two_stream\\fold_S10\\norm_low.npz\n",
      "Using norm_ecg path: c:\\Users\\Joseph\\generative-health-models\\data\\processed\\two_stream\\fold_S10\\norm_ecg.npz\n",
      "low mean/std: [ 0.00161831 -0.00026734] [0.08802962 3.0933654 ]\n",
      "ecg mean/std: [-2.3908885e-06] [0.2691641]\n",
      "[real counts] {'baseline': 23, 'stress': 46, 'amusement': 77}\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_baseline_calibrated.npz\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_stress_calibrated.npz\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_amusement_calibrated.npz\n",
      "Synth files: {'baseline': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_baseline_calibrated.npz'), 'stress': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_stress_calibrated.npz'), 'amusement': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_amusement_calibrated.npz')}\n"
     ]
    }
   ],
   "source": [
    "# Where to save (we'll use SYN_DIR defined earlier)\n",
    "SAVE_DIR = REPO / \"data\" / \"generated\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make a generator tied to your checkpoint\n",
    "gen = WESADGenerator(milestones_dir=MILESTONES, ckpt_path=CKPT)\n",
    "\n",
    "# Show which norm stats we're USING for generation (paths mode -> fold stats)\n",
    "print(\"Using norm_low path:\", NORM_LOW_PATH)\n",
    "print(\"Using norm_ecg path:\", NORM_ECG_PATH)\n",
    "nl = np.load(str(NORM_LOW_PATH), allow_pickle=False)\n",
    "ne = np.load(str(NORM_ECG_PATH), allow_pickle=False)\n",
    "print(\"low mean/std:\", nl[\"mean\"], nl[\"std\"])\n",
    "print(\"ecg mean/std:\", ne[\"mean\"], ne[\"std\"])\n",
    "\n",
    "# Match N per class to the real split\n",
    "counts = {}\n",
    "for name in ORDER:\n",
    "    d = np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=True)\n",
    "    counts[name] = int(d[\"signals\"].shape[0])\n",
    "print(\"[real counts]\", counts)\n",
    "\n",
    "# Helper: generate & calibrate one class\n",
    "def _gen_and_calibrate(name: str, N: int, T: int) -> Path:\n",
    "    out_p = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "    if out_p.exists():\n",
    "        print(\"[synth] exists:\", out_p)\n",
    "        return out_p\n",
    "\n",
    "    print(f\"[synth] generating '{name}' (N={N}, T={T}) → {out_p}\")\n",
    "    X_syn = synth_match_real_fast(\n",
    "        gen, name, T, N, BASE_SEED,\n",
    "        steps=OVERRIDE_STEPS, guidance=OVERRIDE_GUIDANCE,\n",
    "        steps_ecg=STEPS_ECG, steps_low=STEPS_LOW,\n",
    "        guidance_ecg=GUID_ECG, guidance_low=GUID_LOW,\n",
    "        batch_size=16,\n",
    "        norm_source=\"paths\",\n",
    "        norm_low_path=str(NORM_LOW_PATH),\n",
    "        norm_ecg_path=str(NORM_ECG_PATH),\n",
    "    )\n",
    "\n",
    "    # Calibrate in physical units using targets we built earlier\n",
    "    X_syn_cal = cal.apply(\n",
    "        X_syn,\n",
    "        do_ecg=True, do_resp=True, do_eda=True,\n",
    "        ecg_qmap=cal.has_ecg_qmap(), ecg_qmap_alpha=0.6,\n",
    "        enforce_resp_std=True,\n",
    "    )\n",
    "\n",
    "    # Save with labels {0,1,2} matching ORDER\n",
    "    label_idx = ORDER.index(name)\n",
    "    y = np.full(N, label_idx, dtype=np.int32)\n",
    "    np.savez_compressed(\n",
    "        out_p,\n",
    "        signals=X_syn_cal.astype(np.float32, copy=False),\n",
    "        channels=np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object),\n",
    "        labels=y,\n",
    "    )\n",
    "    print(f\"[synth] wrote {out_p} (N={N})\")\n",
    "    return out_p\n",
    "\n",
    "# Generate all three classes to match real counts\n",
    "assert 'T_target' in globals(), \"Define T_target from the real set earlier.\"\n",
    "synth_paths = {name: _gen_and_calibrate(name, counts[name], T_target) for name in ORDER}\n",
    "print(\"Synth files:\", synth_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0031764d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real RAW counts] {'baseline': 23, 'stress': 46, 'amusement': 77} majority= 77\n",
      "[curate A0_e40] baseline   -> kept 23 / 23; shape=(23, 5250, 3)\n",
      "[curate A0_e40] stress     -> kept 31 / 46; shape=(31, 5250, 3)\n",
      "[curate A0_e40] amusement  -> kept 0 / 77; shape=(0, 5250, 3)\n",
      "\n",
      "[A0_e40] Table 2 -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_CLS_A0_e40_zsLocked\\table2_classifier_metrics.csv\n",
      "        setting    AUROC       F1\n",
      "      Real→Real 0.978738 0.943352\n",
      "     Synth→Real 0.693817 0.364004\n",
      "Real+Synth→Real 0.962325 0.180791\n",
      "[curate A3_e40] baseline   -> kept 23 / 23; shape=(23, 5250, 3)\n",
      "[curate A3_e40] stress     -> kept 31 / 46; shape=(31, 5250, 3)\n",
      "[curate A3_e40] amusement  -> kept 2 / 77; shape=(2, 5250, 3)\n",
      "\n",
      "[A3_e40] Table 2 -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_CLS_A3_e40_zsLocked\\table2_classifier_metrics.csv\n",
      "        setting    AUROC       F1\n",
      "      Real→Real 0.970802 0.859073\n",
      "     Synth→Real 0.742961 0.222222\n",
      "Real+Synth→Real 0.972939 0.180791\n",
      "[curate A5_e40] baseline   -> kept 23 / 23; shape=(23, 5250, 3)\n",
      "[curate A5_e40] stress     -> kept 31 / 46; shape=(31, 5250, 3)\n",
      "[curate A5_e40] amusement  -> kept 3 / 77; shape=(3, 5250, 3)\n",
      "\n",
      "[A5_e40] Table 2 -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_CLS_A5_e40_zsLocked\\table2_classifier_metrics.csv\n",
      "        setting    AUROC       F1\n",
      "      Real→Real 0.967983 0.873427\n",
      "     Synth→Real 0.315387 0.335441\n",
      "Real+Synth→Real 0.949344 0.180791\n",
      "\n",
      "=== Summary (locked classifier; vary amusement fraction) ===\n",
      " amusement_frac  epochs  AUROC_Real→Real  F1_Real→Real  AUROC_Real+Synth→Real  F1_Real+Synth→Real                                                                                                                                                                                csv\n",
      "           0.00      40         0.978738      0.943352               0.962325            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A0_e40.csv\n",
      "           0.03      40         0.970802      0.859073               0.972939            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A3_e40.csv\n",
      "           0.05      40         0.967983      0.873427               0.949344            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A5_e40.csv\n",
      "\n",
      "Top by F1 (Real+Synth→Real):\n",
      " amusement_frac  epochs  AUROC_Real→Real  F1_Real→Real  AUROC_Real+Synth→Real  F1_Real+Synth→Real                                                                                                                                                                                csv\n",
      "           0.00      40         0.978738      0.943352               0.962325            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A0_e40.csv\n",
      "           0.03      40         0.970802      0.859073               0.972939            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A3_e40.csv\n",
      "           0.05      40         0.967983      0.873427               0.949344            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A5_e40.csv\n",
      "\n",
      "Top by AUROC (Real+Synth→Real):\n",
      " amusement_frac  epochs  AUROC_Real→Real  F1_Real→Real  AUROC_Real+Synth→Real  F1_Real+Synth→Real                                                                                                                                                                                csv\n",
      "           0.03      40         0.970802      0.859073               0.972939            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A3_e40.csv\n",
      "           0.00      40         0.978738      0.943352               0.962325            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A0_e40.csv\n",
      "           0.05      40         0.967983      0.873427               0.949344            0.180791 c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_INTEGRATED\\table2_classifier_metrics_A5_e40.csv\n"
     ]
    }
   ],
   "source": [
    "# ---- knobs (locked classifier, vary only curation) ----\n",
    "FRACTIONS = [0.00, 0.03, 0.05]   # amusement fractions to try\n",
    "EPOCHS    = 40                   # lock classifier epochs here\n",
    "SEED      = 0\n",
    "\n",
    "# ---- preconditions ----\n",
    "assert 'RUN_TAG' in globals()\n",
    "assert 'ORDER' in globals()\n",
    "assert 'REAL_SPLIT_DIR' in globals() and Path(REAL_SPLIT_DIR).exists()\n",
    "assert 'SYN_DIR' in globals() and Path(SYN_DIR).exists()\n",
    "assert 'T_target' in globals() and isinstance(T_target, int)\n",
    "assert 'FS_ECG' in globals() and 'FS_LOW' in globals()\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "channels = np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object)  # not saved (avoid pickle); here for reference only\n",
    "\n",
    "def _empty_X(): return np.empty((0, T_target, 3), dtype=np.float32)\n",
    "def _empty_y(): return np.empty((0,), dtype=np.int32)\n",
    "\n",
    "# Real class counts (RAW)\n",
    "real_counts = {}\n",
    "for name in ORDER:\n",
    "    with np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=False) as d:\n",
    "        real_counts[name] = int(d[\"signals\"].shape[0])\n",
    "majority_n = max(real_counts.values())\n",
    "print(\"[real RAW counts]\", real_counts, \"majority=\", majority_n)\n",
    "\n",
    "summary_rows = []\n",
    "INTEGRATED_DIR = REPO / \"results\" / \"evaluation\" / (RUN_TAG + \"_INTEGRATED\")\n",
    "INTEGRATED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for frac in FRACTIONS:\n",
    "    tag = f\"A{int(frac*100)}_e{EPOCHS}\"\n",
    "    cur_dir = SYN_DIR.with_name(SYN_DIR.name + f\"_curated_{tag}\")\n",
    "    cur_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- curate synth per class on RAW calibrated NPZs ---\n",
    "    for name in ORDER:\n",
    "        src = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "        if not src.exists():\n",
    "            print(f\"[curate] missing synth raw: {src} -> writing empty stub\")\n",
    "            np.savez_compressed(cur_dir / f\"synth_{name}_calibrated.npz\",\n",
    "                                signals=_empty_X(), labels=_empty_y())\n",
    "            continue\n",
    "\n",
    "        with np.load(src, allow_pickle=False) as d:\n",
    "            Xs = d[\"signals\"].astype(np.float32); ys = d[\"labels\"].astype(np.int32)\n",
    "\n",
    "        if name == \"amusement\":\n",
    "            k = int(np.floor(frac * len(Xs)))\n",
    "        else:\n",
    "            need = max(0, majority_n - real_counts[name])\n",
    "            k = min(need, len(Xs))\n",
    "\n",
    "        if k > 0:\n",
    "            idx = rng.choice(len(Xs), size=k, replace=False)\n",
    "            X_keep = Xs[idx]; y_keep = ys[idx]\n",
    "        else:\n",
    "            X_keep = _empty_X(); y_keep = _empty_y()\n",
    "\n",
    "        # Safety: ensure correct T\n",
    "        if X_keep.shape[1] != T_target:\n",
    "            X_keep = _empty_X(); y_keep = _empty_y()\n",
    "\n",
    "        np.savez_compressed(cur_dir / f\"synth_{name}_calibrated.npz\",\n",
    "                            signals=X_keep, labels=y_keep)\n",
    "        print(f\"[curate {tag}] {name:<10} -> kept {k} / {len(Xs)}; shape={X_keep.shape}\")\n",
    "\n",
    "    # --- run classifier with locked recipe (z-score + balanced) ---\n",
    "    real_files_cls  = {k: REAL_SPLIT_DIR / f\"real_{k}.npz\"               for k in ORDER}\n",
    "    synth_files_cls = {k: cur_dir        / f\"synth_{k}_calibrated.npz\"   for k in ORDER}\n",
    "\n",
    "    out_dir = REPO / \"results\" / \"evaluation\" / (RUN_TAG + f\"_CLS_{tag}_zsLocked\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cfg_cls = EvalConfig(\n",
    "        T_target=T_target, fs_ecg=FS_ECG, fs_low=FS_LOW,\n",
    "        results_dir=out_dir,\n",
    "        run_classifier=True,\n",
    "        clf_labels=(0,1,2),\n",
    "        clf_epochs=EPOCHS,\n",
    "        clf_batch_size=64,\n",
    "        clf_seed=0,\n",
    "        clf_lr=1e-3,\n",
    "        clf_zscore=True,               # <-- lock: z-score w.r.t REAL\n",
    "        clf_class_weight=\"balanced\",   # <-- lock: inverse-frequency weights\n",
    "    )\n",
    "    ev = WESADEvaluator(cfg_cls)\n",
    "    res = ev.evaluate_all(real_files_cls, synth_files_cls)\n",
    "\n",
    "    # Show/collect Table 2\n",
    "    t2 = Path(res[\"table2_csv\"])\n",
    "    df2 = pd.read_csv(t2)\n",
    "\n",
    "    def _pick(rowname: str, col: str):\n",
    "        # handle potential unicode arrow variants robustly\n",
    "        m = df2['setting'].astype(str).str.contains(\"Real\\+Synth\", regex=True, na=False) if rowname==\"Real+Synth→Real\" \\\n",
    "            else df2['setting'].astype(str).str.contains(rowname.split('→')[0], na=False)\n",
    "        if not m.any():\n",
    "            return np.nan\n",
    "        return float(df2.loc[m, col].values[0])\n",
    "\n",
    "    auroc_r   = _pick(\"Real→Real\", \"AUROC\")\n",
    "    f1_r      = _pick(\"Real→Real\", \"F1\")\n",
    "    auroc_mix = _pick(\"Real+Synth→Real\", \"AUROC\")\n",
    "    f1_mix    = _pick(\"Real+Synth→Real\", \"F1\")\n",
    "\n",
    "    print(f\"\\n[{tag}] Table 2 -> {t2}\")\n",
    "    print(df2.to_string(index=False))\n",
    "\n",
    "    # copy to integrated folder\n",
    "    dest_csv = INTEGRATED_DIR / f\"table2_classifier_metrics_{tag}.csv\"\n",
    "    copy2(t2, dest_csv)\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"amusement_frac\": frac,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"AUROC_Real→Real\": auroc_r,\n",
    "        \"F1_Real→Real\": f1_r,\n",
    "        \"AUROC_Real+Synth→Real\": auroc_mix,\n",
    "        \"F1_Real+Synth→Real\": f1_mix,\n",
    "        \"csv\": str(dest_csv),\n",
    "    })\n",
    "\n",
    "# --- summary across fractions ---\n",
    "summary = pd.DataFrame(summary_rows)\n",
    "print(\"\\n=== Summary (locked classifier; vary amusement fraction) ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "print(\"\\nTop by F1 (Real+Synth→Real):\")\n",
    "print(summary.sort_values(\"F1_Real+Synth→Real\", ascending=False).head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop by AUROC (Real+Synth→Real):\")\n",
    "print(summary.sort_values(\"AUROC_Real+Synth→Real\", ascending=False).head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44286f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real counts] {'baseline': 23, 'stress': 46, 'amusement': 77}\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_baseline_calibrated.npz\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_stress_calibrated.npz\n",
      "[synth] exists: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_amusement_calibrated.npz\n",
      "Synth files: {'baseline': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_baseline_calibrated.npz'), 'stress': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_stress_calibrated.npz'), 'amusement': WindowsPath('c:/Users/Joseph/generative-health-models/data/generated/3class_calibrated/synth_amusement_calibrated.npz')}\n"
     ]
    }
   ],
   "source": [
    "# --- Per-class counts from REAL split (physical units) ---\n",
    "counts = {}\n",
    "for name in ORDER:\n",
    "    with np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=True) as d:\n",
    "        counts[name] = int(d[\"signals\"].shape[0])\n",
    "print(\"[real counts]\", counts)\n",
    "\n",
    "# --- Per-head sampling for this run (as requested) ---\n",
    "STEPS_ECG = 100\n",
    "STEPS_LOW = 100\n",
    "GUID_ECG  = 0.5\n",
    "GUID_LOW  = 0.1\n",
    "\n",
    "# --- Generate & calibrate helper (idempotent) ---\n",
    "from pathlib import Path\n",
    "def _gen_and_calibrate(name: str, N: int, T: int) -> Path:\n",
    "    out_p = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "    if out_p.exists():\n",
    "        print(\"[synth] exists:\", out_p)\n",
    "        return out_p\n",
    "\n",
    "    print(f\"[synth] generating '{name}' (N={N}, T={T}) → {out_p}\")\n",
    "    X_syn = synth_match_real_fast(\n",
    "        gen, name, T, N, BASE_SEED,\n",
    "        steps=OVERRIDE_STEPS, guidance=OVERRIDE_GUIDANCE,\n",
    "        steps_ecg=STEPS_ECG, steps_low=STEPS_LOW,\n",
    "        guidance_ecg=GUID_ECG, guidance_low=GUID_LOW,\n",
    "        batch_size=16,\n",
    "        norm_source=\"paths\",\n",
    "        norm_low_path=str(NORM_LOW_PATH),\n",
    "        norm_ecg_path=str(NORM_ECG_PATH),\n",
    "    )\n",
    "    # Calibrate in physical units using prebuilt targets\n",
    "    X_syn_cal = cal.apply(\n",
    "        X_syn,\n",
    "        do_ecg=True, do_resp=True, do_eda=True,\n",
    "        ecg_qmap=cal.has_ecg_qmap(), ecg_qmap_alpha=0.7,\n",
    "        enforce_resp_std=True,\n",
    "    )\n",
    "    # Labels {0,1,2} matching ORDER\n",
    "    label_idx = ORDER.index(name)\n",
    "    y = np.full(N, label_idx, dtype=np.int32)\n",
    "    np.savez_compressed(\n",
    "        out_p,\n",
    "        signals=X_syn_cal.astype(np.float32, copy=False),\n",
    "        channels=np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object),\n",
    "        labels=y,\n",
    "    )\n",
    "    print(f\"[synth] wrote {out_p} (N={N})\")\n",
    "    return out_p\n",
    "\n",
    "# --- Generate any missing classes (match T to real) ---\n",
    "assert 'T_target' in globals(), \"T_target not set; run the real-prep cell first.\"\n",
    "synth_paths = {name: _gen_and_calibrate(name, counts[name], T_target) for name in ORDER}\n",
    "print(\"Synth files:\", synth_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708b4eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping single-condition save; calibrated per-class files already exist in: c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\n",
      "  baseline   c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_baseline_calibrated.npz  (N=23, T=5250)\n",
      "  stress     c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_stress_calibrated.npz  (N=46, T=5250)\n",
      "  amusement  c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_amusement_calibrated.npz  (N=77, T=5250)\n"
     ]
    }
   ],
   "source": [
    "channels = np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object)\n",
    "\n",
    "if 'X_cal' in globals():\n",
    "    # Prefer evaluator-friendly schema and include a label vector\n",
    "    label_idx = ORDER.index(CONDITION) if 'CONDITION' in globals() else 0\n",
    "    cal_npz = SAVE_DIR / f\"synth_{CONDITION}_N{X_cal.shape[0]}_T{X_cal.shape[1]}_seed{BASE_SEED}_calibrated_preview.npz\"\n",
    "    np.savez_compressed(\n",
    "        cal_npz,\n",
    "        signals=X_cal.astype(np.float32, copy=False),\n",
    "        channels=channels,\n",
    "        labels=np.full(X_cal.shape[0], label_idx, dtype=np.int32),\n",
    "        condition=str(CONDITION),\n",
    "        window_ids=np.arange(X_cal.shape[0], dtype=np.int32),\n",
    "    )\n",
    "    print(\"Saved preview calibrated NPZ ->\", cal_npz)\n",
    "else:\n",
    "    print(\"Skipping single-condition save; calibrated per-class files already exist in:\", SYN_DIR)\n",
    "    for name in ORDER:\n",
    "        p = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "        if p.exists():\n",
    "            with np.load(p, allow_pickle=True) as d:\n",
    "                X = d[\"signals\"]\n",
    "                print(f\"  {name:<10} {p}  (N={X.shape[0]}, T={X.shape[1]})\")\n",
    "        else:\n",
    "            print(f\"  [missing] {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bb7af24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote meta -> C:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\eval_ckpt130\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_meta.json\n"
     ]
    }
   ],
   "source": [
    "# --- Build a consolidated run meta (works with per-class calibrated files) ---\n",
    "manifest = getattr(gen.bundle, \"manifest\", {})\n",
    "sampling_method = str(manifest.get(\"sampling_method\", \"ddim\"))\n",
    "\n",
    "base_steps = int(OVERRIDE_STEPS or manifest.get(\"sampling_steps\", 50))\n",
    "base_guid  = float(OVERRIDE_GUIDANCE if OVERRIDE_GUIDANCE is not None else manifest.get(\"cfg_scale\", 0.0))\n",
    "\n",
    "def _summ_stats(arr: np.ndarray):\n",
    "    return {\n",
    "        \"mean\": [float(arr[..., i].mean()) for i in range(3)],\n",
    "        \"std\":  [float(arr[..., i].std())  for i in range(3)],\n",
    "    }\n",
    "\n",
    "# Real stats are always available\n",
    "stats_real = _summ_stats(X_real)\n",
    "\n",
    "# Optional single-condition preview stats (only if those vars exist)\n",
    "stats_pre  = _summ_stats(X_synth) if \"X_synth\" in globals() else None\n",
    "stats_post = _summ_stats(X_cal)   if \"X_cal\"   in globals() else None\n",
    "\n",
    "# If no single-condition preview, aggregate calibrated synth across the three class files\n",
    "if stats_post is None:\n",
    "    try:\n",
    "        agg = []\n",
    "        for name in ORDER:\n",
    "            p = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "            if p.exists():\n",
    "                with np.load(p, allow_pickle=True) as d:\n",
    "                    agg.append(d[\"signals\"].astype(np.float32))\n",
    "        if agg:\n",
    "            S = np.concatenate(agg, axis=0)  # (N_total, T, 3)\n",
    "            stats_post = _summ_stats(S)\n",
    "    except Exception as e:\n",
    "        print(\"[meta] warn: could not aggregate synth stats:\", e)\n",
    "\n",
    "# Per-class counts (recompute if not in scope)\n",
    "try:\n",
    "    counts  # noqa: F401\n",
    "except NameError:\n",
    "    counts = {}\n",
    "    for name in ORDER:\n",
    "        with np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=True) as d:\n",
    "            counts[name] = int(d[\"signals\"].shape[0])\n",
    "\n",
    "# Optional previous evaluation block (if you already ran an eval and have 'results')\n",
    "eval_block = None\n",
    "if \"results\" in globals() and isinstance(results, dict) and \"metrics\" in results:\n",
    "    eval_block = {\n",
    "        \"table1_csv\": results.get(\"table1_csv\"),\n",
    "        \"figure_psd\": results.get(\"figure_psd\"),\n",
    "        \"figure_acf\": results.get(\"figure_acf\"),\n",
    "        \"metrics\": results[\"metrics\"],\n",
    "    }\n",
    "\n",
    "# Collect synthesized file paths for traceability\n",
    "synth_files_map = {name: str((SYN_DIR / f\"synth_{name}_calibrated.npz\").resolve()) for name in ORDER}\n",
    "\n",
    "meta = {\n",
    "    \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"run\": {\n",
    "        \"seed\": int(BASE_SEED),\n",
    "        \"save_dir\": str(SYN_DIR.resolve()),\n",
    "        \"real_split_dir\": str(REAL_SPLIT_DIR.resolve()),\n",
    "        \"per_class_counts\": {k: int(v) for k, v in counts.items()},\n",
    "        # single-condition fields (present only if preview was run)\n",
    "        \"single_condition\": {\n",
    "            \"condition\": str(CONDITION) if \"CONDITION\" in globals() else None,\n",
    "            \"N\": int(X_synth.shape[0]) if \"X_synth\" in globals() else None,\n",
    "            \"T\": int(X_synth.shape[1]) if \"X_synth\" in globals() else None,\n",
    "            \"npz_raw\": str(npz_path) if \"npz_path\" in globals() else None,\n",
    "            \"npz_calibrated\": str(cal_npz) if \"cal_npz\" in globals() else None,\n",
    "        },\n",
    "        \"synth_files_calibrated\": synth_files_map,\n",
    "        \"real_full_npz\": str((OUT_DIR / \"real_test_ecgT.npz\").resolve()),\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"ckpt_path\": str(CKPT),\n",
    "        \"ckpt_sha256\": sha256_file(CKPT),\n",
    "        \"milestones_dir\": str(MILESTONES),\n",
    "        \"condition_dim\": int(getattr(gen, \"condition_dim\", manifest.get(\"condition_dim\", 3))),\n",
    "        \"sampling_method\": sampling_method,\n",
    "    },\n",
    "    \"sampling\": {\n",
    "        \"base_steps\": base_steps,\n",
    "        \"base_guidance\": base_guid,\n",
    "        \"ecg\": {\"steps\": int(STEPS_ECG), \"guidance\": float(GUID_ECG)},\n",
    "        \"low\": {\"steps\": int(STEPS_LOW), \"guidance\": float(GUID_LOW)},\n",
    "    },\n",
    "    \"norms\": {\n",
    "        \"used\": {\n",
    "            \"low_path\": str(NORM_LOW_PATH),\n",
    "            \"low_sha256\": sha256_file(NORM_LOW_PATH),\n",
    "            \"ecg_path\": str(NORM_ECG_PATH),\n",
    "            \"ecg_sha256\": sha256_file(NORM_ECG_PATH),\n",
    "        },\n",
    "        \"milestone_defaults\": {\n",
    "            \"low_path\": str(gen.bundle.norm_low),\n",
    "            \"low_sha256\": sha256_file(gen.bundle.norm_low),\n",
    "            \"ecg_path\": str(gen.bundle.norm_ecg),\n",
    "            \"ecg_sha256\": sha256_file(gen.bundle.norm_ecg),\n",
    "        },\n",
    "    },\n",
    "    \"calibration\": {\n",
    "        \"ecg_scaled_to_real_std\": True,\n",
    "        \"resp_quantile_mapped\": True,\n",
    "        \"eda_mean_std_matched\": True,\n",
    "        \"ecg_hist_qmap\": bool(STORE_ECG_QMAP),\n",
    "        \"enforce_resp_std\": True,\n",
    "        \"calibration_targets_path\": str(CALIB_JSON),\n",
    "        \"ecg_qmap_alpha\": 0.6,  # keep consistent with _gen_and_calibrate\n",
    "    },\n",
    "    \"stats\": {\n",
    "        \"real\": stats_real,\n",
    "        \"pre_calibration\": stats_pre,    # may be None\n",
    "        \"post_calibration\": stats_post,  # aggregated if preview not run\n",
    "        \"channel_order\": [\"ECG\", \"Resp\", \"EDA\"],\n",
    "    },\n",
    "    \"evaluation\": eval_block,  # may be None; will be filled after you run the eval cells\n",
    "}\n",
    "\n",
    "meta_path = (OUT_DIR / f\"{RUN_TAG}_meta.json\").resolve()\n",
    "meta_path.write_text(json.dumps(meta, indent=2))\n",
    "print(\"Wrote meta ->\", meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "091f1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN_TAG: 3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal\n",
      "[real]  baseline   -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_baseline.npz\n",
      "[real]  stress     -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_stress.npz\n",
      "[real]  amusement  -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\real_3class_split\\real_amusement.npz\n",
      "[synth] baseline   -> c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_baseline_calibrated.npz\n",
      "[synth] stress     -> c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_stress_calibrated.npz\n",
      "[synth] amusement  -> c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated\\synth_amusement_calibrated.npz\n"
     ]
    }
   ],
   "source": [
    "# --- Per-class file maps for the evaluator (RAW / physical units) ---\n",
    "real_files = {\n",
    "    \"baseline\": REAL_SPLIT_DIR / \"real_baseline.npz\",\n",
    "    \"stress\":   REAL_SPLIT_DIR / \"real_stress.npz\",\n",
    "    \"amusement\":REAL_SPLIT_DIR / \"real_amusement.npz\",\n",
    "}\n",
    "synth_files = {\n",
    "    \"baseline\": SYN_DIR / \"synth_baseline_calibrated.npz\",\n",
    "    \"stress\":   SYN_DIR / \"synth_stress_calibrated.npz\",\n",
    "    \"amusement\":SYN_DIR / \"synth_amusement_calibrated.npz\",\n",
    "}\n",
    "\n",
    "# Reconfirm RUN_TAG (if not already set earlier)\n",
    "try:\n",
    "    RUN_TAG\n",
    "except NameError:\n",
    "    CKPT_TAG = Path(CKPT).stem\n",
    "    RUN_TAG  = f\"3class_run_{CKPT_TAG}_seed{BASE_SEED}_stE{STEPS_ECG}_stL{STEPS_LOW}_gE{GUID_ECG}_gL{GUID_LOW}_cal\"\n",
    "\n",
    "print(\"RUN_TAG:\", RUN_TAG)\n",
    "for k, p in real_files.items():   print(f\"[real]  {k:<10} -> {p}\")\n",
    "for k, p in synth_files.items():  print(f\"[synth] {k:<10} -> {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0734170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real counts] {'baseline': 23, 'stress': 46, 'amusement': 77} T_target: 5250\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE035_gL010_a80\\synth_baseline_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE035_gL010_a80\\synth_stress_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE035_gL010_a80\\synth_amusement_calibrated.npz\n",
      "\n",
      "[ECG PSD_sim after band/HPF] 0.729  (target ≥ 0.70)\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE030_gL010_a80\\synth_baseline_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE030_gL010_a80\\synth_stress_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE030_gL010_a80\\synth_amusement_calibrated.npz\n",
      "\n",
      "[ECG PSD_sim after band/HPF] 0.729  (target ≥ 0.70)\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE040_gL010_a80\\synth_baseline_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE040_gL010_a80\\synth_stress_calibrated.npz\n",
      "[reuse] c:\\Users\\Joseph\\generative-health-models\\data\\generated\\3class_calibrated_sweep\\stE200_stL100_gE040_gL010_a80\\synth_amusement_calibrated.npz\n",
      "\n",
      "[ECG PSD_sim after band/HPF] 0.729  (target ≥ 0.70)\n",
      "\n",
      "=== ECG-focused sweep summary (higher is better) ===\n",
      "                          tag   gE  alpha  ECG_PSD_sim  Resp_PSD_sim  EDA_PSD_sim\n",
      "stE200_stL100_gE035_gL010_a80 0.35    0.8     0.729119      0.663312     0.999389\n",
      "stE200_stL100_gE030_gL010_a80 0.30    0.8     0.729119      0.663312     0.999389\n",
      "stE200_stL100_gE040_gL010_a80 0.40    0.8     0.729119      0.663312     0.999389\n",
      "\n",
      "Best combo: stE200_stL100_gE035_gL010_a80  ECG_PSD_sim=0.729\n",
      "Table 1 -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_RAW_stE200_stL100_gE040_gL010_a80_ecgBandHP\\table1_distribution_psd_acf.csv\n",
      "PSD fig -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_RAW_stE200_stL100_gE040_gL010_a80_ecgBandHP\\figure_psd_overlay.png\n",
      "ACF fig -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_RAW_stE200_stL100_gE040_gL010_a80_ecgBandHP\\figure_acf_overlay.png\n"
     ]
    }
   ],
   "source": [
    "# ---- knobs to try ----\n",
    "GUID_ECG_LIST        = [0.35, 0.30, 0.40]   # start at 0.35; also test 0.30/0.40\n",
    "STEPS_ECG            = 200\n",
    "STEPS_LOW            = 100\n",
    "GUID_LOW             = 0.10\n",
    "ECG_QMAP_ALPHA_LIST  = [0.8]                # can add 0.6 or 1.0 later\n",
    "\n",
    "ORDER = [\"baseline\", \"stress\", \"amusement\"]  # sanity\n",
    "\n",
    "assert 'gen' in globals(), \"Create WESADGenerator as 'gen' earlier.\"\n",
    "\n",
    "# Where to write synth variants\n",
    "SYN_SWEEP_BASE = Path(REPO) / \"data\" / \"generated\" / \"3class_calibrated_sweep\"\n",
    "SYN_SWEEP_BASE.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "# Real counts + T_target from the split you already built\n",
    "real_counts = {}\n",
    "T_target = None\n",
    "for name in ORDER:\n",
    "    with np.load(Path(REAL_SPLIT_DIR) / f\"real_{name}.npz\", allow_pickle=False) as d:\n",
    "        real_counts[name] = int(d[\"signals\"].shape[0])\n",
    "        if T_target is None:\n",
    "            T_target = int(d[\"signals\"].shape[1])\n",
    "print(\"[real counts]\", real_counts, \"T_target:\", T_target)\n",
    "\n",
    "# Load (or build) calibrator with ECG q-map\n",
    "try:\n",
    "    cal = WESADCalibrator.load(CALIB_JSON)\n",
    "except Exception:\n",
    "    prep = RealWESADPreparer(FOLD_DIR)\n",
    "    Xr_tmp, _ = prep.prepare(target=\"ecg\")\n",
    "    cal = WESADCalibrator.from_real(Xr_tmp, store_ecg_qmap=True, resp_q_n=4001)\n",
    "    cal.save(CALIB_JSON)\n",
    "\n",
    "if not cal.has_ecg_qmap():\n",
    "    print(\"[warn] calibration targets lack ECG q-map; ecg_qmap will be disabled for apply().\")\n",
    "\n",
    "def _gen_and_calibrate_to(out_dir: Path, name: str, N: int, T: int, ge: float, alpha: float) -> Path:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_p = out_dir / f\"synth_{name}_calibrated.npz\"\n",
    "\n",
    "    # Reuse if already present at correct shape\n",
    "    if out_p.exists():\n",
    "        try:\n",
    "            with np.load(out_p, allow_pickle=False) as d:\n",
    "                if d[\"signals\"].shape == (N, T, 3):\n",
    "                    print(f\"[reuse] {out_p}\")\n",
    "                    return out_p\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    print(f\"[gen] {name}  N={N} T={T}  steps_ecg={STEPS_ECG} steps_low={STEPS_LOW}  gE={ge:.2f} gL={GUID_LOW:.2f}  qmap_alpha={alpha:.2f}\")\n",
    "    X_syn = synth_match_real_fast(\n",
    "        gen, name, T, N, BASE_SEED,\n",
    "        steps=OVERRIDE_STEPS, guidance=OVERRIDE_GUIDANCE,   # base (unused by per-head but kept)\n",
    "        steps_ecg=STEPS_ECG, steps_low=STEPS_LOW,\n",
    "        guidance_ecg=ge, guidance_low=GUID_LOW,\n",
    "        batch_size=16,\n",
    "        norm_source=\"paths\",\n",
    "        norm_low_path=str(Path(FOLD_DIR) / \"norm_low.npz\"),\n",
    "        norm_ecg_path=str(Path(FOLD_DIR) / \"norm_ecg.npz\"),\n",
    "    )\n",
    "\n",
    "    X_syn_cal = cal.apply(\n",
    "        X_syn, do_ecg=True, do_resp=True, do_eda=True,\n",
    "        ecg_qmap=(cal.has_ecg_qmap() and True),\n",
    "        ecg_qmap_alpha=float(alpha),\n",
    "        enforce_resp_std=True\n",
    "    )\n",
    "\n",
    "    y = np.full(N, ORDER.index(name), dtype=np.int32)\n",
    "    np.savez_compressed(\n",
    "        out_p,\n",
    "        signals=X_syn_cal.astype(np.float32, copy=False),\n",
    "        labels=y,\n",
    "        channels=np.array([\"ECG\",\"Resp\",\"EDA\"], dtype=object),\n",
    "    )\n",
    "    return out_p\n",
    "\n",
    "summary = []\n",
    "for ge in GUID_ECG_LIST:\n",
    "    for alpha in ECG_QMAP_ALPHA_LIST:\n",
    "        tag = f\"stE{STEPS_ECG}_stL{STEPS_LOW}_gE{int(round(ge*100)):03d}_gL{int(round(GUID_LOW*100)):03d}_a{int(round(alpha*100)):02d}\"\n",
    "        out_dir = SYN_SWEEP_BASE / tag\n",
    "\n",
    "        synth_paths = {}\n",
    "        for name in ORDER:\n",
    "            synth_paths[name] = _gen_and_calibrate_to(out_dir, name, real_counts[name], T_target, ge, alpha)\n",
    "\n",
    "        real_files  = {k: Path(REAL_SPLIT_DIR) / f\"real_{k}.npz\"                  for k in [\"baseline\",\"stress\",\"amusement\"]}\n",
    "        synth_files = {k: SYN_DIR               / f\"synth_{k}_calibrated.npz\"     for k in [\"baseline\",\"stress\",\"amusement\"]}\n",
    "\n",
    "         # RAW eval (Table 1 only) with EDA linear fix\n",
    "        EVAL_RAW_BAND = REPO / \"results\" / \"evaluation\" / (RUN_TAG + f\"_RAW_{BEST_TAG}_ecgBandHP\")\n",
    "        EVAL_RAW_BAND.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        cfg_raw = EvalConfig(\n",
    "            T_target=T_target, fs_ecg=FS_ECG, fs_low=FS_LOW,\n",
    "            results_dir=EVAL_RAW_BAND,\n",
    "            run_classifier=False,\n",
    "            apply_eda_linfix=True,        # keep your EDA correction\n",
    "            psd_low_max_hz=1.5,           # low streams capped for PSD compare\n",
    "            psd_ecg_band=(0.5, 40.0),     # ECG band\n",
    "            ecg_hp_cut_hz=None,           # no HPF (was hurting)\n",
    "            psd_log=True,                 # <- the key that lifted PSD_sim\n",
    "            psd_norm=None,                # correlation already scale/offset-invariant\n",
    "        )\n",
    "\n",
    "        ev = WESADEvaluator(cfg_raw)\n",
    "        res = ev.evaluate_all(real_files, synth_files)\n",
    "\n",
    "        # Read Table 1 and collect ECG PSD_sim\n",
    "        t1 = Path(res[\"table1_csv\"])\n",
    "        df1 = pd.read_csv(t1)\n",
    "        ecg_row  = df1[df1[\"channel\"].str.upper() == \"ECG\"].iloc[0]\n",
    "        resp_row = df1[df1[\"channel\"].str.upper() == \"RESP\"].iloc[0]\n",
    "        eda_row  = df1[df1[\"channel\"].str.upper() == \"EDA\"].iloc[0]\n",
    "\n",
    "        row_ecg = df1[df1[\"channel\"].str.upper()==\"ECG\"].iloc[0]\n",
    "        ecg_psd = float(ecg_row[\"PSD_sim\"])\n",
    "        print(f\"\\n[ECG PSD_sim after band/HPF] {row_ecg['PSD_sim']:.3f}  (target ≥ 0.70)\")\n",
    "\n",
    "        summary.append({\n",
    "            \"tag\": tag,\n",
    "            \"gE\": ge,\n",
    "            \"alpha\": alpha,\n",
    "            \"ECG_PSD_sim\": ecg_psd,\n",
    "            \"ECG_KS\": float(ecg_row[\"KS\"]),\n",
    "            \"ECG_W1\": float(ecg_row[\"W1\"]),\n",
    "            \"ROW_ECG\": float(row_ecg['PSD_sim']),\n",
    "            \"Resp_PSD_sim\": float(resp_row[\"PSD_sim\"]),\n",
    "            \"EDA_PSD_sim\": float(eda_row[\"PSD_sim\"]),\n",
    "            \"table1_csv\": str(t1),\n",
    "            \"figure_psd\": res[\"figure_psd\"],\n",
    "            \"figure_acf\": res[\"figure_acf\"],\n",
    "        })\n",
    "\n",
    "# ---- summary & best pick ----\n",
    "sum_df = pd.DataFrame(summary).sort_values(\"ECG_PSD_sim\", ascending=False)\n",
    "print(\"\\n=== ECG-focused sweep summary (higher is better) ===\")\n",
    "print(sum_df[[\"tag\",\"gE\",\"alpha\",\"ECG_PSD_sim\",\"Resp_PSD_sim\",\"EDA_PSD_sim\"]].to_string(index=False))\n",
    "\n",
    "if len(sum_df):\n",
    "    best = sum_df.iloc[0]\n",
    "    print(f\"\\nBest combo: {best['tag']}  ECG_PSD_sim={best['ECG_PSD_sim']:.3f}\")\n",
    "    print(f\"Table 1 -> {best['table1_csv']}\")\n",
    "    print(f\"PSD fig -> {best['figure_psd']}\")\n",
    "    print(f\"ACF fig -> {best['figure_acf']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0951f055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080\n",
      "Sample tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    x = torch.randn(1, device=\"cuda\")\n",
    "    print(\"Sample tensor device:\", x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d13e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote Table 1 (+ baseline): c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\ckpt130_cls_run_3class\\table1_with_baseline.csv\n",
      "PSD fig (Diffusion): c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\ckpt130_cls_run_3class\\figure_psd_overlay.png\n",
      "PSD fig (Baseline) : c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\ckpt130_cls_run_3class\\figure_psd_overlay.png\n",
      "ACF fig (Diffusion): c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\ckpt130_cls_run_3class\\figure_acf_overlay.png\n",
      "ACF fig (Baseline) : c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\ckpt130_cls_run_3class\\figure_acf_overlay.png\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(123)  # reproducible baseline\n",
    "\n",
    "def phase_randomize_batch(X: np.ndarray, rng=np.random.default_rng(0)) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Phase-randomized surrogate: preserves magnitude spectrum (thus PSD),\n",
    "    destroys temporal phase relationships. Works per sample, per channel.\n",
    "    X: (N, T, 3) -> returns same shape.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    N, T, C = X.shape\n",
    "    Y = np.empty_like(X)\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            x = X[n, :, c].astype(np.float64)\n",
    "            Xf = np.fft.rfft(x)           # length T//2 + 1\n",
    "            mag = np.abs(Xf)\n",
    "            theta = rng.uniform(-np.pi, np.pi, Xf.shape)\n",
    "\n",
    "            # keep DC (and Nyquist if even-length) as real to preserve mean/energy\n",
    "            theta[0] = 0.0\n",
    "            if (T % 2) == 0:\n",
    "                theta[-1] = 0.0\n",
    "\n",
    "            Yf = mag * np.exp(1j * theta)\n",
    "            y = np.fft.irfft(Yf, n=T)\n",
    "            Y[n, :, c] = y.astype(np.float32)\n",
    "    return Y\n",
    "\n",
    "# Use the same RAW settings you’ve been using for Table 1\n",
    "cfg_raw_bl = EvalConfig(\n",
    "    T_target=T_target,\n",
    "    fs_ecg=FS_ECG,\n",
    "    fs_low=FS_LOW,\n",
    "    results_dir=EVAL_DIR,     # put outputs alongside your existing results\n",
    "    run_classifier=False,\n",
    "    apply_eda_linfix=True,    # keep your EDA linear correction for fairness\n",
    "    psd_low_max_hz=1.5,\n",
    ")\n",
    "\n",
    "ev_bl = WESADEvaluator(cfg_raw_bl)\n",
    "\n",
    "# Load aligned real & diffusion arrays via your evaluator\n",
    "Xr, yr, Xs, ys = ev_bl.load_and_align(real_files, synth_files)\n",
    "\n",
    "# Build baseline (same shape as real), then compute metrics\n",
    "Xb = phase_randomize_batch(Xr, rng=rng)\n",
    "\n",
    "dist_diff = ev_bl.distribution_metrics(Xr, Xs)\n",
    "psd_diff  = ev_bl.psd_similarity(Xr, Xs)\n",
    "acf_diff  = ev_bl.acf_similarity(Xr, Xs)\n",
    "\n",
    "dist_base = ev_bl.distribution_metrics(Xr, Xb)\n",
    "psd_base  = ev_bl.psd_similarity(Xr, Xb)\n",
    "acf_base  = ev_bl.acf_similarity(Xr, Xb)\n",
    "\n",
    "# Write a combined Table 1 with a Model column\n",
    "table1_with_baseline = Path(EVAL_DIR) / \"table1_with_baseline.csv\"\n",
    "with table1_with_baseline.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Channel,Model,KS,W1,JSD,PSD_sim,ACF_sim\\n\")\n",
    "    for ch in [\"ECG\",\"Resp\",\"EDA\"]:\n",
    "        f.write(f\"{ch},Diffusion,{dist_diff[ch]['KS']},{dist_diff[ch]['W1']},{dist_diff[ch]['JSD']},{psd_diff[ch]['PSD_sim']},{acf_diff[ch]['ACF_sim']}\\n\")\n",
    "        f.write(f\"{ch},Baseline (Phase-Rand),{dist_base[ch]['KS']},{dist_base[ch]['W1']},{dist_base[ch]['JSD']},{psd_base[ch]['PSD_sim']},{acf_base[ch]['ACF_sim']}\\n\")\n",
    "\n",
    "# (Optional) save separate PSD/ACF overlays for the baseline\n",
    "psd_fig_diff = ev_bl.figure_psd_overlay(Xr, Xs)\n",
    "psd_fig_base = ev_bl.figure_psd_overlay(Xr, Xb)\n",
    "acf_fig_diff = ev_bl.figure_acf_overlay(Xr, Xs)\n",
    "acf_fig_base = ev_bl.figure_acf_overlay(Xr, Xb)\n",
    "\n",
    "print(\"Wrote Table 1 (+ baseline):\", table1_with_baseline)\n",
    "print(\"PSD fig (Diffusion):\", psd_fig_diff)\n",
    "print(\"PSD fig (Baseline) :\", psd_fig_base)\n",
    "print(\"ACF fig (Diffusion):\", acf_fig_diff)\n",
    "print(\"ACF fig (Baseline) :\", acf_fig_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "463d7b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[finalize] real RAW counts: {'baseline': 23, 'stress': 46, 'amusement': 77} majority= 77\n",
      "[finalize] baseline   -> kept 23 / 23; shape=(23, 5250, 3)\n",
      "[finalize] stress     -> kept 31 / 46; shape=(31, 5250, 3)\n",
      "[finalize] amusement  -> kept 3 / 77; shape=(3, 5250, 3)\n",
      "[FINAL RAW] Table 1: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_FINAL_A5_e40_BUNDLE\\RAW\\table1_distribution_psd_acf.csv\n",
      "[FINAL RAW] PSD fig: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_FINAL_A5_e40_BUNDLE\\RAW\\figure_psd_overlay.png\n",
      "[FINAL RAW] ACF fig: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_FINAL_A5_e40_BUNDLE\\RAW\\figure_acf_overlay.png\n",
      "[FINAL CLS] Table 2: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_FINAL_A5_e40_BUNDLE\\CLS\\table2_classifier_metrics.csv\n",
      "[FINAL summary] Real+Synth→Real: AUROC=0.9803  F1=0.1808\n"
     ]
    }
   ],
   "source": [
    "# --- choose your final setting here ---\n",
    "CHOSEN_FRAC = 0.05   # 0.05 for best F1; use 0.03 for best AUROC; 0.00 for middle ground\n",
    "EPOCHS = 40          # keep the locked classifier recipe; bump to 50 if you want\n",
    "\n",
    "# --- preconditions (already defined earlier in your notebook) ---\n",
    "assert 'RUN_TAG' in globals()\n",
    "assert 'ORDER' in globals()\n",
    "assert 'REAL_SPLIT_DIR' in globals() and Path(REAL_SPLIT_DIR).exists()\n",
    "assert 'SYN_DIR' in globals() and Path(SYN_DIR).exists()\n",
    "assert 'T_target' in globals()\n",
    "assert 'FS_ECG' in globals() and 'FS_LOW' in globals()\n",
    "from evaluation.wesad_eval import EvalConfig, WESADEvaluator  # uses your patched evaluator\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "def _empty_X(): return np.empty((0, T_target, 3), dtype=np.float32)\n",
    "def _empty_y(): return np.empty((0,), dtype=np.int32)\n",
    "\n",
    "# --- real RAW counts (for topping-up baseline/stress) ---\n",
    "real_counts = {}\n",
    "for name in ORDER:\n",
    "    with np.load(REAL_SPLIT_DIR / f\"real_{name}.npz\", allow_pickle=False) as d:\n",
    "        real_counts[name] = int(d[\"signals\"].shape[0])\n",
    "majority_n = max(real_counts.values())\n",
    "print(\"[finalize] real RAW counts:\", real_counts, \"majority=\", majority_n)\n",
    "\n",
    "# --- curate synth on RAW calibrated files for the chosen fraction ---\n",
    "tag = f\"FINAL_A{int(CHOSEN_FRAC*100)}_e{EPOCHS}\"\n",
    "CUR_SYN_RAW_DIR = SYN_DIR.with_name(SYN_DIR.name + f\"_{tag}\")\n",
    "CUR_SYN_RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name in ORDER:\n",
    "    src = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "    if not src.exists():\n",
    "        print(f\"[finalize] missing synth raw: {src} -> writing empty stub\")\n",
    "        np.savez_compressed(CUR_SYN_RAW_DIR / f\"synth_{name}_calibrated.npz\",\n",
    "                            signals=_empty_X(), labels=_empty_y())\n",
    "        continue\n",
    "\n",
    "    with np.load(src, allow_pickle=False) as d:\n",
    "        Xs = d[\"signals\"].astype(np.float32); ys = d[\"labels\"].astype(np.int32)\n",
    "\n",
    "    if name == \"amusement\":\n",
    "        k = int(np.floor(CHOSEN_FRAC * len(Xs)))\n",
    "    else:\n",
    "        need = max(0, majority_n - real_counts[name])\n",
    "        k = min(need, len(Xs))\n",
    "\n",
    "    if k > 0:\n",
    "        idx = rng.choice(len(Xs), size=k, replace=False)\n",
    "        X_keep = Xs[idx]; y_keep = ys[idx]\n",
    "    else:\n",
    "        X_keep = _empty_X(); y_keep = _empty_y()\n",
    "\n",
    "    if X_keep.shape[1] != T_target:  # safety\n",
    "        X_keep = _empty_X(); y_keep = _empty_y()\n",
    "\n",
    "    np.savez_compressed(CUR_SYN_RAW_DIR / f\"synth_{name}_calibrated.npz\",\n",
    "                        signals=X_keep, labels=y_keep)\n",
    "    print(f\"[finalize] {name:<10} -> kept {k} / {len(Xs)}; shape={X_keep.shape}\")\n",
    "\n",
    "# --- build file maps ---\n",
    "real_files = {k: REAL_SPLIT_DIR  / f\"real_{k}.npz\"              for k in ORDER}\n",
    "synth_files= {k: CUR_SYN_RAW_DIR / f\"synth_{k}_calibrated.npz\"  for k in ORDER}\n",
    "\n",
    "# --- where to store outputs ---\n",
    "FINAL_DIR = (REPO / \"results\" / \"evaluation\" / (RUN_TAG + f\"_{tag}_BUNDLE\"))\n",
    "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------ PASS 1: RAW (Table 1 + figures) ------------------\n",
    "cfg_raw = EvalConfig(\n",
    "    T_target=T_target, fs_ecg=FS_ECG, fs_low=FS_LOW,\n",
    "    results_dir=FINAL_DIR / \"RAW\",\n",
    "    run_classifier=False,\n",
    "    apply_eda_linfix=True,   # EDA linear mean/std correction for KS/W1/JSD only\n",
    "    psd_low_max_hz=1.5,\n",
    ")\n",
    "ev_raw = WESADEvaluator(cfg_raw)\n",
    "res_raw = ev_raw.evaluate_all(real_files, synth_files)\n",
    "print(\"[FINAL RAW] Table 1:\", res_raw[\"table1_csv\"])\n",
    "print(\"[FINAL RAW] PSD fig:\", res_raw[\"figure_psd\"])\n",
    "print(\"[FINAL RAW] ACF fig:\", res_raw[\"figure_acf\"])\n",
    "\n",
    "# ------------------ PASS 2: CLS (Table 2) ------------------\n",
    "cfg_cls = EvalConfig(\n",
    "    T_target=T_target, fs_ecg=FS_ECG, fs_low=FS_LOW,\n",
    "    results_dir=FINAL_DIR / \"CLS\",\n",
    "    run_classifier=True,\n",
    "    clf_labels=(0,1,2),\n",
    "    clf_epochs=EPOCHS,\n",
    "    clf_batch_size=64,\n",
    "    clf_seed=0,\n",
    "    clf_lr=1e-3,\n",
    "    clf_zscore=True,               # on-the-fly standardization from REAL stats\n",
    "    clf_class_weight=\"balanced\",   # inverse-frequency weighting\n",
    ")\n",
    "ev_cls = WESADEvaluator(cfg_cls)\n",
    "res_cls = ev_cls.evaluate_all(real_files, synth_files)\n",
    "print(\"[FINAL CLS] Table 2:\", res_cls[\"table2_csv\"])\n",
    "\n",
    "# --- tiny recap (prints the Real+Synth→Real row) ---\n",
    "t2 = Path(res_cls[\"table2_csv\"])\n",
    "df2 = pd.read_csv(t2)\n",
    "row = df2[df2[\"setting\"].astype(str).str.contains(\"Real\\\\+Synth\", regex=True, na=False)]\n",
    "if len(row):\n",
    "    auroc = float(row[\"AUROC\"].values[0]); f1 = float(row[\"F1\"].values[0])\n",
    "    print(f\"[FINAL summary] Real+Synth→Real: AUROC={auroc:.4f}  F1={f1:.4f}\")\n",
    "else:\n",
    "    print(\"[FINAL summary] Could not find Real+Synth→Real row in Table 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed58893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_PLOTS\\signal_snippets_overlay_clean.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Resolve paths & constants from your notebook (with safe fallbacks) ----\n",
    "REPO      = Path(globals().get(\"REPO\", r\"C:\\Users\\Joseph\\generative-health-models\"))\n",
    "ORDER     = list(globals().get(\"ORDER\", [\"baseline\",\"stress\",\"amusement\"]))\n",
    "REAL_DIR  = Path(globals().get(\"REAL_SPLIT_DIR\", REPO / \"results/evaluation/real_3class_split\"))\n",
    "SYN_DIR   = Path(globals().get(\"SYN_DIR\",      REPO / \"data/generated/3class_calibrated\"))\n",
    "RUN_TAG   = str(globals().get(\"RUN_TAG\",       \"signal_snippets\"))\n",
    "FS_ECG    = float(globals().get(\"FS_ECG\",      175.0))   # fused arrays at ECG rate\n",
    "SECONDS   = 8\n",
    "OUT_DIR   = REPO / \"results\" / \"evaluation\" / f\"{RUN_TAG}_PLOTS\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Display knobs (same look as before)\n",
    "ECG_DECIM  = 3\n",
    "REAL_STYLE = dict(color=\"#1f77b4\", lw=1.8, alpha=0.95, zorder=3, label=\"Real\")\n",
    "SYN_STYLE  = dict(color=\"#ff7f0e\", lw=1.4, alpha=0.85, ls=(0,(6,3)), zorder=2, label=\"Synth\")\n",
    "\n",
    "def _load_signals(npz_path: Path) -> np.ndarray:\n",
    "    with np.load(npz_path, allow_pickle=False) as d:\n",
    "        if \"signals\" in d:\n",
    "            return d[\"signals\"].astype(np.float32, copy=False)\n",
    "        # fallback to any (N,T,3)\n",
    "        for k in d.files:\n",
    "            arr = d[k]\n",
    "            if arr.ndim == 3 and arr.shape[-1] == 3:\n",
    "                return arr.astype(np.float32, copy=False)\n",
    "    raise ValueError(f\"No (N,T,3) signals found in {npz_path}\")\n",
    "\n",
    "def _pick_snippet(X: np.ndarray, seconds: int, fs: float):\n",
    "    N, T, C = X.shape\n",
    "    L = int(round(seconds * fs))\n",
    "    L = min(L, T)\n",
    "    # median-ECG-std window for \"typical\" sample\n",
    "    ecg_std = X[..., 0].std(axis=1)\n",
    "    mid_idx = int(np.argsort(ecg_std)[len(ecg_std)//2])\n",
    "    x = X[mid_idx]\n",
    "    s = max(0, (T - L)//2); e = s + L\n",
    "    return x[s:e]  # (L,3)\n",
    "\n",
    "# ---- Load snippets for each class (real & synth) ----\n",
    "snips_real, snips_synth = [], []\n",
    "T_ref = None\n",
    "for name in ORDER:\n",
    "    Xr = _load_signals(REAL_DIR / f\"real_{name}.npz\")\n",
    "    Xs_path = SYN_DIR / f\"synth_{name}_calibrated.npz\"\n",
    "    if T_ref is None: T_ref = Xr.shape[1]\n",
    "    if Xs_path.exists():\n",
    "        Xs = _load_signals(Xs_path)\n",
    "    else:\n",
    "        Xs = np.zeros((1, T_ref, 3), dtype=np.float32)  # empty placeholder\n",
    "    snips_real.append(_pick_snippet(Xr, SECONDS, FS_ECG))\n",
    "    snips_synth.append(_pick_snippet(Xs, SECONDS, FS_ECG))\n",
    "\n",
    "L = snips_real[0].shape[0]\n",
    "t = np.arange(L) / FS_ECG\n",
    "\n",
    "# ---- Robust, row-wise y-limits (percentiles) ----\n",
    "def _row_limits(channel, q_lo=1.0, q_hi=99.0, pad=0.06):\n",
    "    vals = np.concatenate([snips_real[i][:,channel] for i in range(len(ORDER))]\n",
    "                          + [snips_synth[i][:,channel] for i in range(len(ORDER))])\n",
    "    lo, hi = np.percentile(vals, [q_lo, q_hi])\n",
    "    if channel == 0:  # ECG symmetric looks nicer\n",
    "        m = max(abs(lo), abs(hi)); lo, hi = -m, m\n",
    "    span = hi - lo\n",
    "    return (lo - pad*span, hi + pad*span)\n",
    "\n",
    "ylims = {\n",
    "    0: _row_limits(0, 1, 99, 0.05),  # ECG\n",
    "    1: _row_limits(1, 1, 99, 0.12),  # Resp (more pad for tiny amplitudes)\n",
    "    2: _row_limits(2, 1, 99, 0.08),  # EDA\n",
    "}\n",
    "\n",
    "# ---- Figure with a dedicated header row for title + legend ----\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs  = fig.add_gridspec(nrows=4, ncols=3, height_ratios=[0.18, 1, 1, 1],\n",
    "                       hspace=0.75, wspace=0.42)\n",
    "\n",
    "# Header row (axis is hidden). Title + legend live here so they never overlap plots.\n",
    "hdr = fig.add_subplot(gs[0, :])\n",
    "hdr.axis(\"off\")\n",
    "hdr.set_title(\"Signal snippets — real vs. synth (per channel)\",\n",
    "              fontsize=14, fontweight=\"semibold\", pad=14)\n",
    "\n",
    "legend_handles = [\n",
    "    Line2D([0],[0], **REAL_STYLE),\n",
    "    Line2D([0],[0], **SYN_STYLE),\n",
    "]\n",
    "# Place legend centered in the header row\n",
    "hdr.legend(handles=legend_handles, loc=\"center\", ncol=2, frameon=False,\n",
    "           columnspacing=1.4, handlelength=2.8, handletextpad=0.6,\n",
    "           bbox_to_anchor=(0.5, 0.25))  # lower in the header strip, far from titles\n",
    "\n",
    "# Axes grid (3x3) for ECG/Resp/EDA × classes\n",
    "axes = {\n",
    "    \"ecg\":  [fig.add_subplot(gs[1, c]) for c in range(3)],\n",
    "    \"resp\": [fig.add_subplot(gs[2, c]) for c in range(3)],\n",
    "    \"eda\":  [fig.add_subplot(gs[3, c]) for c in range(3)],\n",
    "}\n",
    "row_labels = [\"ECG [a.u.]\", \"Resp [a.u.]\", \"EDA [a.u.]\"]\n",
    "\n",
    "for c_idx, name in enumerate(ORDER):\n",
    "    # Titles on the ECG row\n",
    "    ax0 = axes[\"ecg\"][c_idx]\n",
    "    ax0.set_title(name, fontsize=12, pad=6)\n",
    "\n",
    "    # ECG (decimated for clarity)\n",
    "    d = max(1, int(ECG_DECIM))\n",
    "    ax0.plot(t[::d], snips_real[c_idx][::d, 0], **REAL_STYLE)\n",
    "    ax0.plot(t[::d], snips_synth[c_idx][::d, 0], **SYN_STYLE)\n",
    "    ax0.set_ylim(*ylims[0]); ax0.grid(alpha=0.25)\n",
    "\n",
    "    # Resp (scientific offset; tiny variations visible)\n",
    "    ax1 = axes[\"resp\"][c_idx]\n",
    "    ax1.plot(t, snips_real[c_idx][:, 1], **REAL_STYLE)\n",
    "    ax1.plot(t, snips_synth[c_idx][:, 1], **SYN_STYLE)\n",
    "    ax1.set_ylim(*ylims[1]); ax1.grid(alpha=0.25)\n",
    "    fmt = ScalarFormatter(useMathText=True); fmt.set_powerlimits((-2, 2))\n",
    "    ax1.yaxis.set_major_formatter(fmt)\n",
    "    ax1.yaxis.get_offset_text().set_x(-0.06)\n",
    "\n",
    "    # EDA\n",
    "    ax2 = axes[\"eda\"][c_idx]\n",
    "    ax2.plot(t, snips_real[c_idx][:, 2], **REAL_STYLE)\n",
    "    ax2.plot(t, snips_synth[c_idx][:, 2], **SYN_STYLE)\n",
    "    ax2.set_ylim(*ylims[2]); ax2.grid(alpha=0.25)\n",
    "\n",
    "# Row y-labels & bottom x-labels\n",
    "for ax in axes[\"ecg\"]:  ax.set_ylabel(row_labels[0])\n",
    "for ax in axes[\"resp\"]: ax.set_ylabel(row_labels[1])\n",
    "for ax in axes[\"eda\"]:\n",
    "    ax.set_ylabel(row_labels[2])\n",
    "    ax.set_xlabel(\"time [s]\")\n",
    "\n",
    "# Tidy spines\n",
    "for ax in [*axes[\"ecg\"], *axes[\"resp\"], *axes[\"eda\"]]:\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Save\n",
    "out_path = OUT_DIR / \"signal_snippets_overlay_clean.png\"\n",
    "fig.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b0521ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PNG: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_PLOTS\\signal_snippets_overlay_clean.png\n",
      "Saved PDF: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_PLOTS\\signal_snippets_overlay_clean.pdf\n"
     ]
    }
   ],
   "source": [
    "out_path = OUT_DIR / \"signal_snippets_overlay_clean.png\"\n",
    "\n",
    "# Save PNG (raster)\n",
    "fig.savefig(out_path, dpi=220)\n",
    "\n",
    "# Save PDF (vector) — add this line\n",
    "fig.savefig(out_path.with_suffix(\".pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "plt.close(fig)\n",
    "print(\"Saved PNG:\", out_path)\n",
    "print(\"Saved PDF:\", out_path.with_suffix(\".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2ce917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[leak] real: (146, 5250, 3) synth: (146, 5250, 3)\n",
      "\n",
      "[leakage distances — summary]\n",
      "               group   n     median        p05        p95       mean       std\n",
      "real_val->real_train  43   1.245964   0.404575   2.216059   1.344767  0.714672\n",
      "   synth->real_train 146 256.582749 229.409842 354.734592 269.335578 45.808333\n",
      "Saved distances -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_distances.csv\n",
      "Saved summary   -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_summary.csv\n",
      "Saved plots -> c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_hist.png and c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_hist.pdf\n",
      "\n",
      "[quick read] median(synth→real) / median(real-val→real) = 205.93\n",
      "Rule of thumb: >>1 is good (no trivial copying). ≈1 or <1 → investigate further (e.g., DTW, embeddings).\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "# Resolve paths/vars from your notebook (safe defaults)\n",
    "REPO     = Path(globals().get(\"REPO\", r\"C:\\Users\\Joseph\\generative-health-models\"))\n",
    "ORDER    = list(globals().get(\"ORDER\", [\"baseline\", \"stress\", \"amusement\"]))\n",
    "REAL_DIR = Path(globals().get(\"REAL_SPLIT_DIR\", REPO / \"results/evaluation/real_3class_split\"))\n",
    "SYN_DIR  = Path(globals().get(\"SYN_DIR\", REPO / \"data/generated/3class_calibrated\"))\n",
    "RUN_TAG  = str(globals().get(\"RUN_TAG\", \"leakage_check\"))\n",
    "OUT_DIR  = REPO / \"results\" / \"evaluation\" / f\"{RUN_TAG}_LEAKAGE\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "def _load_signals(npz_path: Path) -> np.ndarray:\n",
    "    with np.load(npz_path, allow_pickle=False) as d:\n",
    "        if \"signals\" in d:\n",
    "            return d[\"signals\"].astype(np.float32, copy=False)\n",
    "        for k in d.files:\n",
    "            arr = d[k]\n",
    "            if arr.ndim == 3 and arr.shape[-1] == 3:\n",
    "                return arr.astype(np.float32, copy=False)\n",
    "    raise ValueError(f\"No (N,T,3) signals in {npz_path}\")\n",
    "\n",
    "def _stack_map(folder: Path, prefix: str) -> np.ndarray:\n",
    "    xs = []\n",
    "    for name in ORDER:\n",
    "        p = (folder / f\"{prefix}_{name}.npz\")\n",
    "        if not p.exists() and prefix.startswith(\"synth\"):\n",
    "            p = folder / f\"synth_{name}_calibrated.npz\"\n",
    "        if p.exists():\n",
    "            try:\n",
    "                x = _load_signals(p)\n",
    "                if len(x):\n",
    "                    xs.append(x)\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] skipping {p}: {e}\")\n",
    "        else:\n",
    "            print(f\"[warn] missing: {p}\")\n",
    "    if not xs:\n",
    "        raise RuntimeError(f\"No data found in {folder} with prefix='{prefix}'\")\n",
    "    return np.concatenate(xs, axis=0)\n",
    "\n",
    "def _features12_safe(X: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    12-D per-window features: for each channel c in {ECG,Resp,EDA}:\n",
    "      mean_c, std_c, skew_c, kurtosis_c(Fisher)\n",
    "    NaN-safe: when std ~ 0, set skew/kurt to 0.\n",
    "    \"\"\"\n",
    "    N, T, C = X.shape\n",
    "    feats = []\n",
    "    for c in range(3):\n",
    "        x = X[..., c].astype(np.float64)\n",
    "        m  = x.mean(axis=1)\n",
    "        xc = x - m[:, None]\n",
    "        v  = (xc * xc).mean(axis=1)                      # population variance\n",
    "        sd = np.sqrt(np.maximum(v, 0.0))\n",
    "        # guarded skew/kurt\n",
    "        m3 = (xc ** 3).mean(axis=1)\n",
    "        m4 = (xc ** 4).mean(axis=1)\n",
    "        sk = m3 / np.maximum(sd ** 3, eps)\n",
    "        ku = m4 / np.maximum(v ** 2, eps) - 3.0          # Fisher\n",
    "\n",
    "        const = sd < eps\n",
    "        sk[const] = 0.0\n",
    "        ku[const] = 0.0\n",
    "\n",
    "        feats.extend([m, sd, sk, ku])\n",
    "\n",
    "    F = np.stack(feats, axis=1).T    # (12, N)\n",
    "    F = F.T.astype(np.float32)       # (N, 12)\n",
    "    # Final guard: finite only\n",
    "    F = np.nan_to_num(F, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return F\n",
    "\n",
    "# 1) Load real & synth\n",
    "X_real_all  = _stack_map(REAL_DIR,  \"real\")\n",
    "X_synth_all = _stack_map(SYN_DIR,   \"synth\")\n",
    "print(\"[leak] real:\", X_real_all.shape, \"synth:\", X_synth_all.shape)\n",
    "\n",
    "# 2) Split real into train/val (control distances use val)\n",
    "idx = np.arange(len(X_real_all))\n",
    "rng.shuffle(idx)\n",
    "n_val = max(1, int(0.3 * len(idx)))\n",
    "val_idx, train_idx = idx[:n_val], idx[n_val:]\n",
    "X_real_tr, X_real_val = X_real_all[train_idx], X_real_all[val_idx]\n",
    "\n",
    "# 3) Features\n",
    "F_tr  = _features12_safe(X_real_tr)\n",
    "F_val = _features12_safe(X_real_val)\n",
    "F_syn = _features12_safe(X_synth_all)\n",
    "\n",
    "# 4) Standardize by REAL-TRAIN stats (and re-guard for finiteness)\n",
    "scaler = StandardScaler().fit(F_tr)\n",
    "Z_tr  = np.nan_to_num(scaler.transform(F_tr),  nan=0.0, posinf=0.0, neginf=0.0)\n",
    "Z_val = np.nan_to_num(scaler.transform(F_val), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "Z_syn = np.nan_to_num(scaler.transform(F_syn), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# 5) NN distances to real-train\n",
    "nn = NearestNeighbors(n_neighbors=1, metric=\"euclidean\")\n",
    "nn.fit(Z_tr)\n",
    "d_val = nn.kneighbors(Z_val, return_distance=True)[0].ravel()\n",
    "d_syn = nn.kneighbors(Z_syn, return_distance=True)[0].ravel()\n",
    "\n",
    "# 6) Save CSV + summary\n",
    "df_dist = pd.DataFrame({\n",
    "    \"group\": ([\"real_val->real_train\"] * len(d_val)) + ([\"synth->real_train\"] * len(d_syn)),\n",
    "    \"distance\": np.concatenate([d_val, d_syn])\n",
    "})\n",
    "csv_path = OUT_DIR / \"nn_leakage_distances.csv\"\n",
    "df_dist.to_csv(csv_path, index=False)\n",
    "\n",
    "def _summ(name, arr):\n",
    "    return {\n",
    "        \"group\": name,\n",
    "        \"n\": len(arr),\n",
    "        \"median\": float(np.median(arr)),\n",
    "        \"p05\": float(np.percentile(arr, 5)),\n",
    "        \"p95\": float(np.percentile(arr, 95)),\n",
    "        \"mean\": float(np.mean(arr)),\n",
    "        \"std\": float(np.std(arr, ddof=1)) if len(arr) > 1 else 0.0,\n",
    "    }\n",
    "\n",
    "stats = pd.DataFrame([\n",
    "    _summ(\"real_val->real_train\", d_val),\n",
    "    _summ(\"synth->real_train\", d_syn)\n",
    "])\n",
    "stats_path = OUT_DIR / \"nn_leakage_summary.csv\"\n",
    "stats.to_csv(stats_path, index=False)\n",
    "\n",
    "print(\"\\n[leakage distances — summary]\")\n",
    "print(stats.to_string(index=False))\n",
    "print(\"Saved distances ->\", csv_path)\n",
    "print(\"Saved summary   ->\", stats_path)\n",
    "\n",
    "# 7) Histogram overlay\n",
    "plt.figure(figsize=(8.6, 4.8))\n",
    "bins = \"auto\"\n",
    "plt.hist(d_val, bins=bins, alpha=0.55, label=f\"Real-val → Real-train (n={len(d_val)})\")\n",
    "plt.hist(d_syn, bins=bins, alpha=0.55, label=f\"Synth → Real-train (n={len(d_syn)})\")\n",
    "plt.axvline(np.median(d_val), color=\"#1f77b4\", lw=2, ls=\"--\", alpha=0.9)\n",
    "plt.axvline(np.median(d_syn), color=\"#ff7f0e\", lw=2, ls=\"--\", alpha=0.9)\n",
    "plt.xlabel(\"Nearest-neighbor distance in 12-D feature space (z-scored by real-train)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Sanity check for leakage: NN distances to real-train\")\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "png_path = OUT_DIR / \"nn_leakage_hist.png\"\n",
    "pdf_path = OUT_DIR / \"nn_leakage_hist.pdf\"\n",
    "plt.savefig(png_path, dpi=200)\n",
    "plt.savefig(pdf_path, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved plots ->\", png_path, \"and\", pdf_path)\n",
    "\n",
    "# 8) One-line interpretation\n",
    "ratio = np.median(d_syn) / max(np.median(d_val), 1e-9)\n",
    "print(f\"\\n[quick read] median(synth→real) / median(real-val→real) = {ratio:.2f}\")\n",
    "print(\"Rule of thumb: >>1 is good (no trivial copying). ≈1 or <1 → investigate further (e.g., DTW, embeddings).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f43248fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               group   n     median        p05        p95       mean       std\n",
      "real_val->real_train  43   1.245964   0.404575   2.216059   1.344767  0.714672\n",
      "   synth->real_train 146 256.582749 229.409842 354.734592 269.335578 45.808333\n",
      "\n",
      "Median distance ratio (synth/real-val): 205.9×  (>>1 implies no trivial copying)\n",
      "Saved: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_hist_full_plus_zoom.png and c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_hist_full_plus_zoom.pdf\n"
     ]
    }
   ],
   "source": [
    "assert 'd_val' in globals() and 'd_syn' in globals(), \"Run the leakage distances cell first.\"\n",
    "\n",
    "OUT = Path(globals().get('OUT_DIR', '.'))\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Quick stats for caption/report\n",
    "def _summ(arr):\n",
    "    return dict(n=len(arr),\n",
    "                median=float(np.median(arr)),\n",
    "                p05=float(np.percentile(arr,5)),\n",
    "                p95=float(np.percentile(arr,95)),\n",
    "                mean=float(np.mean(arr)),\n",
    "                std=float(np.std(arr, ddof=1)) if len(arr)>1 else 0.0)\n",
    "stats = pd.DataFrame([\n",
    "    {'group':'real_val->real_train', **_summ(d_val)},\n",
    "    {'group':'synth->real_train',    **_summ(d_syn)}\n",
    "])\n",
    "print(stats.to_string(index=False))\n",
    "ratio = np.median(d_syn) / max(np.median(d_val), 1e-9)\n",
    "print(f\"\\nMedian distance ratio (synth/real-val): {ratio:.1f}×  \"\n",
    "      \"(>>1 implies no trivial copying)\")\n",
    "\n",
    "# Shared bin edges so counts are comparable\n",
    "xmax = float(max(np.max(d_val), np.max(d_syn)))\n",
    "bins = np.linspace(0, xmax, 60)\n",
    "\n",
    "fig, (ax_full, ax_zoom) = plt.subplots(1, 2, figsize=(11.5, 4.6), sharey=True)\n",
    "\n",
    "# Full range\n",
    "ax_full.hist(d_val, bins=bins, alpha=0.55, label=f\"Real-val → Real-train (n={len(d_val)})\")\n",
    "ax_full.hist(d_syn, bins=bins, alpha=0.55, label=f\"Synth → Real-train (n={len(d_syn)})\")\n",
    "ax_full.axvline(np.median(d_val), color=\"#1f77b4\", lw=2, ls=\"--\")\n",
    "ax_full.axvline(np.median(d_syn), color=\"#ff7f0e\", lw=2, ls=\"--\")\n",
    "ax_full.set_title(\"Full range\")\n",
    "ax_full.set_xlabel(\"NN distance in 12-D (z-scored by real-train)\")\n",
    "ax_full.set_ylabel(\"count\")\n",
    "ax_full.legend(frameon=False, loc=\"upper right\")\n",
    "\n",
    "# Zoom panel (focus where blue lives)\n",
    "xzoom = max(10.0, float(np.percentile(d_val, 99)) * 1.5)\n",
    "ax_zoom.hist(d_val, bins=bins, alpha=0.55, label=\"Real-val → Real-train\")\n",
    "ax_zoom.hist(d_syn, bins=bins, alpha=0.25, label=\"Synth → Real-train\")  # lighter so blue stands out\n",
    "ax_zoom.axvline(np.median(d_val), color=\"#1f77b4\", lw=2, ls=\"--\")\n",
    "ax_zoom.set_xlim(0, xzoom)\n",
    "ax_zoom.set_title(\"Zoom near 0\")\n",
    "ax_zoom.set_xlabel(\"NN distance (zoomed)\")\n",
    "\n",
    "fig.suptitle(\"Sanity check for leakage: distances to nearest real-train window\", y=1.02, fontsize=13)\n",
    "fig.tight_layout()\n",
    "p_png = OUT / \"nn_leakage_hist_full_plus_zoom.png\"\n",
    "p_pdf = OUT / \"nn_leakage_hist_full_plus_zoom.pdf\"\n",
    "fig.savefig(p_png, dpi=220)\n",
    "fig.savefig(p_pdf, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", p_png, \"and\", p_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df4acf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy-rate@τ (τ = 1st pct of real-val): 0.00%  (τ=1.433, med_val=2.173, med_syn=33.200)\n",
      "              group   n    median       p05       p95\n",
      "real-val→real-train  43  2.173273  1.516632  3.532882\n",
      "   synth→real-train 146 33.199661 27.013119 33.528175\n",
      "Saved: c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_mahalanobis_single.png and c:\\Users\\Joseph\\generative-health-models\\results\\evaluation\\3class_run_ckpt_epoch_130_WEIGHTS_seed42_stE150_stL150_gE0.5_gL0.1_cal_LEAKAGE\\nn_leakage_mahalanobis_single.pdf\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "# Expect Z_tr, Z_val, Z_syn (12-D features) OR Xr_tr, Xr_val, Xs (N,T,3) to already exist.\n",
    "# If you only have Z_*, the code will use those directly.\n",
    "\n",
    "def _feat_12(X):\n",
    "    \"\"\"12-D per window: mean/std/skew/kurtosis per channel (ECG,Resp,EDA).\"\"\"\n",
    "    import scipy.stats as st\n",
    "    m  = X.mean(axis=1)\n",
    "    sd = X.std(axis=1)\n",
    "    sk = st.skew(X, axis=1, bias=False)\n",
    "    ku = st.kurtosis(X, axis=1, fisher=True, bias=False)  # excess kurtosis\n",
    "    F = np.concatenate([m, sd, sk, ku], axis=1).astype(np.float64)\n",
    "    return np.nan_to_num(F, copy=False, posinf=0.0, neginf=0.0)\n",
    "\n",
    "if 'Z_tr' not in globals():\n",
    "    assert all(k in globals() for k in ['Xr_tr','Xr_val','Xs']), \\\n",
    "        \"Provide either Z_tr/Z_val/Z_syn or Xr_tr/Xr_val/Xs.\"\n",
    "    Z_tr  = _feat_12(Xr_tr)\n",
    "    Z_val = _feat_12(Xr_val)\n",
    "    Z_syn = _feat_12(Xs)\n",
    "\n",
    "# Robust whitening on *train* only\n",
    "scaler = RobustScaler(quantile_range=(5,95)).fit(Z_tr)\n",
    "R_tr  = scaler.transform(Z_tr)\n",
    "R_val = scaler.transform(Z_val)\n",
    "R_syn = scaler.transform(Z_syn)\n",
    "\n",
    "# Optional: light clipping after robust scaling to mute remaining outliers\n",
    "R_tr  = np.clip(R_tr,  -8, 8)\n",
    "R_val = np.clip(R_val, -8, 8)\n",
    "R_syn = np.clip(R_syn, -8, 8)\n",
    "\n",
    "# Shrinkage covariance (stable inverse)\n",
    "lw  = LedoitWolf().fit(R_tr)\n",
    "mu  = lw.location_          # (12,)\n",
    "prec= lw.precision_         # (12,12)\n",
    "\n",
    "def _maha_rows(X, mu, prec):\n",
    "    D = X - mu\n",
    "    return np.sqrt(np.einsum('ni,ij,nj->n', D, prec, D))  # length-N\n",
    "\n",
    "d_val_m = _maha_rows(R_val, mu, prec)\n",
    "d_syn_m = _maha_rows(R_syn, mu, prec)\n",
    "\n",
    "# Copy-rate at a conservative threshold: τ = 1st percentile of real-val distances\n",
    "tau = float(np.percentile(d_val_m, 1.0))\n",
    "copy_rate = float((d_syn_m <= tau).mean())\n",
    "print(f\"Copy-rate@τ (τ = 1st pct of real-val): {copy_rate*100:.2f}%  \"\n",
    "      f\"(τ={tau:.3f}, med_val={np.median(d_val_m):.3f}, med_syn={np.median(d_syn_m):.3f})\")\n",
    "\n",
    "# Summary table for the report\n",
    "stats = pd.DataFrame([\n",
    "    {\"group\":\"real-val→real-train\", \"n\":len(d_val_m),\n",
    "     \"median\":np.median(d_val_m), \"p05\":np.percentile(d_val_m,5), \"p95\":np.percentile(d_val_m,95)},\n",
    "    {\"group\":\"synth→real-train\",    \"n\":len(d_syn_m),\n",
    "     \"median\":np.median(d_syn_m), \"p05\":np.percentile(d_syn_m,5), \"p95\":np.percentile(d_syn_m,95)},\n",
    "])\n",
    "print(stats.to_string(index=False))\n",
    "\n",
    "# Plot: full range + zoom near 0\n",
    "OUT = Path(globals().get('OUT_DIR', '.')); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "xmax = float(max(d_val_m.max(), d_syn_m.max()))\n",
    "bins = np.linspace(0, xmax, 48)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10.2, 4.8))\n",
    "\n",
    "# Histograms (overlaid)\n",
    "ax.hist(d_val_m, bins=bins, alpha=0.65, label=f\"Real-val → Real-train (n={len(d_val_m)})\")\n",
    "ax.hist(d_syn_m, bins=bins, alpha=0.65, label=f\"Synth → Real-train (n={len(d_syn_m)})\")\n",
    "\n",
    "# Medians (dashed)\n",
    "ax.axvline(np.median(d_val_m), color=\"#1f77b4\", lw=2.2, ls=\"--\")\n",
    "ax.axvline(np.median(d_syn_m), color=\"#ff7f0e\", lw=2.2, ls=\"--\")\n",
    "\n",
    "# Cosmetics\n",
    "ax.set_xlim(0, bins[-1])\n",
    "ax.set_xlabel(\"Mahalanobis distance (robust-whitened 12-D)\")\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_title(\"Sanity check for leakage: distance to nearest real-train window\")\n",
    "ax.spines[\"top\"].set_visible(False); ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "# Legend ABOVE the axes (outside the plotting area)\n",
    "handles, labels = ax.get_legend_handles_labels()   # from the hist(label=...) calls\n",
    "leg = fig.legend(handles, labels,\n",
    "                 loc=\"upper center\",\n",
    "                 bbox_to_anchor=(0.5, 0.80),   # ← move DOWN by lowering this (e.g., 0.92–0.90)\n",
    "                 bbox_transform=fig.transFigure,  # explicit: coordinates are figure-relative\n",
    "                 ncol=2, frameon=False)\n",
    "\n",
    "# Make room for the legend\n",
    "fig.subplots_adjust(top=0.86)\n",
    "\n",
    "# Save\n",
    "p_png = OUT / \"nn_leakage_mahalanobis_single.png\"\n",
    "p_pdf = OUT / \"nn_leakage_mahalanobis_single.pdf\"\n",
    "fig.savefig(p_png, dpi=220, bbox_inches=\"tight\")\n",
    "fig.savefig(p_pdf, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", p_png, \"and\", p_pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
