{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32b6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import joblib\n",
    "import warnings\n",
    "import random \n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410f2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Deterministic CuDNN kernels ― reproducibility > speed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9faad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wesad_subject(pkl_path):\n",
    "    pkl_path = Path(pkl_path)\n",
    "    if not pkl_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {pkl_path}\")\n",
    "    with pkl_path.open(\"rb\") as f:\n",
    "        # encoding='latin1' is the safe choice for WESAD pickles\n",
    "        return pickle.load(f, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f696bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏠 Project Root: C:\\Users\\Joseph\\generative-health-models\n",
      "\n",
      "🏗️ Verifying project structure:\n",
      "  ✅ data\\raw\\wesad\n",
      "  ✅ data\\processed\n",
      "  ✅ data\\synthetic\n",
      "  ✅ models\\tc_multigan\n",
      "  ✅ results\\figures\n",
      "\n",
      "📁 Found 15 WESAD subject files:\n",
      "  1. S10.pkl\n",
      "  2. S11.pkl\n",
      "  3. S13.pkl\n",
      "  4. S14.pkl\n",
      "  5. S15.pkl\n",
      "     ... and 10 more files\n",
      "✅ Ready to process 15 subjects\n",
      "✅ Subject sanity check passed (15 subjects: S2–S11, S13–S17).\n",
      "\n",
      "🔍 Loaded S10.pkl\n",
      "   Top-level keys: ['signal', 'label', 'subject']\n",
      "   Signal keys: ['chest', 'wrist']\n",
      "   Chest channels: ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
      "\n",
      "📝 Manifest written to: C:\\Users\\Joseph\\generative-health-models\\data\\processed\\wesad_manifest.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── 1) Project root ─────────────────────────────────────────────────────────────\n",
    "project_root = Path(r\"C:\\Users\\Joseph\\generative-health-models\").resolve()\n",
    "print(f\"🏠 Project Root: {project_root}\")\n",
    "\n",
    "# ── 2) Ensure expected directories exist ───────────────────────────────────────\n",
    "required_dirs = [\n",
    "    project_root / \"data\" / \"raw\" / \"wesad\",\n",
    "    project_root / \"data\" / \"processed\",\n",
    "    project_root / \"data\" / \"synthetic\",\n",
    "    project_root / \"models\" / \"tc_multigan\",\n",
    "    project_root / \"results\" / \"figures\",\n",
    "]\n",
    "\n",
    "print(\"\\n🏗️ Verifying project structure:\")\n",
    "for d in required_dirs:\n",
    "    if d.exists():\n",
    "        print(f\"  ✅ {d.relative_to(project_root)}\")\n",
    "    else:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"  📁 Created: {d}\")\n",
    "\n",
    "# ── 3) Discover WESAD subject .pkl files (sorted, filtered) ────────────────────\n",
    "wesad_path = project_root / \"data\" / \"raw\" / \"wesad\"\n",
    "subject_files = sorted(\n",
    "    p for p in wesad_path.rglob(\"*.pkl\") if re.match(r\"S\\d+\\.pkl$\", p.name)\n",
    ")\n",
    "\n",
    "print(f\"\\n📁 Found {len(subject_files)} WESAD subject files:\")\n",
    "for i, p in enumerate(subject_files[:5], 1):\n",
    "    print(f\"  {i}. {p.name}\")\n",
    "if len(subject_files) > 5:\n",
    "    print(f\"     ... and {len(subject_files) - 5} more files\")\n",
    "\n",
    "if not subject_files:\n",
    "    print(\"❌ No WESAD files found! Please check data download.\")\n",
    "else:\n",
    "    print(f\"✅ Ready to process {len(subject_files)} subjects\")\n",
    "\n",
    "# ── 3b) Subject sanity check (expected S2–S17 excluding S12) ───────────────────\n",
    "expected = [f\"S{i}\" for i in range(2, 18) if i != 12]   # 15 subjects\n",
    "ids = [re.match(r\"(S\\d+)\", p.name).group(1) for p in subject_files]\n",
    "\n",
    "missing    = sorted(set(expected) - set(ids))\n",
    "unexpected = sorted(set(ids) - set(expected))\n",
    "dups       = sorted([k for k, c in Counter(ids).items() if c > 1])\n",
    "\n",
    "if missing or unexpected or dups:\n",
    "    print(\"⚠️ Subject sanity check failed:\")\n",
    "    if missing:    print(\"  Missing:\", missing)\n",
    "    if unexpected: print(\"  Unexpected:\", unexpected)\n",
    "    if dups:       print(\"  Duplicates:\", dups)\n",
    "    # Optional hard stop:\n",
    "    # raise ValueError(\"Subject list mismatch\")\n",
    "else:\n",
    "    print(\"✅ Subject sanity check passed (15 subjects: S2–S11, S13–S17).\")\n",
    "\n",
    "# ── 4) Quick sanity‑load one subject using your loader ─────────────────────────\n",
    "# (Helps catch encoding/path issues early.)\n",
    "if subject_files:\n",
    "    try:\n",
    "        sample_path = subject_files[0]\n",
    "        data = load_wesad_subject(sample_path)  # <-- your function\n",
    "        print(f\"\\n🔍 Loaded {sample_path.name}\")\n",
    "\n",
    "        # Brief structure peek (optional but helpful)\n",
    "        top_keys = list(data.keys())\n",
    "        print(\"   Top-level keys:\", top_keys)\n",
    "        if \"signal\" in data and isinstance(data[\"signal\"], dict):\n",
    "            sig_keys = list(data[\"signal\"].keys())\n",
    "            print(\"   Signal keys:\", sig_keys)\n",
    "            if \"chest\" in data[\"signal\"]:\n",
    "                chest_keys = list(data[\"signal\"][\"chest\"].keys())\n",
    "                print(\"   Chest channels:\", chest_keys)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to load {sample_path.name}: {e}\")\n",
    "\n",
    "# ── 5) (Optional) Write a small manifest for traceability ──────────────────────\n",
    "manifest = [\n",
    "    {\"subject\": re.search(r\"S\\d+\", p.name).group(0), \"path\": str(p)}\n",
    "    for p in subject_files\n",
    "]\n",
    "manifest_path = project_root / \"data\" / \"processed\" / \"wesad_manifest.json\"\n",
    "manifest_path.write_text(json.dumps(manifest, indent=2))\n",
    "print(f\"\\n📝 Manifest written to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1415ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 LOSO splits saved to C:\\Users\\Joseph\\generative-health-models\\data\\processed\\wesad_loso_splits.json\n",
      "↳ Total folds: 15 (should be 15)\n",
      "↳ Val subjects per fold: 2\n",
      "↳ Example fold 1: {'train': ['S2', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S11', 'S13', 'S15', 'S16', 'S17'], 'val': ['S3', 'S14'], 'test': ['S10']}\n"
     ]
    }
   ],
   "source": [
    "# Ensure deterministic numeric order (S2, S3, …, S17)\n",
    "def subject_sort_key(p):\n",
    "    return int(re.search(r\"S(\\d+)\", Path(p).stem).group(1))\n",
    "subject_files = sorted(subject_files, key=subject_sort_key)\n",
    "\n",
    "subjects = [Path(p).stem for p in subject_files]  # ['S2','S3',...]\n",
    "groups   = subjects                                # group == subject\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "folds = []\n",
    "\n",
    "# Separate seed for splits; fixed val size per fold (set to 0 to disable val)\n",
    "SPLIT_SEED   = 42\n",
    "VAL_SUBJECTS = 2\n",
    "rng = np.random.default_rng(SPLIT_SEED)\n",
    "\n",
    "for train_idx, test_idx in logo.split(subject_files, groups=groups):\n",
    "    train_files = [subject_files[i] for i in train_idx]\n",
    "    test_files  = [subject_files[i] for i in test_idx]\n",
    "\n",
    "    # Pick validation subjects from the training pool (deterministic)\n",
    "    val_k = min(VAL_SUBJECTS, len(train_files))\n",
    "    if val_k > 0:\n",
    "        val_idx = rng.choice(len(train_files), size=val_k, replace=False)\n",
    "        val_idx_set = set(int(i) for i in val_idx)\n",
    "        val_files = [train_files[i] for i in sorted(val_idx_set)]\n",
    "        train_files_final = [f for i, f in enumerate(train_files) if i not in val_idx_set]\n",
    "    else:\n",
    "        val_files = []\n",
    "        train_files_final = train_files\n",
    "\n",
    "    folds.append({\n",
    "        \"train\": [Path(f).stem for f in train_files_final],\n",
    "        \"val\":   [Path(f).stem for f in val_files],\n",
    "        \"test\":  [Path(f).stem for f in test_files],   # exactly one subject\n",
    "    })\n",
    "\n",
    "# Assert full test coverage (each subject appears once as test)\n",
    "test_counts = Counter(s for f in folds for s in f[\"test\"])\n",
    "assert len(test_counts) == len(subjects) and all(c == 1 for c in test_counts.values()), \\\n",
    "    \"Each subject must appear exactly once in the test set across folds.\"\n",
    "\n",
    "# Persist folds\n",
    "splits_path = project_root / \"data\" / \"processed\" / \"wesad_loso_splits.json\"\n",
    "splits_path.write_text(json.dumps(folds, indent=2))\n",
    "print(f\"📝 LOSO splits saved to {splits_path}\")\n",
    "print(f\"↳ Total folds: {len(folds)} (should be {len(subject_files)})\")\n",
    "print(f\"↳ Val subjects per fold: {VAL_SUBJECTS}\")\n",
    "print(\"↳ Example fold 1:\", folds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d646e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mask_interpolate(m2, mask_ratio=0.05, *, rng=None, protect_endpoints=True):\n",
    "    \"\"\"\n",
    "    TRAINING-ONLY augmentation: randomly remove time points and linearly re-fill.\n",
    "    Do NOT use on validation/test.\n",
    "    \"\"\"\n",
    "    x = np.asarray(m2, dtype=np.float32)\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, None]\n",
    "    T = x.shape[0]\n",
    "    if mask_ratio <= 0 or T < 3:\n",
    "        return x\n",
    "\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    t = np.arange(T)\n",
    "    pool = np.arange(1, T-1) if (protect_endpoints and T > 2) else t\n",
    "    k = min(int(round(T*mask_ratio)), pool.size)\n",
    "    if k == 0:\n",
    "        return x\n",
    "\n",
    "    drop_idx = np.sort(rng.choice(pool, size=k, replace=False))\n",
    "    keep_idx = np.setdiff1d(t, drop_idx)\n",
    "    lin = interp1d(keep_idx, x[keep_idx], axis=0, kind=\"linear\",\n",
    "                   bounds_error=False, fill_value=\"extrapolate\")\n",
    "    return lin(t).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01ab20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chest_data_correct(subject_data, \n",
    "                               channels=(\"ECG\",\"EDA\",\"RESP\"), \n",
    "                               strict=True, \n",
    "                               verbose=True, \n",
    "                               as_float32=True):\n",
    "    \"\"\"\n",
    "    Extract selected chest channels from WESAD and stack to (N, C).\n",
    "    channels: tuple of channel names in desired order.\n",
    "              Valid names include: 'ECG','EDA','EMG','RESP','TEMP','ACC' (ACC is Nx3; not stacked here)\n",
    "    strict:   raise if lengths mismatch; if False, truncate to the shortest length.\n",
    "    \"\"\"\n",
    "    # 1) Access chest dict and labels\n",
    "    chest = subject_data[\"signal\"][\"chest\"]\n",
    "    labels = np.asarray(subject_data[\"label\"]).reshape(-1)\n",
    "\n",
    "    # 2) Normalize key capitalization found in WESAD pickles\n",
    "    #    (Resp→RESP, Temp→TEMP) while not overwriting if already present\n",
    "    rename = {\"Resp\": \"RESP\", \"Temp\": \"TEMP\"}\n",
    "    for old, new in rename.items():\n",
    "        if old in chest and new not in chest:\n",
    "            chest[new] = chest.pop(old)\n",
    "\n",
    "    # 3) Gather requested channels in a fixed order\n",
    "    arrays = []\n",
    "    present = set(chest.keys())\n",
    "    for ch in channels:\n",
    "        if ch not in chest:\n",
    "            # try case-insensitive match\n",
    "            ci = {k.upper(): k for k in chest.keys()}\n",
    "            if ch.upper() in ci:\n",
    "                key = ci[ch.upper()]\n",
    "            else:\n",
    "                raise KeyError(f\"Channel '{ch}' not found. Available: {sorted(present)}\")\n",
    "        else:\n",
    "            key = ch\n",
    "\n",
    "        x = np.asarray(chest[key])\n",
    "        # Expect (N,1) or (N,), enforce (N,1)\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        elif x.ndim == 2 and x.shape[1] != 1:\n",
    "            raise ValueError(f\"Channel '{ch}' expected shape (N,1) or (N,), got {x.shape}\")\n",
    "        elif x.ndim > 2:\n",
    "            raise ValueError(f\"Channel '{ch}' has invalid ndim={x.ndim}\")\n",
    "\n",
    "        arrays.append(x)\n",
    "\n",
    "    # 4) Length checks (signals vs labels)\n",
    "    lens = [a.shape[0] for a in arrays] + [labels.shape[0]]\n",
    "    if len(set(lens)) != 1:\n",
    "        if strict:\n",
    "            raise ValueError(f\"Length mismatch across channels/labels: {lens}\")\n",
    "        # else truncate to shortest\n",
    "        n = min(lens)\n",
    "        arrays = [a[:n] for a in arrays]\n",
    "        labels = labels[:n]\n",
    "    else:\n",
    "        n = lens[0]\n",
    "\n",
    "    # 5) Stack and cast\n",
    "    X = np.concatenate(arrays, axis=1)\n",
    "    if as_float32:\n",
    "        X = X.astype(np.float32, copy=False)\n",
    "\n",
    "    if verbose:\n",
    "        ch_list = \", \".join(channels)\n",
    "        print(f\"📊 Extracted channels ({ch_list}) → X: {X.shape}, labels: {labels.shape}\")\n",
    "\n",
    "    return X, labels, list(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd0b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing data extraction on: S2 (S2.pkl)\n",
      "📊 Extracted channels (ECG, EDA, RESP) → X: (4255300, 3), labels: (4255300,)\n",
      "   Label codes & counts: {0: 2142701, 1: 800800, 2: 430500, 3: 253400, 4: 537599, 6: 45500, 7: 44800}\n",
      "   Duration: 101.3 minutes at fs=700 Hz\n",
      "   Channels order: ['ECG', 'EDA', 'RESP']\n",
      "✅ Data extraction test successful!\n"
     ]
    }
   ],
   "source": [
    "def test_data_extraction(channels=(\"ECG\",\"EDA\",\"RESP\"), fs=700):\n",
    "    \"\"\"Test data extraction on the first subject with strict sanity checks.\"\"\"\n",
    "    if not subject_files:\n",
    "        print(\"❌ No subject files available for testing\")\n",
    "        return False\n",
    "\n",
    "    p = subject_files[0]\n",
    "    sid = Path(p).stem\n",
    "    print(f\"🧪 Testing data extraction on: {sid} ({Path(p).name})\")\n",
    "\n",
    "    try:\n",
    "        # Use the standardized loader\n",
    "        data = load_wesad_subject(p)\n",
    "\n",
    "        # Extract in a fixed channel order; your function returns (X, y, channels)\n",
    "        X, y, ch = extract_chest_data_correct(\n",
    "            data,\n",
    "            channels=channels,\n",
    "            strict=True,\n",
    "            verbose=True,\n",
    "            as_float32=True\n",
    "        )\n",
    "\n",
    "        # ----- Hard checks (fail fast on violations) ---------------------------\n",
    "        assert X.ndim == 2, f\"Expected 2D array (N,C), got ndim={X.ndim}\"\n",
    "        assert X.shape[1] == len(ch), f\"C mismatch: X has {X.shape[1]} cols, channels={len(ch)}\"\n",
    "        assert X.dtype == np.float32, f\"Expected float32, got {X.dtype}\"\n",
    "        assert len(X) == len(y), f\"Length mismatch: X={len(X)} vs labels={len(y)}\"\n",
    "        y = np.asarray(y).astype(np.int64, copy=False)\n",
    "\n",
    "        n_nans = int(np.isnan(X).sum())\n",
    "        assert n_nans == 0, f\"Found {n_nans} NaNs in X\"\n",
    "\n",
    "        # Label summary (helps confirm codes present)\n",
    "        uniq, cnt = np.unique(y, return_counts=True)\n",
    "        label_summary = {int(k): int(v) for k, v in zip(uniq, cnt)}\n",
    "        print(f\"   Label codes & counts: {label_summary}\")\n",
    "\n",
    "        minutes = X.shape[0] / fs / 60.0\n",
    "        print(f\"   Duration: {minutes:.1f} minutes at fs={fs} Hz\")\n",
    "        print(f\"   Channels order: {ch}\")\n",
    "\n",
    "        print(\"✅ Data extraction test successful!\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "extraction_success = test_data_extraction()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52526536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def butter_lowpass_zerophase(x, fs, cutoff_hz, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    sos = butter(order, cutoff_hz/nyq, btype=\"low\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, x.astype(np.float64)).astype(np.float32)\n",
    "\n",
    "def butter_highpass_zerophase(x, fs, cutoff_hz, order=2):\n",
    "    nyq = fs * 0.5\n",
    "    sos = butter(order, cutoff_hz/nyq, btype=\"high\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, x.astype(np.float64)).astype(np.float32)\n",
    "\n",
    "def butter_bandpass_zerophase(x, fs, low_hz, high_hz, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    sos = butter(order, [low_hz/nyq, high_hz/nyq], btype=\"band\", output=\"sos\")\n",
    "    return sosfiltfilt(sos, x.astype(np.float64)).astype(np.float32)\n",
    "\n",
    "def make_label_mask(labels, fs, valid_labels, transition_pad_s=5.0, min_valid_run_s=30.0):\n",
    "    y = np.asarray(labels)\n",
    "    n = y.size\n",
    "    keep = np.isin(y, np.array(list(valid_labels)))\n",
    "    # remove ±pad around transitions\n",
    "    pad = int(round(transition_pad_s*fs))\n",
    "    if pad > 0 and n > 1:\n",
    "        chg = np.flatnonzero(np.diff(y) != 0)\n",
    "        if chg.size:\n",
    "            edge = np.zeros(n, dtype=bool)\n",
    "            for i in chg:\n",
    "                lo = max(0, i - pad + 1); hi = min(n, i + pad + 1)\n",
    "                edge[lo:hi] = True\n",
    "            keep &= ~edge\n",
    "    # drop short runs\n",
    "    min_len = int(round(min_valid_run_s*fs))\n",
    "    if min_len > 1:\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            if keep[i]:\n",
    "                j = i+1\n",
    "                while j < n and keep[j]:\n",
    "                    j += 1\n",
    "                if (j - i) < min_len:\n",
    "                    keep[i:j] = False\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "    return keep\n",
    "\n",
    "def block_mode_downsample(labels, in_len, factor=None, n_out=None):\n",
    "    \"\"\"Mode of label in each block during downsampling.\"\"\"\n",
    "    y = np.asarray(labels)\n",
    "    if factor is None and n_out is None:\n",
    "        raise ValueError(\"Provide factor or n_out\")\n",
    "    if factor is None:\n",
    "        factor = int(np.floor(in_len / n_out))\n",
    "    n_blocks = int(np.floor(in_len / factor))\n",
    "    out = np.empty(n_blocks, dtype=y.dtype)\n",
    "    for i in range(n_blocks):\n",
    "        block = y[i*factor:(i+1)*factor]\n",
    "        vals, counts = np.unique(block, return_counts=True)\n",
    "        out[i] = vals[np.argmax(counts)]\n",
    "    return out\n",
    "\n",
    "# --- label config (4-class; change to {1,2,3} if you want 3-class) ---\n",
    "LABEL_MAP = {1:\"baseline\", 2:\"stress\", 3:\"amusement\", 4:\"meditation\"}  # keep\n",
    "VALID     = sorted(LABEL_MAP.keys())  # [1,2,3,4]\n",
    "COND      = {lab:i for i, lab in enumerate(VALID)}  # {1:0,2:1,3:2,4:3}\n",
    "\n",
    "\n",
    "def _impute_linear_series(col):\n",
    "    # col: 1D array\n",
    "    col = col.astype(np.float32, copy=False)\n",
    "    n = col.shape[0]\n",
    "    mask = np.isfinite(col)\n",
    "    if mask.all():\n",
    "        return col\n",
    "    if not mask.any():\n",
    "        return np.zeros_like(col)             # last-resort fallback\n",
    "    if mask.sum() == 1:\n",
    "        col[~mask] = col[mask][0]             # fill with single value\n",
    "        return col\n",
    "    idx = np.arange(n, dtype=np.float32)\n",
    "    col[~mask] = np.interp(idx[~mask], idx[mask], col[mask])\n",
    "    return col\n",
    "\n",
    "def preprocess_single_subject(subject_file, target_rate=4, original_rate=700, channels=(\"ECG\",\"EDA\",\"RESP\"),\n",
    "                              transition_pad_s=5.0, min_valid_run_s=30.0, verbose=True,\n",
    "                              eda_hp_cutoff=0.03, eda_hp_order=2, eda_robust=False):\n",
    "    sid = Path(subject_file).stem\n",
    "    if verbose:\n",
    "        print(f\"\\n📂 Processing: {sid}\")\n",
    "\n",
    "    try:\n",
    "        # 1) Load + extract\n",
    "        data = load_wesad_subject(subject_file)\n",
    "        X, y, ch = extract_chest_data_correct(data, channels=channels, strict=True, verbose=False)\n",
    "        n = len(X)\n",
    "        if verbose:\n",
    "            print(f\"  Original: X {X.shape}, y {y.shape} (~{n/original_rate/60:.1f} min)\")\n",
    "\n",
    "        # 2) Channel-specific filtering at original fs\n",
    "        Xf = np.empty_like(X, dtype=np.float32)\n",
    "        for j, name in enumerate(ch):\n",
    "            if name.upper() == \"ECG\":\n",
    "                Xf[:, j] = butter_bandpass_zerophase(X[:, j], original_rate, low_hz=0.5, high_hz=40.0)\n",
    "            elif name.upper() == \"EDA\":\n",
    "                Xf[:, j] = butter_lowpass_zerophase(X[:, j], original_rate, cutoff_hz=5.0)\n",
    "            elif name.upper() in (\"RESP\",\"RESPIRATION\"):\n",
    "                Xf[:, j] = butter_bandpass_zerophase(X[:, j], original_rate, low_hz=0.1, high_hz=0.35)\n",
    "            else:\n",
    "                Xf[:, j] = X[:, j]\n",
    "\n",
    "        # 3) Label-based mask\n",
    "        keep = make_label_mask(y, fs=original_rate, valid_labels=VALID,\n",
    "                               transition_pad_s=transition_pad_s, min_valid_run_s=min_valid_run_s)\n",
    "        Xk = Xf[keep]; yk = y[keep]\n",
    "        if verbose:\n",
    "            uniq, cnt = np.unique(yk, return_counts=True)\n",
    "            print(f\"  After mask (orig fs): {Xk.shape}, label dist: {dict(zip(uniq.tolist(), cnt.tolist()))}\")\n",
    "\n",
    "        # 4) Multi-rate\n",
    "        TARGET_LOW, TARGET_ECG = target_rate, 175\n",
    "        fac_low = original_rate // TARGET_LOW     # 175\n",
    "        fac_ecg = original_rate // TARGET_ECG     # 4\n",
    "\n",
    "        n_keep = (len(yk) // np.lcm(fac_low, fac_ecg)) * np.lcm(fac_low, fac_ecg)\n",
    "        Xk, yk = Xk[:n_keep], yk[:n_keep]\n",
    "\n",
    "        idx_ecg   = ch.index(\"ECG\")\n",
    "        idx_other = [j for j in range(len(ch)) if j != idx_ecg]\n",
    "\n",
    "        # EDA + RESP @ 4 Hz\n",
    "        Xd_low = signal.decimate(Xk[:, idx_other], fac_low, ftype=\"fir\", axis=0, zero_phase=True)\n",
    "\n",
    "        # Enforce [EDA, RESP] order\n",
    "        cols_low = [ch[j] for j in idx_other]\n",
    "        assert \"EDA\" in cols_low and \"RESP\" in cols_low, f\"Low-rate cols missing: {cols_low}\"\n",
    "        perm = [cols_low.index(\"EDA\"), cols_low.index(\"RESP\")]\n",
    "        Xd_low = Xd_low[:, perm]\n",
    "\n",
    "        # EDA high-pass @ 4 Hz\n",
    "        if verbose:\n",
    "            from scipy.signal import welch\n",
    "            nps = min(len(Xd_low), 1024)\n",
    "            f0, P0 = welch(Xd_low[:,0], fs=TARGET_LOW, nperseg=nps)\n",
    "            print(f\"EDA BEFORE HP peak ~ {f0[P0.argmax()]:.4f} Hz\")\n",
    "\n",
    "        if eda_hp_cutoff and eda_hp_cutoff > 0:\n",
    "            Xd_low[:,0] = butter_highpass_zerophase(Xd_low[:,0], fs=TARGET_LOW,\n",
    "                                                    cutoff_hz=eda_hp_cutoff, order=eda_hp_order)\n",
    "\n",
    "        if verbose:\n",
    "            f1, P1 = welch(Xd_low[:,0], fs=TARGET_LOW, nperseg=nps)\n",
    "            print(f\"EDA AFTER  HP peak ~ {f1[P1.argmax()]:.4f} Hz\")\n",
    "\n",
    "        # Optional robust per-subject scale\n",
    "        if eda_robust:\n",
    "            def robust_z_1d(x):\n",
    "                med = np.nanmedian(x)\n",
    "                iqr = np.nanpercentile(x,75) - np.nanpercentile(x,25)\n",
    "                scale = max(iqr/1.349, 1e-6)\n",
    "                return (x - med) / scale\n",
    "            Xd_low[:,0] = robust_z_1d(Xd_low[:,0])\n",
    "\n",
    "        # ECG @ 175 Hz\n",
    "        Xd_ecg = signal.decimate(Xk[:, idx_ecg], fac_ecg, ftype=\"fir\", axis=0, zero_phase=True)[:, None]\n",
    "\n",
    "        # Labels\n",
    "        yd_low = block_mode_downsample(yk, in_len=n_keep, factor=fac_low)\n",
    "        yd_ecg = block_mode_downsample(yk, in_len=n_keep, factor=fac_ecg)\n",
    "\n",
    "        # Impute NaNs (defensive)\n",
    "        for arr in (Xd_low, Xd_ecg):\n",
    "            bad = ~np.isfinite(arr)\n",
    "            if bad.any():\n",
    "                for c in range(arr.shape[1]):\n",
    "                    if bad[:, c].any():\n",
    "                        arr[:, c] = _impute_linear_series(arr[:, c])\n",
    "\n",
    "        # Sanity\n",
    "        assert len(Xd_low) == len(yd_low)\n",
    "        assert len(Xd_ecg) == len(yd_ecg)\n",
    "        assert abs(len(Xd_low)/TARGET_LOW - len(Xd_ecg)/TARGET_ECG) < 1e-6\n",
    "\n",
    "        # One-hot conditioning\n",
    "        y_cond_low = np.vectorize(COND.get)(yd_low)\n",
    "        K = len(COND)\n",
    "        m1_low = np.zeros((len(y_cond_low), K), dtype=np.float32)\n",
    "        m1_low[np.arange(len(y_cond_low)), y_cond_low] = 1.0\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  ➜ X_low {Xd_low.shape} @ {TARGET_LOW} Hz | X_ecg {Xd_ecg.shape} @ {TARGET_ECG} Hz | m1 {m1_low.shape}\")\n",
    "\n",
    "        return {\n",
    "            \"subject_id\": sid,\n",
    "            \"channels_low\": [\"EDA\",\"RESP\"],\n",
    "            \"channels_ecg\": [\"ECG\"],\n",
    "            \"fs_low\": TARGET_LOW,\n",
    "            \"fs_ecg\": TARGET_ECG,\n",
    "            \"m2_low\":   Xd_low.astype(np.float32, copy=False),\n",
    "            \"m2_ecg\":   Xd_ecg.astype(np.float32, copy=False),\n",
    "            \"labels_low\": yd_low.astype(np.int64, copy=False),\n",
    "            \"labels_ecg\": yd_ecg.astype(np.int64, copy=False),\n",
    "            \"m1_low\":   m1_low,\n",
    "            \"duration_minutes\": len(Xd_low) / TARGET_LOW / 60.0,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error processing {sid}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975a61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Processing: S2\n",
      "  Original: X (4255300, 3), y (4255300,) (~101.3 min)\n",
      "  After mask (orig fs): (1987299, 3), label dist: {1: 793800, 2: 423500, 3: 246400, 4: 523599}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11352, 2) @ 4 Hz | X_ecg (496650, 1) @ 175 Hz | m1 (11352, 4)\n",
      "\n",
      "— Summary —\n",
      "Subject: S2\n",
      "fs_low : 4 Hz   | fs_ecg : 175 Hz\n",
      "m2_low : (11352, 2)\n",
      "m2_ecg : (496650, 1)\n",
      "m1_low : (11352, 4)\n",
      "Label counts (low-rate): {1: 4536, 2: 2420, 3: 1408, 4: 2988}\n"
     ]
    }
   ],
   "source": [
    "# Pick the first discovered file\n",
    "p = subject_files[0]            # Path object (from your earlier cell)\n",
    "\n",
    "res = preprocess_single_subject(\n",
    "    subject_file=p,\n",
    "    target_rate=4,              # must divide 700 exactly with current decimate()\n",
    "    original_rate=700,\n",
    "    channels=(\"ECG\",\"EDA\",\"RESP\"),\n",
    "    transition_pad_s=5.0,\n",
    "    min_valid_run_s=30.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Inspect the result\n",
    "if res is not None:\n",
    "    print(\"\\n— Summary —\")\n",
    "    print(\"Subject:\", res[\"subject_id\"])\n",
    "    print(\"fs_low :\", res[\"fs_low\"], \"Hz   | fs_ecg :\", res[\"fs_ecg\"], \"Hz\")\n",
    "    print(\"m2_low :\", res[\"m2_low\"].shape)   # (N_low, 2)\n",
    "    print(\"m2_ecg :\", res[\"m2_ecg\"].shape)   # (N_ecg, 1)\n",
    "    print(\"m1_low :\", res[\"m1_low\"].shape)   # (N_low, K)\n",
    "\n",
    "    # Label distribution after mask + downsample\n",
    "    uniq, cnt = np.unique(res[\"labels_low\"], return_counts=True)\n",
    "    print(\"Label counts (low-rate):\", dict(zip(uniq.tolist(), cnt.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c592fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_subjects(subject_files, max_subjects=None, *,\n",
    "                              target_rate=4, channels=(\"ECG\",\"EDA\",\"RESP\"),\n",
    "                              transition_pad_s=5.0, min_valid_run_s=30.0, verbose=True,\n",
    "                              eda_hp_cutoff=0.03, eda_hp_order=2, eda_robust=False):\n",
    "    \"\"\"\n",
    "    Run preprocess_single_subject() on several files and stack the two\n",
    "    sampling-rate streams separately.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys\n",
    "        X_low        (N_low, 2)   – EDA & RESP @ 4 Hz\n",
    "        m1_low       (N_low, K)   – one-hot labels @ 4 Hz\n",
    "        y_low        (N_low,)     – raw label codes  @ 4 Hz\n",
    "        X_ecg        (N_ecg, 1)   – ECG waveform     @ 175 Hz\n",
    "        y_ecg        (N_ecg,)     – raw label codes  @ 175 Hz\n",
    "        fs_low, fs_ecg, channels_low, channels_ecg, segments, summary, …\n",
    "    \"\"\"\n",
    "    iterable = subject_files if max_subjects is None else subject_files[:max_subjects]\n",
    "    print(f\"\\n🔄 Processing {len(iterable)} subjects …\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # accumulators\n",
    "    all_low, all_m1, all_y_low = [], [], []\n",
    "    all_ecg, all_y_ecg         = [], []\n",
    "    segments = []           # per-subject index bookkeeping\n",
    "    tot_min  = 0.0\n",
    "\n",
    "    low_fs = ecg_fs = None\n",
    "    for subj_idx, p in enumerate(iterable, 1):\n",
    "        res = preprocess_single_subject(\n",
    "        subject_file=p, target_rate=target_rate, original_rate=700, channels=channels,\n",
    "        transition_pad_s=transition_pad_s, min_valid_run_s=min_valid_run_s, verbose=verbose,\n",
    "        eda_hp_cutoff=eda_hp_cutoff, eda_hp_order=eda_hp_order, eda_robust=eda_robust\n",
    "    )\n",
    "        if res is None:\n",
    "            print(f\"⚠️ Skipping {Path(p).name}\")\n",
    "            continue\n",
    "\n",
    "        # -------- pull tensors ----------\n",
    "        X_low, m1_low, y_low = res[\"m2_low\"], res[\"m1_low\"], res[\"labels_low\"]\n",
    "        X_ecg, y_ecg         = res[\"m2_ecg\"], res[\"labels_ecg\"]\n",
    "        sid                  = res[\"subject_id\"]\n",
    "\n",
    "        # -------- sanity on fs ----------\n",
    "        if low_fs is None:\n",
    "            low_fs, ecg_fs = res[\"fs_low\"], res[\"fs_ecg\"]\n",
    "            channels_low   = res[\"channels_low\"]\n",
    "            channels_ecg   = res[\"channels_ecg\"]\n",
    "        else:\n",
    "            assert res[\"fs_low\"] == low_fs and res[\"fs_ecg\"] == ecg_fs, \"fs mismatch\"\n",
    "            assert res[\"channels_low\"] == channels_low and res[\"channels_ecg\"] == channels_ecg, \"channel order mismatch\"\n",
    "\n",
    "        # -------- append ----------\n",
    "        low_start  = 0 if not all_low else segments[-1][\"low_end\"]\n",
    "        ecg_start  = 0 if not all_ecg else segments[-1][\"ecg_end\"]\n",
    "\n",
    "        all_low.append(X_low);   all_m1.append(m1_low); all_y_low.append(y_low)\n",
    "        all_ecg.append(X_ecg);   all_y_ecg.append(y_ecg)\n",
    "\n",
    "        segments.append({\n",
    "            \"subject_id\": sid,\n",
    "            \"low_start\": low_start,\n",
    "            \"low_end\":   low_start + len(X_low),\n",
    "            \"ecg_start\": ecg_start,\n",
    "            \"ecg_end\":   ecg_start + len(X_ecg),\n",
    "            \"duration_minutes\": res[\"duration_minutes\"]\n",
    "        })\n",
    "        tot_min += res[\"duration_minutes\"]\n",
    "\n",
    "    if not all_low:\n",
    "        print(\"❌ No subjects processed successfully.\")\n",
    "        return None\n",
    "\n",
    "    # -------- stack tensors ----------\n",
    "    X_low_comb   = np.vstack(all_low).astype(np.float32, copy=False)\n",
    "    m1_low_comb  = np.vstack(all_m1).astype(np.float32, copy=False)\n",
    "    y_low_comb   = np.concatenate(all_y_low).astype(np.int64, copy=False)\n",
    "\n",
    "    X_ecg_comb   = np.concatenate(all_ecg).astype(np.float32, copy=False)  # 1-D concat ok\n",
    "    y_ecg_comb   = np.concatenate(all_y_ecg).astype(np.int64, copy=False)\n",
    "\n",
    "    # -------- summary ----------\n",
    "    print(f\"\\n📊 Combined Dataset:\")\n",
    "    print(f\"  • Low-rate  : {X_low_comb.shape}  (EDA+RESP @ {low_fs} Hz)\")\n",
    "    print(f\"  • ECG stream: {X_ecg_comb.shape}  (ECG @ {ecg_fs} Hz)\")\n",
    "    print(f\"  • Subjects  : {len(segments)}   Total: {tot_min:.1f} min\")\n",
    "\n",
    "    # label counts (low-rate stream drives conditioning)\n",
    "    uniq, cnt = np.unique(y_low_comb, return_counts=True)\n",
    "    print(f\"  • Label counts (low-rate): {dict(zip(uniq.tolist(), cnt.tolist()))}\")\n",
    "\n",
    "    return {\n",
    "        # low-rate branch -------------------------------------------------------\n",
    "        \"X_low\":  X_low_comb,\n",
    "        \"m1_low\": m1_low_comb,\n",
    "        \"y_low\":  y_low_comb,\n",
    "        \"fs_low\": low_fs,\n",
    "        \"channels_low\": channels_low,     # ['EDA','RESP']\n",
    "\n",
    "        # ECG branch -----------------------------------------------------------\n",
    "        \"X_ecg\":  X_ecg_comb,\n",
    "        \"y_ecg\":  y_ecg_comb,\n",
    "        \"fs_ecg\": ecg_fs,\n",
    "        \"channels_ecg\": channels_ecg,     # ['ECG']\n",
    "\n",
    "        # bookkeeping ----------------------------------------------------------\n",
    "        \"segments\": segments,\n",
    "        \"summary\": {\n",
    "            \"subjects\": len(segments),\n",
    "            \"total_minutes\": tot_min,\n",
    "            \"label_counts\": {int(k): int(v) for k, v in zip(uniq, cnt)},\n",
    "        },\n",
    "        \"feature_names\": {\n",
    "            \"m1\":  [LABEL_MAP[k] for k in sorted(LABEL_MAP)],   # one-hot col names\n",
    "            \"low\": channels_low,\n",
    "            \"ecg\": channels_ecg,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba99cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing 2 subjects …\n",
      "============================================================\n",
      "\n",
      "📂 Processing: S2\n",
      "  Original: X (4255300, 3), y (4255300,) (~101.3 min)\n",
      "  After mask (orig fs): (1987299, 3), label dist: {1: 793800, 2: 423500, 3: 246400, 4: 523599}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11352, 2) @ 4 Hz | X_ecg (496650, 1) @ 175 Hz | m1 (11352, 4)\n",
      "\n",
      "📂 Processing: S3\n",
      "  Original: X (4545100, 3), y (4545100,) (~108.2 min)\n",
      "  After mask (orig fs): (2019501, 3), label dist: {1: 791000, 2: 441000, 3: 255500, 4: 532001}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0664 Hz\n",
      "  ➜ X_low (11540, 2) @ 4 Hz | X_ecg (504875, 1) @ 175 Hz | m1 (11540, 4)\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (22892, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (1001525, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 2   Total: 95.4 min\n",
      "  • Label counts (low-rate): {1: 9056, 2: 4940, 3: 2868, 4: 6028}\n",
      "\n",
      "— Combined check —\n",
      "X_low : (22892, 2) | m1_low : (22892, 4) | y_low : (22892,)\n",
      "X_ecg : (1001525, 1)\n",
      "fs_low : 4 Hz | fs_ecg : 175 Hz\n",
      "channels_low : ['EDA', 'RESP'] | channels_ecg : ['ECG']\n",
      "Segments: 2 → [{'subject_id': 'S2', 'low_start': 0, 'low_end': 11352, 'ecg_start': 0, 'ecg_end': 496650, 'duration_minutes': 47.3}, {'subject_id': 'S3', 'low_start': 11352, 'low_end': 22892, 'ecg_start': 496650, 'ecg_end': 1001525, 'duration_minutes': 48.083333333333336}]\n"
     ]
    }
   ],
   "source": [
    "ds = process_multiple_subjects(\n",
    "    subject_files,\n",
    "    max_subjects=2,                 # small smoke test\n",
    "    target_rate=4,\n",
    "    channels=(\"ECG\",\"EDA\",\"RESP\"),  # ← Fixed: updated to new channel config\n",
    "    transition_pad_s=5.0,\n",
    "    min_valid_run_s=30.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Basic invariants\n",
    "if ds is not None:\n",
    "    print(\"\\n— Combined check —\")\n",
    "    print(\"X_low :\", ds[\"X_low\"].shape,  \"| m1_low :\", ds[\"m1_low\"].shape,\n",
    "          \"| y_low :\", ds[\"y_low\"].shape)\n",
    "    print(\"X_ecg :\", ds[\"X_ecg\"].shape)\n",
    "    print(\"fs_low :\", ds[\"fs_low\"], \"Hz | fs_ecg :\", ds[\"fs_ecg\"], \"Hz\")\n",
    "    print(\"channels_low :\", ds[\"channels_low\"], \"| channels_ecg :\", ds[\"channels_ecg\"])\n",
    "    print(\"Segments:\", len(ds[\"segments\"]), \"→\", ds[\"segments\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1ab71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _constant_label_windows(X, y_raw, y_cond, m1, fs, T, step, require_single_label=True):\n",
    "    \"\"\"Slice windows within a subject segment; enforce single label if requested.\"\"\"\n",
    "    Xw, ycw, m1w = [], [], []\n",
    "    n = len(y_raw)\n",
    "    if require_single_label:\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            j = i + 1\n",
    "            while j < n and y_raw[j] == y_raw[i]:\n",
    "                j += 1\n",
    "            run_len = j - i\n",
    "            if run_len >= T:\n",
    "                for t0 in range(i, j - T + 1, step):\n",
    "                    mid = t0 + T//2\n",
    "                    Xw.append(X[t0:t0+T])\n",
    "                    ycw.append(int(y_cond[mid]))   # 0..K-1\n",
    "                    m1w.append(m1[mid])            # one-hot for that label\n",
    "            i = j\n",
    "    else:\n",
    "        for t0 in range(0, n - T + 1, step):\n",
    "            mid = t0 + T//2\n",
    "            Xw.append(X[t0:t0+T])\n",
    "            ycw.append(int(y_cond[mid]))\n",
    "            m1w.append(m1[mid])\n",
    "    if not Xw:\n",
    "        return None, None, None\n",
    "    return (np.stack(Xw, 0).astype(np.float32),\n",
    "            np.asarray(ycw, dtype=np.int64),\n",
    "            np.stack(m1w, 0).astype(np.float32))\n",
    "\n",
    "def _fit_norm_stats(Xw):\n",
    "    \"\"\"Per-channel mean/std across windows and time.\"\"\"\n",
    "    mean = Xw.mean(axis=(0,1), dtype=np.float64)\n",
    "    std  = Xw.std(axis=(0,1), dtype=np.float64)\n",
    "    std[std < 1e-8] = 1.0\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def _apply_norm(Xw, mean, std):\n",
    "    return ((Xw - mean) / std).astype(np.float32)\n",
    "\n",
    "def create_training_sequences_from_combined(\n",
    "    ds,\n",
    "    window_s=60,                # 60-s windows\n",
    "    step_s=30,                  # 50 % overlap\n",
    "    train_subject_ids=None,\n",
    "    test_subject_ids=None,\n",
    "    require_single_label=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Build train/test windows for the **two-stream** dataset produced by\n",
    "    process_multiple_subjects (X_low @ 4 Hz, X_ecg @ 175 Hz).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys\n",
    "      train : {\"X_low\",\"X_ecg\",\"m1_seq\",\"cond\", \"mean_low\",\"std_low\",\n",
    "               \"mean_ecg\",\"std_ecg\"}\n",
    "      test  : {\"X_low\",\"X_ecg\",\"m1_seq\",\"cond\"}\n",
    "      config: meta information\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------ constants\n",
    "    fs_low = ds[\"fs_low\"]           # 4\n",
    "    fs_ecg = ds[\"fs_ecg\"]           # 175\n",
    "    T_low  = int(window_s * fs_low)     # 240\n",
    "    T_ecg  = int(window_s * fs_ecg)     # 10 500\n",
    "    step_low = int(step_s * fs_low)\n",
    "    step_ecg = int(step_s * fs_ecg)\n",
    "\n",
    "    # ------------------------------------------------------------------ split by id\n",
    "    all_ids = [seg[\"subject_id\"] for seg in ds[\"segments\"]]\n",
    "    uniq_ids = list(dict.fromkeys(all_ids))          # stable, unique\n",
    "    if train_subject_ids is None or test_subject_ids is None:\n",
    "        n_train = max(1, int(round(0.8 * len(uniq_ids))))\n",
    "        train_subject_ids, test_subject_ids = uniq_ids[:n_train], uniq_ids[n_train:]\n",
    "\n",
    "    # ------------------------------------------------------------------ helper\n",
    "    def slice_per_subject(ids):\n",
    "        Xl, Xe, m1s, ycs = [], [], [], []\n",
    "        for seg in ds[\"segments\"]:\n",
    "            if seg[\"subject_id\"] not in ids:\n",
    "                continue\n",
    "\n",
    "            # -------- low-rate slice (EDA+RESP) -----------------------\n",
    "            X_low  = ds[\"X_low\"][ seg[\"low_start\"] : seg[\"low_end\"] ]\n",
    "            y_low  = ds[\"y_low\"][ seg[\"low_start\"] : seg[\"low_end\"] ]\n",
    "            m1_low = ds[\"m1_low\"][ seg[\"low_start\"] : seg[\"low_end\"] ]\n",
    "\n",
    "            out_low = _constant_label_windows_slice(\n",
    "                X_low, y_low, y_low, m1_low, T_low, step_low\n",
    "            ) if require_single_label else _windows_from_ds(...)\n",
    "\n",
    "            # -------- ECG slice --------------------------------------\n",
    "            X_ecg = ds[\"X_ecg\"][ seg[\"ecg_start\"] : seg[\"ecg_end\"] ]\n",
    "            y_ecg = ds[\"y_ecg\"][ seg[\"ecg_start\"] : seg[\"ecg_end\"] ]\n",
    "\n",
    "            # m1 not used for ECG branch → create dummy array of correct length\n",
    "            dummy_m1 = np.zeros((len(y_ecg), ds[\"m1_low\"].shape[1]), dtype=np.float32)\n",
    "\n",
    "            out_ecg = _constant_label_windows_slice(\n",
    "                X_ecg, y_ecg, y_ecg, dummy_m1,    # dummy_m1 avoids length mismatch\n",
    "                T_ecg, step_ecg\n",
    "            )\n",
    "\n",
    "            if out_low[0] is None or out_ecg[0] is None:\n",
    "                continue\n",
    "\n",
    "            # both have same #windows by construction\n",
    "            assert out_low[0].shape[0] == out_ecg[0].shape[0]\n",
    "\n",
    "            Xl.append(out_low[0]);   Xe.append(out_ecg[0])\n",
    "            ycs.append(out_low[1]);  m1s.append(out_low[2])\n",
    "\n",
    "        if not Xl:\n",
    "            return None\n",
    "        return (np.concatenate(Xl, 0),\n",
    "                np.concatenate(Xe, 0),\n",
    "                np.concatenate(m1s, 0),\n",
    "                np.concatenate(ycs, 0))\n",
    "\n",
    "    # ------------------------------------------------------------------ collect\n",
    "    tr = slice_per_subject(train_subject_ids)\n",
    "    te = slice_per_subject(test_subject_ids)\n",
    "    if tr is None or te is None:\n",
    "        raise RuntimeError(\"No windows created – try smaller window_s or step_s.\")\n",
    "\n",
    "    Xl_tr, Xe_tr, m1_tr, yc_tr = tr\n",
    "    Xl_te, Xe_te, m1_te, yc_te = te\n",
    "\n",
    "    # ------------------------------------------------------------------ normalise\n",
    "    mean_low, std_low = Xl_tr.mean((0,1)), Xl_tr.std((0,1)); std_low[std_low==0] = 1\n",
    "    mean_ecg, std_ecg = Xe_tr.mean((0,1)), Xe_tr.std((0,1)); std_ecg[std_ecg==0] = 1\n",
    "\n",
    "    Xl_tr = ((Xl_tr - mean_low)/std_low).astype(np.float32)\n",
    "    Xl_te = ((Xl_te - mean_low)/std_low).astype(np.float32)\n",
    "    Xe_tr = ((Xe_tr - mean_ecg)/std_ecg).astype(np.float32)\n",
    "    Xe_te = ((Xe_te - mean_ecg)/std_ecg).astype(np.float32)\n",
    "\n",
    "    # one-hot needs repeating across time if the model expects per-step cond\n",
    "    m1_tr_seq = np.repeat(m1_tr[:, None, :], T_low, axis=1)\n",
    "    m1_te_seq = np.repeat(m1_te[:, None, :], T_low, axis=1)\n",
    "\n",
    "    # ------------------------------------------------------------------ return\n",
    "    return {\n",
    "        \"train\": {\n",
    "            \"X_low\": Xl_tr, \"X_ecg\": Xe_tr,\n",
    "            \"m1_seq\": m1_tr_seq, \"cond\": yc_tr,\n",
    "            \"mean_low\": mean_low.astype(np.float32),\n",
    "            \"std_low\":  std_low.astype(np.float32),\n",
    "            \"mean_ecg\": mean_ecg.astype(np.float32),\n",
    "            \"std_ecg\":  std_ecg.astype(np.float32)\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"X_low\": Xl_te, \"X_ecg\": Xe_te,\n",
    "            \"m1_seq\": m1_te_seq, \"cond\": yc_te\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"fs_low\": fs_low, \"fs_ecg\": fs_ecg,\n",
    "            \"T_low\": T_low, \"T_ecg\": T_ecg,\n",
    "            \"step_low\": step_low, \"step_ecg\": step_ecg,\n",
    "            \"channels_low\": ds[\"channels_low\"],\n",
    "            \"channels_ecg\": ds[\"channels_ecg\"],\n",
    "            \"K\": m1_tr.shape[-1],\n",
    "            \"train_subject_ids\": train_subject_ids,\n",
    "            \"test_subject_ids\":  test_subject_ids\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31d9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _constant_label_windows_slice(X, y_raw, y_cond, m1, T, step):\n",
    "    \"\"\"Windows fully inside constant-label runs for a single subject slice.\"\"\"\n",
    "    Xw, ycw, m1w = [], [], []\n",
    "    n = len(y_raw)\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        j = i + 1\n",
    "        while j < n and y_raw[j] == y_raw[i]:\n",
    "            j += 1\n",
    "        run_len = j - i\n",
    "        if run_len >= T:\n",
    "            for t0 in range(i, j - T + 1, step):\n",
    "                mid = t0 + T//2\n",
    "                Xw.append(X[t0:t0+T])\n",
    "                ycw.append(int(y_cond[mid]))   # 0..K-1\n",
    "                m1w.append(m1[mid])            # one-hot for that label\n",
    "        i = j\n",
    "    if not Xw:\n",
    "        return None, None, None\n",
    "    return (np.stack(Xw, 0).astype(np.float32),\n",
    "            np.asarray(ycw, dtype=np.int64),\n",
    "            np.stack(m1w, 0).astype(np.float32))\n",
    "\n",
    "def _windows_from_ds(ds, T, step):\n",
    "    \"\"\"Collect windows per subject from a combined ds dict.\"\"\"\n",
    "    Xw_list, ycw_list, m1w_list = [], [], []\n",
    "    for seg in ds[\"segments\"]:\n",
    "        s0, s1 = seg[\"start\"], seg[\"end\"]\n",
    "        out = _constant_label_windows_slice(\n",
    "            ds[\"X\"][s0:s1], ds[\"y_raw\"][s0:s1],\n",
    "            ds[\"y_cond\"][s0:s1], ds[\"m1\"][s0:s1],\n",
    "            T, step\n",
    "        )\n",
    "        if out[0] is not None:\n",
    "            Xw_list.append(out[0]); ycw_list.append(out[1]); m1w_list.append(out[2])\n",
    "    if not Xw_list:\n",
    "        return None, None, None\n",
    "    return (np.concatenate(Xw_list, 0),\n",
    "            np.concatenate(ycw_list, 0),\n",
    "            np.concatenate(m1w_list, 0))\n",
    "\n",
    "def _fit_norm_stats(Xw):\n",
    "    mean = Xw.mean(axis=(0,1), dtype=np.float64)\n",
    "    std  = Xw.std(axis=(0,1), dtype=np.float64)\n",
    "    std[std < 1e-8] = 1.0\n",
    "    return mean.astype(np.float32), std.astype(np.float32)\n",
    "\n",
    "def _apply_norm(Xw, mean, std):\n",
    "    return ((Xw - mean) / std).astype(np.float32)\n",
    "\n",
    "\n",
    "def _impute_linear_windows(Xw, ycw, m1w, split_name, return_stats=False):\n",
    "    \"\"\"\n",
    "    Replace non‑finite values in each window/channel by linear interpolation along time.\n",
    "    • 0 valid points in a channel → drop the window\n",
    "    • 1 valid point            → fill that channel with the single value\n",
    "    • ≥2 valid points          → linear interpolation (with constant edge fill)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    Xw = Xw.copy().astype(np.float32, copy=False)\n",
    "    Xw[~np.isfinite(Xw)] = np.nan\n",
    "\n",
    "    if Xw is None:\n",
    "        if return_stats: \n",
    "            return None, None, None, {\"N_in\": 0, \"dropped\": 0, \"split\": split_name}\n",
    "        return None, None, None\n",
    "\n",
    "    N, T, C = Xw.shape\n",
    "    t = np.arange(T, dtype=np.float32)\n",
    "    keep = np.ones(N, dtype=bool)\n",
    "    dropped = 0\n",
    "\n",
    "    for i in range(N):\n",
    "        Xi = Xw[i]\n",
    "        ok_window = True\n",
    "        for c in range(C):\n",
    "            col = Xi[:, c]\n",
    "            good = np.isfinite(col)\n",
    "            n_good = int(good.sum())\n",
    "            if n_good == 0:\n",
    "                ok_window = False\n",
    "                break\n",
    "            elif n_good == T:\n",
    "                continue\n",
    "            elif n_good == 1:\n",
    "                Xi[:, c] = float(col[good][0])\n",
    "            else:\n",
    "                Xi[~good, c] = np.interp(t[~good], t[good], col[good])\n",
    "        if not ok_window:\n",
    "            keep[i] = False\n",
    "            dropped += 1\n",
    "\n",
    "    stats = {\"N_in\": N, \"dropped\": dropped, \"split\": split_name}\n",
    "    if dropped:\n",
    "        print(f\"⚠️ {split_name}: dropped {dropped} / {N} windows (0 valid points in a channel).\")\n",
    "    if return_stats:\n",
    "        return Xw[keep], ycw[keep], m1w[keep], stats\n",
    "    return Xw[keep], ycw[keep], m1w[keep]\n",
    "\n",
    "def create_train_test_sequences(proc_train, proc_test,\n",
    "                                sequence_length=240, step_overlap=0.5,\n",
    "                                impute=True):\n",
    "    \"\"\"Build single-label windows for train & test; z-score on train only (signals).\"\"\"\n",
    "    T = int(sequence_length)\n",
    "    step = max(1, int(round(T * (1 - step_overlap))))\n",
    "\n",
    "    Xw_tr, ycw_tr, m1w_tr = _windows_from_ds(proc_train, T, step)\n",
    "    Xw_te, ycw_te, m1w_te = _windows_from_ds(proc_test,  T, step)\n",
    "\n",
    "    if Xw_tr is None or Xw_te is None:\n",
    "        raise RuntimeError(\"No windows created; reduce sequence_length or step_overlap.\")\n",
    "\n",
    "    impute_stats = {\"train\": {\"N_in\": len(Xw_tr), \"dropped\": 0, \"split\": \"TRAIN\"},\n",
    "                    \"test\":  {\"N_in\": len(Xw_te), \"dropped\": 0, \"split\": \"TEST\"}}\n",
    "\n",
    "    if impute:\n",
    "        print(f\"Before impute: train={Xw_tr.shape[0]} test={Xw_te.shape[0]}\")\n",
    "        Xw_tr, ycw_tr, m1w_tr, s_tr = _impute_linear_windows(Xw_tr, ycw_tr, m1w_tr, \"TRAIN\", return_stats=True)\n",
    "        Xw_te, ycw_te, m1w_te, s_te = _impute_linear_windows(Xw_te, ycw_te, m1w_te, \"TEST\",  return_stats=True)\n",
    "        impute_stats = {\"train\": s_tr, \"test\": s_te}\n",
    "        print(f\"After  impute: train={Xw_tr.shape[0]} test={Xw_te.shape[0]}\")\n",
    "\n",
    "    if Xw_tr.size == 0 or Xw_te.size == 0:\n",
    "        raise RuntimeError(\"All windows dropped. Try shorter windows or enable imputation.\")\n",
    "\n",
    "    mean, std = _fit_norm_stats(Xw_tr)\n",
    "    Xw_tr_n = _apply_norm(Xw_tr, mean, std)\n",
    "    Xw_te_n = _apply_norm(Xw_te, mean, std)\n",
    "\n",
    "    m1_tr_seq = np.repeat(m1w_tr[:, None, :], T, axis=1)\n",
    "    m1_te_seq = np.repeat(m1w_te[:, None, :], T, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"train\": {\"X\": Xw_tr_n, \"m1_seq\": m1_tr_seq, \"cond\": ycw_tr, \"mean\": mean, \"std\": std},\n",
    "        \"test\":  {\"X\": Xw_te_n, \"m1_seq\": m1_te_seq, \"cond\": ycw_te},\n",
    "        \"config\": {\n",
    "            \"T\": T, \"step\": step, \"fs\": proc_train[\"fs_out\"],\n",
    "            \"channels\": proc_train[\"channels\"], \"K\": m1_tr_seq.shape[-1],\n",
    "            \"train_subjects\": [s[\"subject_id\"] for s in proc_train[\"segments\"]],\n",
    "            \"test_subjects\":  [s[\"subject_id\"] for s in proc_test[\"segments\"]],\n",
    "        },\n",
    "        \"impute_stats\": impute_stats\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81a8e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train low-rate : (182, 120, 2) | Train ECG : (182, 5250, 1)\n"
     ]
    }
   ],
   "source": [
    "train_ids = [ds[\"segments\"][0][\"subject_id\"]]   # e.g., 'S2'\n",
    "test_ids  = [ds[\"segments\"][1][\"subject_id\"]]   # e.g., 'S3'\n",
    "\n",
    "seqs = create_training_sequences_from_combined(\n",
    "    ds,\n",
    "    window_s=30, step_s=15,\n",
    "    train_subject_ids=train_ids,\n",
    "    test_subject_ids=test_ids,\n",
    "    require_single_label=True\n",
    ")\n",
    "\n",
    "print(\"Train low-rate :\", seqs[\"train\"][\"X_low\"].shape,\n",
    "      \"| Train ECG :\",   seqs[\"train\"][\"X_ecg\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8911f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessing_results(seqs, save_name=None, show=False):\n",
    "    \"\"\"Visualize sample window, conditioning, correlations, and class balance for current schema.\"\"\"\n",
    "\n",
    "    fs  = seqs[\"config\"][\"fs\"]\n",
    "    T   = seqs[\"config\"][\"T\"]\n",
    "    chs = seqs[\"config\"][\"channels\"]\n",
    "    K   = seqs[\"config\"][\"K\"]\n",
    "\n",
    "    X_tr   = seqs[\"train\"][\"X\"]         # [N,T,C], normalized\n",
    "    median_idx = np.argsort(np.abs(X_tr).mean(axis=(1,2)))[len(X_tr)//2]\n",
    "    M1_tr  = seqs[\"train\"][\"m1_seq\"]    # [N,T,K] one‑hot per time step\n",
    "    y_tr   = seqs[\"train\"][\"cond\"]      # [N], 0..K-1\n",
    "\n",
    "    # pick a sample window\n",
    "    idx = 0\n",
    "    x = X_tr[median_idx]        # [T,C]\n",
    "    m = M1_tr[median_idx]       # [T,K]\n",
    "    t = np.arange(T) / fs\n",
    "\n",
    "    # optional class names\n",
    "    try:\n",
    "        class_names = [LABEL_MAP[k] for k in sorted(LABEL_MAP.keys())][:K]\n",
    "    except Exception:\n",
    "        class_names = [f\"class_{i}\" for i in range(K)]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(\"WESAD – Preprocessed Windows Overview\", fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "    # (1) Signals (normalized)\n",
    "    for c in range(x.shape[1]):\n",
    "        axes[0,0].plot(t, x[:, c])\n",
    "    axes[0,0].set_title(\"Signals (median window)\")\n",
    "    axes[0,0].set_xlabel(\"Time (s)\"); axes[0,0].set_ylabel(\"z‑score\")\n",
    "    axes[0,0].legend(chs)\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "    # (2) Conditioning one‑hot (sample window)\n",
    "    im = axes[0,1].imshow(m.T, aspect=\"auto\", interpolation=\"nearest\")\n",
    "    axes[0,1].set_title(\"Conditioning one‑hot (sample window)\")\n",
    "    axes[0,1].set_ylabel(\"Class\")\n",
    "    axes[0,1].set_xlabel(\"Time step\")\n",
    "    axes[0,1].set_yticks(range(K))\n",
    "    axes[0,1].set_yticklabels(class_names)\n",
    "    plt.colorbar(im, ax=axes[0,1])\n",
    "\n",
    "    # (3) Correlation across channels (flatten several windows)\n",
    "    n_corr = min(100, X_tr.shape[0])\n",
    "    flat = X_tr[:n_corr].reshape(-1, X_tr.shape[-1])  # [(n_corr*T), C]\n",
    "    corr = np.corrcoef(flat.T)                        # [C,C]\n",
    "    im2 = axes[1,0].imshow(corr, vmin=-1, vmax=1)\n",
    "    axes[1,0].set_title(f\"Channel correlation (first {n_corr} windows)\")\n",
    "    axes[1,0].set_xticks(range(len(chs))); axes[1,0].set_xticklabels(chs)\n",
    "    axes[1,0].set_yticks(range(len(chs))); axes[1,0].set_yticklabels(chs)\n",
    "    plt.colorbar(im2, ax=axes[1,0])\n",
    "\n",
    "    # (4) Class balance (train split)\n",
    "    cnt = Counter(y_tr.tolist())\n",
    "    xs = np.arange(K)\n",
    "    axes[1,1].bar(xs, [cnt.get(i,0) for i in xs])\n",
    "    axes[1,1].set_title(\"Train windows per class\")\n",
    "    axes[1,1].set_xticks(xs); axes[1,1].set_xticklabels(class_names, rotation=0)\n",
    "    axes[1,1].set_ylabel(\"# windows\")\n",
    "    axes[1,1].grid(True, axis=\"y\", alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save figure\n",
    "    figures_dir = Path(project_root) / \"results\" / \"figures\"\n",
    "    figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = figures_dir / save_name\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"✅ Visualization saved to: {out_path}\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "    # Data quality summary\n",
    "    print(\"\\n📊 Data Quality Summary (train split):\")\n",
    "    print(f\"  • X shape: {X_tr.shape} (N,T,C) at fs={fs} Hz, channels={chs}\")\n",
    "    print(f\"  • m1_seq shape: {M1_tr.shape} (N,T,K), K={K}, classes={class_names}\")\n",
    "    print(f\"  • No NaNs in X: {not np.isnan(X_tr).any()}\")\n",
    "    print(f\"  • No NaNs in m1_seq: {not np.isnan(M1_tr).any()}\")\n",
    "    mu = X_tr.mean(axis=(0,1)); sd = X_tr.std(axis=(0,1))\n",
    "    print(f\"  • Per‑channel mean ≈ 0: {mu}\")\n",
    "    print(f\"  • Per‑channel std  ≈ 1: {sd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "686fc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_summary(seqs, processed_dir):\n",
    "    \"\"\"\n",
    "    Print a summary for the *two-stream* dataset produced by\n",
    "    create_training_sequences_from_combined + save_processed_data_two_stream.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from pathlib import Path\n",
    "\n",
    "    cfg = seqs[\"config\"]\n",
    "\n",
    "    # ── meta info ────────────────────────────────────────────────────────────\n",
    "    ch_low  = cfg[\"channels_low\"]          # ['EDA','RESP']\n",
    "    ch_ecg  = cfg[\"channels_ecg\"]          # ['ECG']\n",
    "    fs_low  = cfg[\"fs_low\"]                # 4\n",
    "    fs_ecg  = cfg[\"fs_ecg\"]                # 175\n",
    "    T_low   = cfg[\"T_low\"]                 # 120  (30 s)\n",
    "    T_ecg   = cfg[\"T_ecg\"]                 # 5 250\n",
    "    K       = cfg[\"K\"]\n",
    "\n",
    "    # ── basic counts ────────────────────────────────────────────────────────\n",
    "    n_tr = seqs[\"train\"][\"X_low\"].shape[0]\n",
    "    n_te = seqs[\"test\"][\"X_low\"].shape[0]\n",
    "\n",
    "    mu_low,  sd_low  = seqs[\"train\"][\"mean_low\"],  seqs[\"train\"][\"std_low\"]\n",
    "    mu_ecg,  sd_ecg  = seqs[\"train\"][\"mean_ecg\"],  seqs[\"train\"][\"std_ecg\"]\n",
    "\n",
    "    try:\n",
    "        label_names = [LABEL_MAP[k] for k in sorted(LABEL_MAP)][:K]\n",
    "    except Exception:\n",
    "        label_names = [f\"class_{i}\" for i in range(K)]\n",
    "\n",
    "    # ── print summary ───────────────────────────────────────────────────────\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"🎉 Two-Stream WESAD Preprocessing Completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"📊 Final Dataset Statistics:\")\n",
    "    print(f\"   • Train windows: {n_tr:,}   Test windows: {n_te:,}\")\n",
    "    print(f\"   • Window length: low-rate {T_low} steps  (30 s @ {fs_low} Hz)\")\n",
    "    print(f\"                    ECG      {T_ecg} steps  (30 s @ {fs_ecg} Hz)\")\n",
    "    print(f\"   • Channels (low): {ch_low}   (ECG): {ch_ecg}\")\n",
    "    print(f\"   • Classes (K): {K} → {label_names}\")\n",
    "\n",
    "    # per-class counts\n",
    "    tr_cnt = Counter(seqs[\"train\"][\"cond\"].tolist())\n",
    "    te_cnt = Counter(seqs[\"test\"][\"cond\"].tolist())\n",
    "    print(f\"   • Train per-class: {[tr_cnt.get(i,0) for i in range(K)]}\")\n",
    "    print(f\"   • Test  per-class: {[te_cnt.get(i,0) for i in range(K)]}\")\n",
    "\n",
    "    print(\"\\n🧭 Normalisation (train only):\")\n",
    "    print(f\"   • low-rate μ: {mu_low}   σ: {sd_low}\")\n",
    "    print(f\"   • ECG      μ: {mu_ecg}   σ: {sd_ecg}\")\n",
    "\n",
    "    # ── file overview ───────────────────────────────────────────────────────\n",
    "    processed_dir = Path(processed_dir)\n",
    "    files = [\n",
    "        \"train_X_low.npy\", \"train_X_ecg.npy\", \"train_m1_seq.npy\", \"train_cond.npy\",\n",
    "        \"test_X_low.npy\",  \"test_X_ecg.npy\",  \"test_m1_seq.npy\",  \"test_cond.npy\",\n",
    "        \"norm_low.npz\", \"norm_ecg.npz\", \"dataset_config.json\"\n",
    "    ]\n",
    "    print(\"\\n📁 Output Files:\")\n",
    "    print(f\"   • Directory: {processed_dir}\")\n",
    "    for f in files:\n",
    "        p = processed_dir / f\n",
    "        status = \"✅\" if p.exists() else \"❌\"\n",
    "        size   = f\" ({p.stat().st_size/1_048_576:.1f} MB)\" if p.exists() else \"\"\n",
    "        print(f\"   • {status} {f}{size}\")\n",
    "\n",
    "    print(\"\\n🎯 Ready for next steps:\")\n",
    "    print(\"   1) Train your dual-branch GAN on (X_low, X_ecg, m1_seq).\")\n",
    "    print(\"   2) Generate synthetic windows per class; keep them normalised with the train stats.\")\n",
    "    print(\"   3) Evaluate KS/W1/JS (EDA, RESP, ECG) + HRV, then classifier F1 ≥ 95 %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f02f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data_two_stream(seqs, subdir):\n",
    "    out_dir = Path(project_root) / \"data\" / \"processed\" / subdir\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(out_dir / \"train_X_low.npy\",  seqs[\"train\"][\"X_low\"])\n",
    "    np.save(out_dir / \"train_X_ecg.npy\",  seqs[\"train\"][\"X_ecg\"])\n",
    "    np.save(out_dir / \"train_m1_seq.npy\", seqs[\"train\"][\"m1_seq\"])\n",
    "    np.save(out_dir / \"train_cond.npy\",   seqs[\"train\"][\"cond\"])\n",
    "    np.save(out_dir / \"test_X_low.npy\",   seqs[\"test\"][\"X_low\"])\n",
    "    np.save(out_dir / \"test_X_ecg.npy\",   seqs[\"test\"][\"X_ecg\"])\n",
    "    np.save(out_dir / \"test_m1_seq.npy\",  seqs[\"test\"][\"m1_seq\"])\n",
    "    np.save(out_dir / \"test_cond.npy\",    seqs[\"test\"][\"cond\"])\n",
    "    np.savez(out_dir / \"norm_low.npz\",  mean=seqs[\"train\"][\"mean_low\"],  std=seqs[\"train\"][\"std_low\"])\n",
    "    np.savez(out_dir / \"norm_ecg.npz\",  mean=seqs[\"train\"][\"mean_ecg\"],  std=seqs[\"train\"][\"std_ecg\"])\n",
    "    (out_dir / \"dataset_config.json\").write_text(json.dumps(seqs[\"config\"], indent=2))\n",
    "    return out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8826514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_eda_hp(train_paths, test_paths, train_ids, test_ids,\n",
    "                 cutoffs=(0.03, 0.04, 0.05), orders=(2,4), robust=False):\n",
    "    rows = []\n",
    "    for co in cutoffs:\n",
    "        for od in orders:\n",
    "            ds_fold = process_multiple_subjects(\n",
    "                train_paths + test_paths,\n",
    "                target_rate=4, channels=(\"ECG\",\"EDA\",\"RESP\"),\n",
    "                transition_pad_s=5.0, min_valid_run_s=30.0, verbose=False,\n",
    "                eda_hp_cutoff=co, eda_hp_order=od, eda_robust=robust\n",
    "            )\n",
    "            seqs = create_training_sequences_from_combined(\n",
    "                ds_fold, window_s=30, step_s=15,\n",
    "                train_subject_ids=train_ids, test_subject_ids=test_ids,\n",
    "                require_single_label=True\n",
    "            )\n",
    "\n",
    "            r = seqs[\"train\"][\"X_low\"][:,:,0].ravel()  # EDA train (z to train stats)\n",
    "            t = seqs[\"test\"][\"X_low\"][:,:,0].ravel()   # EDA test\n",
    "            n = min(len(r), len(t))\n",
    "            rng = np.random.default_rng(0)\n",
    "            r = r[rng.choice(len(r), n, replace=False)]\n",
    "            t = t[rng.choice(len(t), n, replace=False)]\n",
    "            ks = float(stats.ks_2samp(r, t).statistic)\n",
    "            w1 = float(stats.wasserstein_distance(r, t))\n",
    "            mu_te = float(seqs[\"test\"][\"X_low\"][:,:,0].mean())\n",
    "            sd_te = float(seqs[\"test\"][\"X_low\"][:,:,0].std())\n",
    "\n",
    "            rows.append(dict(cutoff=co, order=od, robust=robust,\n",
    "                             KS=ks, W1=w1, test_mu=mu_te, test_sd=sd_te,\n",
    "                             N_tr=int(seqs[\"train\"][\"X_low\"].shape[0]),\n",
    "                             N_te=int(seqs[\"test\"][\"X_low\"].shape[0])))\n",
    "    df = pd.DataFrame(rows).sort_values([\"KS\",\"W1\",\"cutoff\",\"order\"])\n",
    "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9583814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      " cutoff  order  robust    KS    W1  test_mu  test_sd  N_tr  N_te\n",
      "  0.050      2   False 0.195 0.152   -0.011    0.138  2645   194\n",
      "  0.050      4   False 0.195 0.161   -0.011    0.137  2645   194\n",
      "  0.030      4   False 0.200 0.172   -0.010    0.142  2645   194\n",
      "  0.040      2   False 0.201 0.155   -0.012    0.139  2645   194\n",
      "  0.040      4   False 0.201 0.167   -0.011    0.139  2645   194\n",
      "  0.030      2   False 0.205 0.160   -0.013    0.141  2645   194\n"
     ]
    }
   ],
   "source": [
    "df_hp = sweep_eda_hp(\n",
    "    train_paths, test_paths, train_ids, test_ids,\n",
    "    cutoffs=(0.03, 0.04, 0.05), orders=(2, 4), robust=False\n",
    ")\n",
    "# optional: save it\n",
    "(project_root / \"results\" / \"eda_hp_sweep.csv\").parent.mkdir(parents=True, exist_ok=True)\n",
    "df_hp.to_csv(project_root / \"results\" / \"eda_hp_sweep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193ac72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting two-stream preprocessing pipeline (LOSO)…\n",
      "Fold 0 — Test: ['S10'] | Train(+val): 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📂 Processing: S2\n",
      "  Original: X (4255300, 3), y (4255300,) (~101.3 min)\n",
      "  After mask (orig fs): (1987299, 3), label dist: {1: 793800, 2: 423500, 3: 246400, 4: 523599}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11352, 2) @ 4 Hz | X_ecg (496650, 1) @ 175 Hz | m1 (11352, 4)\n",
      "\n",
      "📂 Processing: S4\n",
      "  Original: X (4496100, 3), y (4496100,) (~107.0 min)\n",
      "  After mask (orig fs): (2044001, 3), label dist: {1: 803601, 2: 437500, 3: 253400, 4: 549500}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0352 Hz\n",
      "  ➜ X_low (11680, 2) @ 4 Hz | X_ecg (511000, 1) @ 175 Hz | m1 (11680, 4)\n",
      "\n",
      "📂 Processing: S5\n",
      "  Original: X (4380600, 3), y (4380600,) (~104.3 min)\n",
      "  After mask (orig fs): (2072700, 3), label dist: {1: 831600, 2: 444500, 3: 254800, 4: 541800}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11844, 2) @ 4 Hz | X_ecg (518175, 1) @ 175 Hz | m1 (11844, 4)\n",
      "\n",
      "📂 Processing: S6\n",
      "  Original: X (4949700, 3), y (4949700,) (~117.8 min)\n",
      "  After mask (orig fs): (2057300, 3), label dist: {1: 819000, 2: 448000, 3: 253400, 4: 536900}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11756, 2) @ 4 Hz | X_ecg (514325, 1) @ 175 Hz | m1 (11756, 4)\n",
      "\n",
      "📂 Processing: S7\n",
      "  Original: X (3666600, 3), y (3666600,) (~87.3 min)\n",
      "  After mask (orig fs): (2056602, 3), label dist: {1: 823200, 2: 441000, 3: 253401, 4: 539001}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0391 Hz\n",
      "  ➜ X_low (11752, 2) @ 4 Hz | X_ecg (514150, 1) @ 175 Hz | m1 (11752, 4)\n",
      "\n",
      "📂 Processing: S8\n",
      "  Original: X (3826200, 3), y (3826200,) (~91.1 min)\n",
      "  After mask (orig fs): (2068499, 3), label dist: {1: 811300, 2: 462000, 3: 251999, 4: 543200}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11816, 2) @ 4 Hz | X_ecg (516950, 1) @ 175 Hz | m1 (11816, 4)\n",
      "\n",
      "📂 Processing: S9\n",
      "  Original: X (3656100, 3), y (3656100,) (~87.0 min)\n",
      "  After mask (orig fs): (2058000, 3), label dist: {1: 819000, 2: 444500, 3: 253400, 4: 541100}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11760, 2) @ 4 Hz | X_ecg (514500, 1) @ 175 Hz | m1 (11760, 4)\n",
      "\n",
      "📂 Processing: S11\n",
      "  Original: X (3663100, 3), y (3663100,) (~87.2 min)\n",
      "  After mask (orig fs): (2078301, 3), label dist: {1: 819000, 2: 469000, 3: 250600, 4: 539701}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11876, 2) @ 4 Hz | X_ecg (519575, 1) @ 175 Hz | m1 (11876, 4)\n",
      "\n",
      "📂 Processing: S13\n",
      "  Original: X (3875900, 3), y (3875900,) (~92.3 min)\n",
      "  After mask (orig fs): (2079700, 3), label dist: {1: 819001, 2: 457800, 3: 260400, 4: 542499}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0391 Hz\n",
      "  ➜ X_low (11884, 2) @ 4 Hz | X_ecg (519925, 1) @ 175 Hz | m1 (11884, 4)\n",
      "\n",
      "📂 Processing: S15\n",
      "  Original: X (3676400, 3), y (3676400,) (~87.5 min)\n",
      "  After mask (orig fs): (2083899, 3), label dist: {1: 815500, 2: 473200, 3: 253400, 4: 541799}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0430 Hz\n",
      "  ➜ X_low (11904, 2) @ 4 Hz | X_ecg (520800, 1) @ 175 Hz | m1 (11904, 4)\n",
      "\n",
      "📂 Processing: S16\n",
      "  Original: X (3941700, 3), y (3941700,) (~93.8 min)\n",
      "  After mask (orig fs): (2074100, 3), label dist: {1: 819000, 2: 464101, 3: 250600, 4: 540399}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0352 Hz\n",
      "  ➜ X_low (11852, 2) @ 4 Hz | X_ecg (518525, 1) @ 175 Hz | m1 (11852, 4)\n",
      "\n",
      "📂 Processing: S17\n",
      "  Original: X (4144000, 3), y (4144000,) (~98.7 min)\n",
      "  After mask (orig fs): (2069900, 3), label dist: {1: 819700, 2: 499100, 3: 253400, 4: 497700}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11828, 2) @ 4 Hz | X_ecg (517475, 1) @ 175 Hz | m1 (11828, 4)\n",
      "\n",
      "📂 Processing: S3\n",
      "  Original: X (4545100, 3), y (4545100,) (~108.2 min)\n",
      "  After mask (orig fs): (2019501, 3), label dist: {1: 791000, 2: 441000, 3: 255500, 4: 532001}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0664 Hz\n",
      "  ➜ X_low (11540, 2) @ 4 Hz | X_ecg (504875, 1) @ 175 Hz | m1 (11540, 4)\n",
      "\n",
      "📂 Processing: S14\n",
      "  Original: X (3883600, 3), y (3883600,) (~92.5 min)\n",
      "  After mask (orig fs): (2079701, 3), label dist: {1: 819000, 2: 465500, 3: 253401, 4: 541800}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11884, 2) @ 4 Hz | X_ecg (519925, 1) @ 175 Hz | m1 (11884, 4)\n",
      "\n",
      "📂 Processing: S10\n",
      "  Original: X (3847200, 3), y (3847200,) (~91.6 min)\n",
      "  After mask (orig fs): (2116100, 3), label dist: {1: 819000, 2: 500500, 3: 253400, 4: 543200}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0391 Hz\n",
      "  ➜ X_low (12092, 2) @ 4 Hz | X_ecg (529025, 1) @ 175 Hz | m1 (12092, 4)\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "Train low-rate : (2645, 120, 2) | Train ECG : (2645, 5250, 1)\n",
      "Test  low-rate : (194, 120, 2) | Test  ECG : (194, 5250, 1)\n",
      "\n",
      "============================================================\n",
      "🎉 Two-Stream WESAD Preprocessing Completed!\n",
      "============================================================\n",
      "📊 Final Dataset Statistics:\n",
      "   • Train windows: 2,645   Test windows: 194\n",
      "   • Window length: low-rate 120 steps  (30 s @ 4 Hz)\n",
      "                    ECG      5250 steps  (30 s @ 175 Hz)\n",
      "   • Channels (low): ['EDA', 'RESP']   (ECG): ['ECG']\n",
      "   • Classes (K): 4 → ['baseline', 'stress', 'amusement', 'meditation']\n",
      "   • Train per-class: [0, 1069, 588, 319]\n",
      "   • Test  per-class: [0, 77, 46, 23]\n",
      "\n",
      "🧭 Normalisation (train only):\n",
      "   • low-rate μ: [ 0.00161832 -0.00026734]   σ: [0.08802961 3.0933664 ]\n",
      "   • ECG      μ: [-2.3908967e-06]   σ: [0.26916406]\n",
      "\n",
      "📁 Output Files:\n",
      "   • Directory: C:\\Users\\Joseph\\generative-health-models\\data\\processed\\tc_multigan_fold_S10\n",
      "   • ✅ train_X_low.npy (2.4 MB)\n",
      "   • ✅ train_X_ecg.npy (53.0 MB)\n",
      "   • ✅ train_m1_seq.npy (4.8 MB)\n",
      "   • ✅ train_cond.npy (0.0 MB)\n",
      "   • ✅ test_X_low.npy (0.2 MB)\n",
      "   • ✅ test_X_ecg.npy (3.9 MB)\n",
      "   • ✅ test_m1_seq.npy (0.4 MB)\n",
      "   • ✅ test_cond.npy (0.0 MB)\n",
      "   • ✅ norm_low.npz (0.0 MB)\n",
      "   • ✅ norm_ecg.npz (0.0 MB)\n",
      "   • ✅ dataset_config.json (0.0 MB)\n",
      "\n",
      "🎯 Ready for next steps:\n",
      "   1) Train your dual-branch GAN on (X_low, X_ecg, m1_seq).\n",
      "   2) Generate synthetic windows per class; keep them normalised with the train stats.\n",
      "   3) Evaluate KS/W1/JS (EDA, RESP, ECG) + HRV, then classifier F1 ≥ 95 %.\n",
      "✅ Fold finished → C:\\Users\\Joseph\\generative-health-models\\data\\processed\\tc_multigan_fold_S10\n"
     ]
    }
   ],
   "source": [
    "assert subject_files, \"No subject files found.\"\n",
    "print(\"🚀 Starting two-stream preprocessing pipeline (LOSO)…\")\n",
    "\n",
    "# 0)  ── load the 15 LOSO folds you generated earlier ──────────────────────────\n",
    "splits_path = project_root / \"data\" / \"processed\" / \"wesad_loso_splits.json\"\n",
    "folds = json.loads(splits_path.read_text())\n",
    "\n",
    "# >>> choose the fold you want to run\n",
    "FOLD = 0                            # 0 … 14\n",
    "test_ids  = folds[FOLD][\"test\"]     # e.g. ['S10']\n",
    "train_ids = folds[FOLD][\"train\"] + folds[FOLD].get(\"val\", [])\n",
    "\n",
    "# map subject ID → .pkl path\n",
    "id2path = {Path(p).stem: p for p in subject_files}\n",
    "train_paths = [id2path[sid] for sid in train_ids]\n",
    "test_paths  = [id2path[sid] for sid in test_ids]\n",
    "\n",
    "print(f\"Fold {FOLD} — Test: {test_ids} | Train(+val): {len(train_paths)} subjects\")\n",
    "\n",
    "# 1) ── combine *all* subjects of this fold into one two-stream dataset ────────\n",
    "ds_fold = process_multiple_subjects(\n",
    "    train_paths + test_paths,       # combine; slicing happens later\n",
    "    target_rate=4,\n",
    "    channels=(\"ECG\", \"EDA\", \"RESP\"),\n",
    "    transition_pad_s=5.0,\n",
    "    min_valid_run_s=30.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 2) ── slice train / test windows (30-s, 50 % overlap, single-label) ─────────\n",
    "seqs = create_training_sequences_from_combined(\n",
    "    ds_fold,\n",
    "    window_s=30,\n",
    "    step_s=15,\n",
    "    train_subject_ids=train_ids,\n",
    "    test_subject_ids=test_ids,\n",
    "    require_single_label=True\n",
    ")\n",
    "\n",
    "print(\"Train low-rate :\", seqs[\"train\"][\"X_low\"].shape,\n",
    "      \"| Train ECG :\",   seqs[\"train\"][\"X_ecg\"].shape)\n",
    "print(\"Test  low-rate :\",  seqs[\"test\"][\"X_low\"].shape,\n",
    "      \"| Test  ECG :\",    seqs[\"test\"][\"X_ecg\"].shape)\n",
    "\n",
    "# 3) ── save + (optional) visualise + summary ─────────────────────────────────\n",
    "out_dir = save_processed_data_two_stream(\n",
    "    seqs, subdir=f\"tc_multigan_fold_{test_ids[0]}\"\n",
    ")\n",
    "\n",
    "# ⬇ if your old visualiser expects single-stream keys, skip or adapt it\n",
    "# visualize_preprocessing_results_two_stream is a tiny wrapper you can add\n",
    "# visualize_preprocessing_results_two_stream(seqs, save_name=f\"overview_{test_ids[0]}.png\")\n",
    "\n",
    "preprocessing_summary(seqs, out_dir)\n",
    "print(\"✅ Fold finished →\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e43de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen EDA HP: 0.05 Hz, order 2\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📂 Processing: S2\n",
      "  Original: X (4255300, 3), y (4255300,) (~101.3 min)\n",
      "  After mask (orig fs): (1987299, 3), label dist: {1: 793800, 2: 423500, 3: 246400, 4: 523599}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0742 Hz\n",
      "  ➜ X_low (11352, 2) @ 4 Hz | X_ecg (496650, 1) @ 175 Hz | m1 (11352, 4)\n",
      "\n",
      "📂 Processing: S4\n",
      "  Original: X (4496100, 3), y (4496100,) (~107.0 min)\n",
      "  After mask (orig fs): (2044001, 3), label dist: {1: 803601, 2: 437500, 3: 253400, 4: 549500}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0742 Hz\n",
      "  ➜ X_low (11680, 2) @ 4 Hz | X_ecg (511000, 1) @ 175 Hz | m1 (11680, 4)\n",
      "\n",
      "📂 Processing: S5\n",
      "  Original: X (4380600, 3), y (4380600,) (~104.3 min)\n",
      "  After mask (orig fs): (2072700, 3), label dist: {1: 831600, 2: 444500, 3: 254800, 4: 541800}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0625 Hz\n",
      "  ➜ X_low (11844, 2) @ 4 Hz | X_ecg (518175, 1) @ 175 Hz | m1 (11844, 4)\n",
      "\n",
      "📂 Processing: S6\n",
      "  Original: X (4949700, 3), y (4949700,) (~117.8 min)\n",
      "  After mask (orig fs): (2057300, 3), label dist: {1: 819000, 2: 448000, 3: 253400, 4: 536900}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0820 Hz\n",
      "  ➜ X_low (11756, 2) @ 4 Hz | X_ecg (514325, 1) @ 175 Hz | m1 (11756, 4)\n",
      "\n",
      "📂 Processing: S7\n",
      "  Original: X (3666600, 3), y (3666600,) (~87.3 min)\n",
      "  After mask (orig fs): (2056602, 3), label dist: {1: 823200, 2: 441000, 3: 253401, 4: 539001}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0742 Hz\n",
      "  ➜ X_low (11752, 2) @ 4 Hz | X_ecg (514150, 1) @ 175 Hz | m1 (11752, 4)\n",
      "\n",
      "📂 Processing: S8\n",
      "  Original: X (3826200, 3), y (3826200,) (~91.1 min)\n",
      "  After mask (orig fs): (2068499, 3), label dist: {1: 811300, 2: 462000, 3: 251999, 4: 543200}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11816, 2) @ 4 Hz | X_ecg (516950, 1) @ 175 Hz | m1 (11816, 4)\n",
      "\n",
      "📂 Processing: S9\n",
      "  Original: X (3656100, 3), y (3656100,) (~87.0 min)\n",
      "  After mask (orig fs): (2058000, 3), label dist: {1: 819000, 2: 444500, 3: 253400, 4: 541100}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0742 Hz\n",
      "  ➜ X_low (11760, 2) @ 4 Hz | X_ecg (514500, 1) @ 175 Hz | m1 (11760, 4)\n",
      "\n",
      "📂 Processing: S11\n",
      "  Original: X (3663100, 3), y (3663100,) (~87.2 min)\n",
      "  After mask (orig fs): (2078301, 3), label dist: {1: 819000, 2: 469000, 3: 250600, 4: 539701}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11876, 2) @ 4 Hz | X_ecg (519575, 1) @ 175 Hz | m1 (11876, 4)\n",
      "\n",
      "📂 Processing: S13\n",
      "  Original: X (3875900, 3), y (3875900,) (~92.3 min)\n",
      "  After mask (orig fs): (2079700, 3), label dist: {1: 819001, 2: 457800, 3: 260400, 4: 542499}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0938 Hz\n",
      "  ➜ X_low (11884, 2) @ 4 Hz | X_ecg (519925, 1) @ 175 Hz | m1 (11884, 4)\n",
      "\n",
      "📂 Processing: S15\n",
      "  Original: X (3676400, 3), y (3676400,) (~87.5 min)\n",
      "  After mask (orig fs): (2083899, 3), label dist: {1: 815500, 2: 473200, 3: 253400, 4: 541799}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0625 Hz\n",
      "  ➜ X_low (11904, 2) @ 4 Hz | X_ecg (520800, 1) @ 175 Hz | m1 (11904, 4)\n",
      "\n",
      "📂 Processing: S16\n",
      "  Original: X (3941700, 3), y (3941700,) (~93.8 min)\n",
      "  After mask (orig fs): (2074100, 3), label dist: {1: 819000, 2: 464101, 3: 250600, 4: 540399}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0781 Hz\n",
      "  ➜ X_low (11852, 2) @ 4 Hz | X_ecg (518525, 1) @ 175 Hz | m1 (11852, 4)\n",
      "\n",
      "📂 Processing: S17\n",
      "  Original: X (4144000, 3), y (4144000,) (~98.7 min)\n",
      "  After mask (orig fs): (2069900, 3), label dist: {1: 819700, 2: 499100, 3: 253400, 4: 497700}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11828, 2) @ 4 Hz | X_ecg (517475, 1) @ 175 Hz | m1 (11828, 4)\n",
      "\n",
      "📂 Processing: S3\n",
      "  Original: X (4545100, 3), y (4545100,) (~108.2 min)\n",
      "  After mask (orig fs): (2019501, 3), label dist: {1: 791000, 2: 441000, 3: 255500, 4: 532001}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0664 Hz\n",
      "  ➜ X_low (11540, 2) @ 4 Hz | X_ecg (504875, 1) @ 175 Hz | m1 (11540, 4)\n",
      "\n",
      "📂 Processing: S14\n",
      "  Original: X (3883600, 3), y (3883600,) (~92.5 min)\n",
      "  After mask (orig fs): (2079701, 3), label dist: {1: 819000, 2: 465500, 3: 253401, 4: 541800}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0000 Hz\n",
      "  ➜ X_low (11884, 2) @ 4 Hz | X_ecg (519925, 1) @ 175 Hz | m1 (11884, 4)\n",
      "\n",
      "📂 Processing: S10\n",
      "  Original: X (3847200, 3), y (3847200,) (~91.6 min)\n",
      "  After mask (orig fs): (2116100, 3), label dist: {1: 819000, 2: 500500, 3: 253400, 4: 543200}\n",
      "EDA BEFORE HP peak ~ 0.0039 Hz\n",
      "EDA AFTER  HP peak ~ 0.0703 Hz\n",
      "  ➜ X_low (12092, 2) @ 4 Hz | X_ecg (529025, 1) @ 175 Hz | m1 (12092, 4)\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "Saved to: C:\\Users\\Joseph\\generative-health-models\\data\\processed\\tc_multigan_fold_S10_hp050_o2\n"
     ]
    }
   ],
   "source": [
    "# pick best row\n",
    "best = df_hp.sort_values([\"KS\",\"W1\",\"cutoff\",\"order\"]).iloc[0]\n",
    "BEST_CUTOFF = float(best[\"cutoff\"])\n",
    "BEST_ORDER  = int(best[\"order\"])\n",
    "print(\"Chosen EDA HP:\", BEST_CUTOFF, \"Hz, order\", BEST_ORDER)\n",
    "\n",
    "# rebuild with chosen params\n",
    "ds_fold = process_multiple_subjects(\n",
    "    train_paths + test_paths,\n",
    "    target_rate=4, channels=(\"ECG\",\"EDA\",\"RESP\"),\n",
    "    transition_pad_s=5.0, min_valid_run_s=30.0, verbose=True,\n",
    "    eda_hp_cutoff=BEST_CUTOFF, eda_hp_order=BEST_ORDER, eda_robust=False\n",
    ")\n",
    "seqs = create_training_sequences_from_combined(\n",
    "    ds_fold, window_s=30, step_s=15,\n",
    "    train_subject_ids=train_ids, test_subject_ids=test_ids,\n",
    "    require_single_label=True\n",
    ")\n",
    "\n",
    "tag = f\"hp{int(BEST_CUTOFF*1000):03d}_o{BEST_ORDER}\"\n",
    "out_dir = save_processed_data_two_stream(\n",
    "    seqs, subdir=f\"tc_multigan_fold_{test_ids[0]}_{tag}\"\n",
    ")\n",
    "print(\"Saved to:\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adec29c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44205.0 44205.0\n",
      "Train windows: 2645 Test windows: 194\n",
      "Train mean≈0: [-1.1201316e-08  5.7689181e-10] Train std≈1: [0.9999996 0.9999992]\n",
      "Test mean (not forced to 0): [-0.01319962  0.00013314] Test std: [0.14074133 0.9113119 ]\n",
      "train {1: 1069, 2: 588, 4: 669, 3: 319}\n",
      "test {1: 77, 3: 23, 4: 48, 2: 46}\n",
      "EDA PSD peak ~ 0.0 Hz\n",
      "EDA KS(train,test)= 0.205 W1= 0.16\n",
      "RESP KS(train,test)= 0.036 W1= 0.07\n"
     ]
    }
   ],
   "source": [
    "# Low stream is [EDA, RESP] in this code\n",
    "assert ds_fold[\"channels_low\"] == [\"EDA\",\"RESP\"]\n",
    "assert not np.isnan(ds_fold[\"X_low\"]).any(), \"NaNs in X_low\"\n",
    "assert not np.isnan(ds_fold[\"X_ecg\"]).any(), \"NaNs in X_ecg\"\n",
    "\n",
    "span_low = len(ds_fold[\"X_low\"]) / ds_fold[\"fs_low\"]\n",
    "span_ecg = len(ds_fold[\"X_ecg\"]) / ds_fold[\"fs_ecg\"]\n",
    "print(span_low, span_ecg)\n",
    "assert abs(span_low - span_ecg) < 1e-6\n",
    "\n",
    "for seg in ds_fold[\"segments\"]:\n",
    "    a,b = seg[\"low_start\"], seg[\"low_end\"]\n",
    "    c,d = seg[\"ecg_start\"], seg[\"ecg_end\"]\n",
    "    # Same subjects should have same duration\n",
    "    assert abs((b-a)/ds_fold[\"fs_low\"] - (d-c)/ds_fold[\"fs_ecg\"]) < 1e-6\n",
    "\n",
    "print(\"Train windows:\", seqs[\"train\"][\"X_low\"].shape[0], \n",
    "      \"Test windows:\", seqs[\"test\"][\"X_low\"].shape[0])\n",
    "\n",
    "\n",
    "mu = seqs[\"train\"][\"X_low\"].mean((0,1)); sd = seqs[\"train\"][\"X_low\"].std((0,1))\n",
    "print(\"Train mean≈0:\", mu, \"Train std≈1:\", sd)\n",
    "\n",
    "\n",
    "mu_te = seqs[\"test\"][\"X_low\"].mean((0,1))\n",
    "sd_te = seqs[\"test\"][\"X_low\"].std((0,1))\n",
    "print(\"Test mean (not forced to 0):\", mu_te, \"Test std:\", sd_te)\n",
    "\n",
    "import numpy as np, collections\n",
    "for split in [\"train\",\"test\"]:\n",
    "    cnt = collections.Counter(seqs[split][\"cond\"].tolist())\n",
    "    print(split, dict(cnt))\n",
    "\n",
    "from scipy.signal import welch\n",
    "x_eda = ds_fold[\"X_low\"][:4096,0]  # first EDA samples\n",
    "f, P = welch(x_eda, fs=ds_fold[\"fs_low\"], nperseg=256)\n",
    "print(\"EDA PSD peak ~\", f[P.argmax()], \"Hz\")  # EDA dynamics are very low freq\n",
    "\n",
    "# Compare train vs test REAL distributions (EDA, RESP) after train z-scoring\n",
    "real_train = seqs[\"train\"][\"X_low\"].reshape(-1, 2)\n",
    "real_test  = seqs[\"test\"][\"X_low\"].reshape(-1, 2)\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "for i, name in enumerate([\"EDA\",\"RESP\"]):\n",
    "    r = real_train[:,i]; t = real_test[:,i]\n",
    "    r = r[np.isfinite(r)]; t = t[np.isfinite(t)]\n",
    "    n = min(len(r), len(t))\n",
    "    rng = np.random.default_rng(0)\n",
    "    r = r[rng.choice(len(r), n, replace=False)]\n",
    "    t = t[rng.choice(len(t), n, replace=False)]\n",
    "    ks = stats.ks_2samp(r, t).statistic\n",
    "    w1 = stats.wasserstein_distance(r, t)\n",
    "    print(name, \"KS(train,test)=\", round(ks,3), \"W1=\", round(w1,3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "225b551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG train mean≈0,std≈1: [-5.614325e-09] [0.9999998]\n",
      "ECG test mean/std: [8.217065e-06] [0.53762823]\n",
      "ECG KS(train,test) = 0.2373637702503682\n",
      "ECG W1 = 0.24367693083576528\n",
      "R-peaks: 43 | mean RR=0.700s | bpm≈85.7\n"
     ]
    }
   ],
   "source": [
    "mu_tr = seqs[\"train\"][\"X_ecg\"].mean((0,1))    # shape (1,)\n",
    "sd_tr = seqs[\"train\"][\"X_ecg\"].std((0,1))\n",
    "mu_te = seqs[\"test\"][\"X_ecg\"].mean((0,1))\n",
    "sd_te = seqs[\"test\"][\"X_ecg\"].std((0,1))\n",
    "print(\"ECG train mean≈0,std≈1:\", mu_tr, sd_tr)\n",
    "print(\"ECG test mean/std:\",      mu_te, sd_te)\n",
    "\n",
    "from scipy import stats\n",
    "r = seqs[\"train\"][\"X_ecg\"].reshape(-1)  # already z-scored to train stats\n",
    "t = seqs[\"test\"][\"X_ecg\"].reshape(-1)\n",
    "# balance sample sizes\n",
    "import numpy as np\n",
    "n = min(len(r), len(t))\n",
    "rng = np.random.default_rng(0)\n",
    "r = r[rng.choice(len(r), n, replace=False)]\n",
    "t = t[rng.choice(len(t), n, replace=False)]\n",
    "print(\"ECG KS(train,test) =\", stats.ks_2samp(r, t).statistic)\n",
    "print(\"ECG W1 =\", stats.wasserstein_distance(r, t))\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "ecg = seqs[\"test\"][\"X_ecg\"][0,:,0]  # first test window\n",
    "# simple heuristic: peaks > 1.0 z, spaced ≥ 0.25 s (175*0.25 ≈ 44 samples)\n",
    "peaks, _ = find_peaks(ecg, height=1.0, distance=44)\n",
    "rr = np.diff(peaks) / 175.0  # seconds\n",
    "if len(rr) > 0:\n",
    "    bpm = 60.0 / rr.mean()\n",
    "    print(f\"R-peaks: {len(peaks)} | mean RR={rr.mean():.3f}s | bpm≈{bpm:.1f}\")\n",
    "else:\n",
    "    print(\"No clear R-peaks with this simple detector — try lower height (e.g., 0.7) or better preprocessing.\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a7becbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map subject id -> .pkl path once\n",
    "id2path = {Path(p).stem: p for p in subject_files}\n",
    "\n",
    "# Load LOSO splits you generated earlier\n",
    "splits_path = project_root / \"data\" / \"processed\" / \"wesad_loso_splits.json\"\n",
    "folds = json.loads(splits_path.read_text())\n",
    "\n",
    "def summarize_fold(seqs, fold_name, class_names=(\"baseline\",\"stress\",\"amusement\",\"meditation\")):\n",
    "    K = int(seqs[\"config\"][\"K\"])\n",
    "    tr_y = seqs[\"train\"][\"cond\"]; te_y = seqs[\"test\"][\"cond\"]\n",
    "    tr_counts = np.bincount(tr_y, minlength=K)\n",
    "    te_counts = np.bincount(te_y, minlength=K)\n",
    "    X_tr = seqs[\"train\"][\"X\"]\n",
    "    mu = X_tr.mean(axis=(0,1)); sd = X_tr.std(axis=(0,1))\n",
    "    \n",
    "    # Updated for ECG, EDA, RESP channels\n",
    "    stats = {\n",
    "        \"fold\": fold_name,\n",
    "        \"T\": seqs[\"config\"][\"T\"],\n",
    "        \"step\": seqs[\"config\"][\"step\"],\n",
    "        \"fs\": seqs[\"config\"][\"fs\"],\n",
    "        \"train_N\": int(X_tr.shape[0]),\n",
    "        \"test_N\": int(seqs[\"test\"][\"X\"].shape[0]),\n",
    "        \"impute_dropped_train\": int(seqs[\"impute_stats\"][\"train\"][\"dropped\"]),\n",
    "        \"impute_dropped_test\":  int(seqs[\"impute_stats\"][\"test\"][\"dropped\"]),\n",
    "        \"mu_ECG\": float(mu[0]), \"mu_EDA\": float(mu[1]), \"mu_RESP\": float(mu[2]),\n",
    "        \"sd_ECG\": float(sd[0]), \"sd_EDA\": float(sd[1]), \"sd_RESP\": float(sd[2]),\n",
    "    }\n",
    "    for k in range(K):\n",
    "        stats[f\"train_{class_names[k]}\"] = int(tr_counts[k])\n",
    "        stats[f\"test_{class_names[k]}\"]  = int(te_counts[k])\n",
    "    return stats\n",
    "\n",
    "def run_all_folds(sequence_length=120,    # 30-s low-rate windows (120 steps)\n",
    "                  step_overlap=0.5,\n",
    "                  impute=True,            # not used; kept for API compat\n",
    "                  out_root=None,\n",
    "                  channels=(\"ECG\",\"EDA\",\"RESP\")):\n",
    "\n",
    "    out_root = Path(out_root or (project_root / \"data\" / \"processed\"))\n",
    "    id2path  = {Path(p).stem: p for p in subject_files}\n",
    "\n",
    "    all_rows = []\n",
    "    for f_idx, split in enumerate(folds):\n",
    "        test_ids  = split[\"test\"]                # e.g. ['S10']\n",
    "        train_ids = split[\"train\"] + split.get(\"val\", [])\n",
    "        fold_tag  = f\"fold_{test_ids[0]}\"\n",
    "\n",
    "        print(f\"\\n🚀 Fold {f_idx} — Test: {test_ids} | Train: {len(train_ids)} subjects\")\n",
    "\n",
    "        # ---------- combine all subjects of this fold ----------\n",
    "        paths = [id2path[s] for s in (train_ids + test_ids)]\n",
    "        ds_fold = process_multiple_subjects(paths,\n",
    "                                            target_rate=4,\n",
    "                                            channels=channels,\n",
    "                                            transition_pad_s=5.0,\n",
    "                                            min_valid_run_s=30.0,\n",
    "                                            verbose=False)\n",
    "\n",
    "        # ---------- slice train / test windows ----------\n",
    "        seqs = create_training_sequences_from_combined(\n",
    "            ds_fold,\n",
    "            window_s=sequence_length / 4,        # 120 → 30-s windows\n",
    "            step_s=(sequence_length / 4) * (1-step_overlap),\n",
    "            train_subject_ids=train_ids,\n",
    "            test_subject_ids=test_ids,\n",
    "            require_single_label=True\n",
    "        )\n",
    "\n",
    "        # ---------- save ----------\n",
    "        save_processed_data_two_stream(seqs, subdir=f\"tc_multigan_{fold_tag}\")\n",
    "\n",
    "        # ---------- simple stats ----------\n",
    "        row = {\n",
    "            \"fold\": fold_tag,\n",
    "            \"train_N\": int(seqs[\"train\"][\"X_low\"].shape[0]),\n",
    "            \"test_N\":  int(seqs[\"test\"][\"X_low\"].shape[0]),\n",
    "            \"mu_low_ECG\": float(seqs[\"train\"][\"mean_ecg\"][0]),\n",
    "            \"sd_low_ECG\": float(seqs[\"train\"][\"std_ecg\"][0])\n",
    "        }\n",
    "        all_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(all_rows).sort_values(\"fold\")\n",
    "    csv_path = out_root / \"loso_preproc_two_stream_summary.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n📊 Aggregated preprocessing stats → {csv_path}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3aeb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Fold 0 — Test: ['S10'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 1 — Test: ['S11'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 2 — Test: ['S13'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 3 — Test: ['S14'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 4 — Test: ['S15'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 5 — Test: ['S16'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 6 — Test: ['S17'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 7 — Test: ['S2'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 8 — Test: ['S3'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 9 — Test: ['S4'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.7 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 10 — Test: ['S5'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 11 — Test: ['S6'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.7 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 12 — Test: ['S7'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 13 — Test: ['S8'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.7 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "🚀 Fold 14 — Test: ['S9'] | Train: 14 subjects\n",
      "\n",
      "🔄 Processing 15 subjects …\n",
      "============================================================\n",
      "\n",
      "📊 Combined Dataset:\n",
      "  • Low-rate  : (176820, 2)  (EDA+RESP @ 4 Hz)\n",
      "  • ECG stream: (7735875, 1)  (ECG @ 175 Hz)\n",
      "  • Subjects  : 15   Total: 736.8 min\n",
      "  • Label counts (low-rate): {1: 69844, 2: 39264, 3: 21700, 4: 46012}\n",
      "\n",
      "📊 Aggregated preprocessing stats → C:\\Users\\Joseph\\generative-health-models\\data\\processed\\loso_preproc_two_stream_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_N</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2649.733333</td>\n",
       "      <td>2.711527e+00</td>\n",
       "      <td>2645.000000</td>\n",
       "      <td>2648.500000</td>\n",
       "      <td>2649.000000</td>\n",
       "      <td>2650.000000</td>\n",
       "      <td>2.657000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_N</th>\n",
       "      <td>15.0</td>\n",
       "      <td>189.266667</td>\n",
       "      <td>2.711527e+00</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>1.940000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu_low_ECG</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>6.052112e-07</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-8.484654e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd_low_ECG</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.262519</td>\n",
       "      <td>3.728952e-03</td>\n",
       "      <td>0.255415</td>\n",
       "      <td>0.260487</td>\n",
       "      <td>0.262263</td>\n",
       "      <td>0.264563</td>\n",
       "      <td>2.691641e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count         mean           std          min          25%  \\\n",
       "train_N      15.0  2649.733333  2.711527e+00  2645.000000  2648.500000   \n",
       "test_N       15.0   189.266667  2.711527e+00   182.000000   189.000000   \n",
       "mu_low_ECG   15.0    -0.000002  6.052112e-07    -0.000003    -0.000003   \n",
       "sd_low_ECG   15.0     0.262519  3.728952e-03     0.255415     0.260487   \n",
       "\n",
       "                    50%          75%           max  \n",
       "train_N     2649.000000  2650.000000  2.657000e+03  \n",
       "test_N       190.000000   190.500000  1.940000e+02  \n",
       "mu_low_ECG    -0.000002    -0.000002 -8.484654e-07  \n",
       "sd_low_ECG     0.262263     0.264563  2.691641e-01  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = run_all_folds(sequence_length=120, step_overlap=0.5)\n",
    "df_stats.describe().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
